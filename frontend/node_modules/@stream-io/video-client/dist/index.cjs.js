'use strict';

require('webrtc-adapter');
var runtime = require('@protobuf-ts/runtime');
var runtimeRpc = require('@protobuf-ts/runtime-rpc');
var axios = require('axios');
var twirpTransport = require('@protobuf-ts/twirp-transport');
var rxjs = require('rxjs');
var uaParserJs = require('ua-parser-js');
var sdpTransform = require('sdp-transform');
var https = require('https');

class Tracer {
    constructor(id) {
        this.buffer = [];
        this.enabled = true;
        this.setEnabled = (enabled) => {
            if (this.enabled === enabled)
                return;
            this.enabled = enabled;
            this.buffer = [];
        };
        this.trace = (tag, data) => {
            if (!this.enabled)
                return;
            this.buffer.push([tag, this.id, data, Date.now()]);
        };
        this.take = () => {
            const snapshot = this.buffer;
            this.buffer = [];
            return {
                snapshot,
                rollback: () => {
                    this.buffer.unshift(...snapshot);
                },
            };
        };
        this.dispose = () => {
            this.buffer = [];
        };
        this.id = id;
    }
}

const tracer = new Tracer(null);
if (typeof navigator !== 'undefined' &&
    typeof navigator.mediaDevices !== 'undefined') {
    const dumpStream = (stream) => ({
        id: stream.id,
        tracks: stream.getTracks().map((track) => ({
            id: track.id,
            kind: track.kind,
            label: track.label,
            enabled: track.enabled,
            muted: track.muted,
            readyState: track.readyState,
        })),
    });
    const trace = tracer.trace;
    const target = navigator.mediaDevices;
    for (const method of ['getUserMedia', 'getDisplayMedia']) {
        const original = target[method];
        if (!original)
            continue;
        target[method] = async function tracedMethod(constraints) {
            const tag = `navigator.mediaDevices.${method}`;
            trace(tag, constraints);
            try {
                const stream = await original.call(target, constraints);
                trace(`${tag}OnSuccess`, dumpStream(stream));
                return stream;
            }
            catch (err) {
                trace(`${tag}OnFailure`, err.name);
                throw err;
            }
        };
    }
}

/* tslint:disable */
/**
 * @export
 */
const AudioSettingsRequestDefaultDeviceEnum = {
    SPEAKER: 'speaker',
    EARPIECE: 'earpiece',
};
/**
 * @export
 */
const AudioSettingsResponseDefaultDeviceEnum = {
    SPEAKER: 'speaker',
    EARPIECE: 'earpiece',
};
/**
 * @export
 */
const CreateDeviceRequestPushProviderEnum = {
    FIREBASE: 'firebase',
    APN: 'apn',
    HUAWEI: 'huawei',
    XIAOMI: 'xiaomi',
};
/**
 * @export
 */
const FrameRecordingSettingsRequestModeEnum = {
    AVAILABLE: 'available',
    DISABLED: 'disabled',
    AUTO_ON: 'auto-on',
};
/**
 * @export
 */
const FrameRecordingSettingsRequestQualityEnum = {
    _360P: '360p',
    _480P: '480p',
    _720P: '720p',
    _1080P: '1080p',
    _1440P: '1440p',
};
/**
 * @export
 */
const FrameRecordingSettingsResponseModeEnum = {
    AVAILABLE: 'available',
    DISABLED: 'disabled',
    AUTO_ON: 'auto-on',
};
/**
 * @export
 */
const LayoutSettingsRequestNameEnum = {
    SPOTLIGHT: 'spotlight',
    GRID: 'grid',
    SINGLE_PARTICIPANT: 'single-participant',
    MOBILE: 'mobile',
    CUSTOM: 'custom',
};
/**
 * @export
 */
const NoiseCancellationSettingsModeEnum = {
    AVAILABLE: 'available',
    DISABLED: 'disabled',
    AUTO_ON: 'auto-on',
};
/**
 * All possibility of string to use
 * @export
 */
const OwnCapability = {
    BLOCK_USERS: 'block-users',
    CHANGE_MAX_DURATION: 'change-max-duration',
    CREATE_CALL: 'create-call',
    CREATE_REACTION: 'create-reaction',
    ENABLE_NOISE_CANCELLATION: 'enable-noise-cancellation',
    END_CALL: 'end-call',
    JOIN_BACKSTAGE: 'join-backstage',
    JOIN_CALL: 'join-call',
    JOIN_ENDED_CALL: 'join-ended-call',
    MUTE_USERS: 'mute-users',
    PIN_FOR_EVERYONE: 'pin-for-everyone',
    READ_CALL: 'read-call',
    REMOVE_CALL_MEMBER: 'remove-call-member',
    SCREENSHARE: 'screenshare',
    SEND_AUDIO: 'send-audio',
    SEND_VIDEO: 'send-video',
    START_BROADCAST_CALL: 'start-broadcast-call',
    START_CLOSED_CAPTIONS_CALL: 'start-closed-captions-call',
    START_FRAME_RECORD_CALL: 'start-frame-record-call',
    START_RECORD_CALL: 'start-record-call',
    START_TRANSCRIPTION_CALL: 'start-transcription-call',
    STOP_BROADCAST_CALL: 'stop-broadcast-call',
    STOP_CLOSED_CAPTIONS_CALL: 'stop-closed-captions-call',
    STOP_FRAME_RECORD_CALL: 'stop-frame-record-call',
    STOP_RECORD_CALL: 'stop-record-call',
    STOP_TRANSCRIPTION_CALL: 'stop-transcription-call',
    UPDATE_CALL: 'update-call',
    UPDATE_CALL_MEMBER: 'update-call-member',
    UPDATE_CALL_PERMISSIONS: 'update-call-permissions',
    UPDATE_CALL_SETTINGS: 'update-call-settings',
};
/**
 * @export
 */
const RTMPBroadcastRequestQualityEnum = {
    _360P: '360p',
    _480P: '480p',
    _720P: '720p',
    _1080P: '1080p',
    _1440P: '1440p',
    PORTRAIT_360X640: 'portrait-360x640',
    PORTRAIT_480X854: 'portrait-480x854',
    PORTRAIT_720X1280: 'portrait-720x1280',
    PORTRAIT_1080X1920: 'portrait-1080x1920',
    PORTRAIT_1440X2560: 'portrait-1440x2560',
};
/**
 * @export
 */
const RTMPSettingsRequestQualityEnum = {
    _360P: '360p',
    _480P: '480p',
    _720P: '720p',
    _1080P: '1080p',
    _1440P: '1440p',
    PORTRAIT_360X640: 'portrait-360x640',
    PORTRAIT_480X854: 'portrait-480x854',
    PORTRAIT_720X1280: 'portrait-720x1280',
    PORTRAIT_1080X1920: 'portrait-1080x1920',
    PORTRAIT_1440X2560: 'portrait-1440x2560',
};
/**
 * @export
 */
const RecordSettingsRequestModeEnum = {
    AVAILABLE: 'available',
    DISABLED: 'disabled',
    AUTO_ON: 'auto-on',
};
/**
 * @export
 */
const RecordSettingsRequestQualityEnum = {
    _360P: '360p',
    _480P: '480p',
    _720P: '720p',
    _1080P: '1080p',
    _1440P: '1440p',
    PORTRAIT_360X640: 'portrait-360x640',
    PORTRAIT_480X854: 'portrait-480x854',
    PORTRAIT_720X1280: 'portrait-720x1280',
    PORTRAIT_1080X1920: 'portrait-1080x1920',
    PORTRAIT_1440X2560: 'portrait-1440x2560',
};
/**
 * @export
 */
const TranscriptionSettingsRequestClosedCaptionModeEnum = {
    AVAILABLE: 'available',
    DISABLED: 'disabled',
    AUTO_ON: 'auto-on',
};
/**
 * @export
 */
const TranscriptionSettingsRequestLanguageEnum = {
    AUTO: 'auto',
    EN: 'en',
    FR: 'fr',
    ES: 'es',
    DE: 'de',
    IT: 'it',
    NL: 'nl',
    PT: 'pt',
    PL: 'pl',
    CA: 'ca',
    CS: 'cs',
    DA: 'da',
    EL: 'el',
    FI: 'fi',
    ID: 'id',
    JA: 'ja',
    RU: 'ru',
    SV: 'sv',
    TA: 'ta',
    TH: 'th',
    TR: 'tr',
    HU: 'hu',
    RO: 'ro',
    ZH: 'zh',
    AR: 'ar',
    TL: 'tl',
    HE: 'he',
    HI: 'hi',
    HR: 'hr',
    KO: 'ko',
    MS: 'ms',
    NO: 'no',
    UK: 'uk',
};
/**
 * @export
 */
const TranscriptionSettingsRequestModeEnum = {
    AVAILABLE: 'available',
    DISABLED: 'disabled',
    AUTO_ON: 'auto-on',
};
/**
 * @export
 */
const TranscriptionSettingsResponseClosedCaptionModeEnum = {
    AVAILABLE: 'available',
    DISABLED: 'disabled',
    AUTO_ON: 'auto-on',
};
/**
 * @export
 */
const TranscriptionSettingsResponseLanguageEnum = {
    AUTO: 'auto',
    EN: 'en',
    FR: 'fr',
    ES: 'es',
    DE: 'de',
    IT: 'it',
    NL: 'nl',
    PT: 'pt',
    PL: 'pl',
    CA: 'ca',
    CS: 'cs',
    DA: 'da',
    EL: 'el',
    FI: 'fi',
    ID: 'id',
    JA: 'ja',
    RU: 'ru',
    SV: 'sv',
    TA: 'ta',
    TH: 'th',
    TR: 'tr',
    HU: 'hu',
    RO: 'ro',
    ZH: 'zh',
    AR: 'ar',
    TL: 'tl',
    HE: 'he',
    HI: 'hi',
    HR: 'hr',
    KO: 'ko',
    MS: 'ms',
    NO: 'no',
    UK: 'uk',
};
/**
 * @export
 */
const TranscriptionSettingsResponseModeEnum = {
    AVAILABLE: 'available',
    DISABLED: 'disabled',
    AUTO_ON: 'auto-on',
};
/**
 * @export
 */
const VideoSettingsRequestCameraFacingEnum = {
    FRONT: 'front',
    BACK: 'back',
    EXTERNAL: 'external',
};
/**
 * @export
 */
const VideoSettingsResponseCameraFacingEnum = {
    FRONT: 'front',
    BACK: 'back',
    EXTERNAL: 'external',
};

class ErrorFromResponse extends Error {
}

// @generated by protobuf-ts 2.9.6 with parameter long_type_string,client_generic,server_none,eslint_disable,optimize_code_size
// @generated from protobuf file "google/protobuf/struct.proto" (package "google.protobuf", syntax proto3)
// tslint:disable
//
// Protocol Buffers - Google's data interchange format
// Copyright 2008 Google Inc.  All rights reserved.
// https://developers.google.com/protocol-buffers/
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are
// met:
//
//     * Redistributions of source code must retain the above copyright
// notice, this list of conditions and the following disclaimer.
//     * Redistributions in binary form must reproduce the above
// copyright notice, this list of conditions and the following disclaimer
// in the documentation and/or other materials provided with the
// distribution.
//     * Neither the name of Google Inc. nor the names of its
// contributors may be used to endorse or promote products derived from
// this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
//
/**
 * `NullValue` is a singleton enumeration to represent the null value for the
 * `Value` type union.
 *
 *  The JSON representation for `NullValue` is JSON `null`.
 *
 * @generated from protobuf enum google.protobuf.NullValue
 */
var NullValue;
(function (NullValue) {
    /**
     * Null value.
     *
     * @generated from protobuf enum value: NULL_VALUE = 0;
     */
    NullValue[NullValue["NULL_VALUE"] = 0] = "NULL_VALUE";
})(NullValue || (NullValue = {}));
// @generated message type with reflection information, may provide speed optimized methods
class Struct$Type extends runtime.MessageType {
    constructor() {
        super('google.protobuf.Struct', [
            {
                no: 1,
                name: 'fields',
                kind: 'map',
                K: 9 /*ScalarType.STRING*/,
                V: { kind: 'message', T: () => Value },
            },
        ]);
    }
    /**
     * Encode `Struct` to JSON object.
     */
    internalJsonWrite(message, options) {
        let json = {};
        for (let [k, v] of Object.entries(message.fields)) {
            json[k] = Value.toJson(v);
        }
        return json;
    }
    /**
     * Decode `Struct` from JSON object.
     */
    internalJsonRead(json, options, target) {
        if (!runtime.isJsonObject(json))
            throw new globalThis.Error('Unable to parse message ' +
                this.typeName +
                ' from JSON ' +
                runtime.typeofJsonValue(json) +
                '.');
        if (!target)
            target = this.create();
        for (let [k, v] of globalThis.Object.entries(json)) {
            target.fields[k] = Value.fromJson(v);
        }
        return target;
    }
}
/**
 * @generated MessageType for protobuf message google.protobuf.Struct
 */
const Struct = new Struct$Type();
// @generated message type with reflection information, may provide speed optimized methods
class Value$Type extends runtime.MessageType {
    constructor() {
        super('google.protobuf.Value', [
            {
                no: 1,
                name: 'null_value',
                kind: 'enum',
                oneof: 'kind',
                T: () => ['google.protobuf.NullValue', NullValue],
            },
            {
                no: 2,
                name: 'number_value',
                kind: 'scalar',
                oneof: 'kind',
                T: 1 /*ScalarType.DOUBLE*/,
            },
            {
                no: 3,
                name: 'string_value',
                kind: 'scalar',
                oneof: 'kind',
                T: 9 /*ScalarType.STRING*/,
            },
            {
                no: 4,
                name: 'bool_value',
                kind: 'scalar',
                oneof: 'kind',
                T: 8 /*ScalarType.BOOL*/,
            },
            {
                no: 5,
                name: 'struct_value',
                kind: 'message',
                oneof: 'kind',
                T: () => Struct,
            },
            {
                no: 6,
                name: 'list_value',
                kind: 'message',
                oneof: 'kind',
                T: () => ListValue,
            },
        ]);
    }
    /**
     * Encode `Value` to JSON value.
     */
    internalJsonWrite(message, options) {
        if (message.kind.oneofKind === undefined)
            throw new globalThis.Error();
        switch (message.kind.oneofKind) {
            case undefined:
                throw new globalThis.Error();
            case 'boolValue':
                return message.kind.boolValue;
            case 'nullValue':
                return null;
            case 'numberValue':
                let numberValue = message.kind.numberValue;
                if (typeof numberValue == 'number' && !Number.isFinite(numberValue))
                    throw new globalThis.Error();
                return numberValue;
            case 'stringValue':
                return message.kind.stringValue;
            case 'listValue':
                let listValueField = this.fields.find((f) => f.no === 6);
                if (listValueField?.kind !== 'message')
                    throw new globalThis.Error();
                return listValueField.T().toJson(message.kind.listValue);
            case 'structValue':
                let structValueField = this.fields.find((f) => f.no === 5);
                if (structValueField?.kind !== 'message')
                    throw new globalThis.Error();
                return structValueField.T().toJson(message.kind.structValue);
        }
    }
    /**
     * Decode `Value` from JSON value.
     */
    internalJsonRead(json, options, target) {
        if (!target)
            target = this.create();
        switch (typeof json) {
            case 'number':
                target.kind = { oneofKind: 'numberValue', numberValue: json };
                break;
            case 'string':
                target.kind = { oneofKind: 'stringValue', stringValue: json };
                break;
            case 'boolean':
                target.kind = { oneofKind: 'boolValue', boolValue: json };
                break;
            case 'object':
                if (json === null) {
                    target.kind = {
                        oneofKind: 'nullValue',
                        nullValue: NullValue.NULL_VALUE,
                    };
                }
                else if (globalThis.Array.isArray(json)) {
                    target.kind = {
                        oneofKind: 'listValue',
                        listValue: ListValue.fromJson(json),
                    };
                }
                else {
                    target.kind = {
                        oneofKind: 'structValue',
                        structValue: Struct.fromJson(json),
                    };
                }
                break;
            default:
                throw new globalThis.Error('Unable to parse ' +
                    this.typeName +
                    ' from JSON ' +
                    runtime.typeofJsonValue(json));
        }
        return target;
    }
}
/**
 * @generated MessageType for protobuf message google.protobuf.Value
 */
const Value = new Value$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ListValue$Type extends runtime.MessageType {
    constructor() {
        super('google.protobuf.ListValue', [
            {
                no: 1,
                name: 'values',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => Value,
            },
        ]);
    }
    /**
     * Encode `ListValue` to JSON array.
     */
    internalJsonWrite(message, options) {
        return message.values.map((v) => Value.toJson(v));
    }
    /**
     * Decode `ListValue` from JSON array.
     */
    internalJsonRead(json, options, target) {
        if (!globalThis.Array.isArray(json))
            throw new globalThis.Error('Unable to parse ' +
                this.typeName +
                ' from JSON ' +
                runtime.typeofJsonValue(json));
        if (!target)
            target = this.create();
        let values = json.map((v) => Value.fromJson(v));
        target.values.push(...values);
        return target;
    }
}
/**
 * @generated MessageType for protobuf message google.protobuf.ListValue
 */
const ListValue = new ListValue$Type();

// @generated by protobuf-ts 2.9.6 with parameter long_type_string,client_generic,server_none,eslint_disable,optimize_code_size
// @generated from protobuf file "google/protobuf/timestamp.proto" (package "google.protobuf", syntax proto3)
// tslint:disable
//
// Protocol Buffers - Google's data interchange format
// Copyright 2008 Google Inc.  All rights reserved.
// https://developers.google.com/protocol-buffers/
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are
// met:
//
//     * Redistributions of source code must retain the above copyright
// notice, this list of conditions and the following disclaimer.
//     * Redistributions in binary form must reproduce the above
// copyright notice, this list of conditions and the following disclaimer
// in the documentation and/or other materials provided with the
// distribution.
//     * Neither the name of Google Inc. nor the names of its
// contributors may be used to endorse or promote products derived from
// this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
//
// @generated message type with reflection information, may provide speed optimized methods
class Timestamp$Type extends runtime.MessageType {
    constructor() {
        super('google.protobuf.Timestamp', [
            { no: 1, name: 'seconds', kind: 'scalar', T: 3 /*ScalarType.INT64*/ },
            { no: 2, name: 'nanos', kind: 'scalar', T: 5 /*ScalarType.INT32*/ },
        ]);
    }
    /**
     * Creates a new `Timestamp` for the current time.
     */
    now() {
        const msg = this.create();
        const ms = Date.now();
        msg.seconds = runtime.PbLong.from(Math.floor(ms / 1000)).toString();
        msg.nanos = (ms % 1000) * 1000000;
        return msg;
    }
    /**
     * Converts a `Timestamp` to a JavaScript Date.
     */
    toDate(message) {
        return new Date(runtime.PbLong.from(message.seconds).toNumber() * 1000 +
            Math.ceil(message.nanos / 1000000));
    }
    /**
     * Converts a JavaScript Date to a `Timestamp`.
     */
    fromDate(date) {
        const msg = this.create();
        const ms = date.getTime();
        msg.seconds = runtime.PbLong.from(Math.floor(ms / 1000)).toString();
        msg.nanos =
            ((ms % 1000) + (ms < 0 && ms % 1000 !== 0 ? 1000 : 0)) * 1000000;
        return msg;
    }
    /**
     * In JSON format, the `Timestamp` type is encoded as a string
     * in the RFC 3339 format.
     */
    internalJsonWrite(message, options) {
        let ms = runtime.PbLong.from(message.seconds).toNumber() * 1000;
        if (ms < Date.parse('0001-01-01T00:00:00Z') ||
            ms > Date.parse('9999-12-31T23:59:59Z'))
            throw new Error('Unable to encode Timestamp to JSON. Must be from 0001-01-01T00:00:00Z to 9999-12-31T23:59:59Z inclusive.');
        if (message.nanos < 0)
            throw new Error('Unable to encode invalid Timestamp to JSON. Nanos must not be negative.');
        let z = 'Z';
        if (message.nanos > 0) {
            let nanosStr = (message.nanos + 1000000000).toString().substring(1);
            if (nanosStr.substring(3) === '000000')
                z = '.' + nanosStr.substring(0, 3) + 'Z';
            else if (nanosStr.substring(6) === '000')
                z = '.' + nanosStr.substring(0, 6) + 'Z';
            else
                z = '.' + nanosStr + 'Z';
        }
        return new Date(ms).toISOString().replace('.000Z', z);
    }
    /**
     * In JSON format, the `Timestamp` type is encoded as a string
     * in the RFC 3339 format.
     */
    internalJsonRead(json, options, target) {
        if (typeof json !== 'string')
            throw new Error('Unable to parse Timestamp from JSON ' + runtime.typeofJsonValue(json) + '.');
        let matches = json.match(/^([0-9]{4})-([0-9]{2})-([0-9]{2})T([0-9]{2}):([0-9]{2}):([0-9]{2})(?:Z|\.([0-9]{3,9})Z|([+-][0-9][0-9]:[0-9][0-9]))$/);
        if (!matches)
            throw new Error('Unable to parse Timestamp from JSON. Invalid format.');
        let ms = Date.parse(matches[1] +
            '-' +
            matches[2] +
            '-' +
            matches[3] +
            'T' +
            matches[4] +
            ':' +
            matches[5] +
            ':' +
            matches[6] +
            (matches[8] ? matches[8] : 'Z'));
        if (Number.isNaN(ms))
            throw new Error('Unable to parse Timestamp from JSON. Invalid value.');
        if (ms < Date.parse('0001-01-01T00:00:00Z') ||
            ms > Date.parse('9999-12-31T23:59:59Z'))
            throw new globalThis.Error('Unable to parse Timestamp from JSON. Must be from 0001-01-01T00:00:00Z to 9999-12-31T23:59:59Z inclusive.');
        if (!target)
            target = this.create();
        target.seconds = runtime.PbLong.from(ms / 1000).toString();
        target.nanos = 0;
        if (matches[7])
            target.nanos =
                parseInt('1' + matches[7] + '0'.repeat(9 - matches[7].length)) -
                    1000000000;
        return target;
    }
}
/**
 * @generated MessageType for protobuf message google.protobuf.Timestamp
 */
const Timestamp = new Timestamp$Type();

// @generated by protobuf-ts 2.9.6 with parameter long_type_string,client_generic,server_none,eslint_disable,optimize_code_size
// @generated from protobuf file "video/sfu/models/models.proto" (package "stream.video.sfu.models", syntax proto3)
// tslint:disable
/**
 * @generated from protobuf enum stream.video.sfu.models.PeerType
 */
var PeerType;
(function (PeerType) {
    /**
     * todo fix me (marcelo)
     *
     * @generated from protobuf enum value: PEER_TYPE_PUBLISHER_UNSPECIFIED = 0;
     */
    PeerType[PeerType["PUBLISHER_UNSPECIFIED"] = 0] = "PUBLISHER_UNSPECIFIED";
    /**
     * @generated from protobuf enum value: PEER_TYPE_SUBSCRIBER = 1;
     */
    PeerType[PeerType["SUBSCRIBER"] = 1] = "SUBSCRIBER";
})(PeerType || (PeerType = {}));
/**
 * @generated from protobuf enum stream.video.sfu.models.ConnectionQuality
 */
var ConnectionQuality;
(function (ConnectionQuality) {
    /**
     * @generated from protobuf enum value: CONNECTION_QUALITY_UNSPECIFIED = 0;
     */
    ConnectionQuality[ConnectionQuality["UNSPECIFIED"] = 0] = "UNSPECIFIED";
    /**
     * @generated from protobuf enum value: CONNECTION_QUALITY_POOR = 1;
     */
    ConnectionQuality[ConnectionQuality["POOR"] = 1] = "POOR";
    /**
     * @generated from protobuf enum value: CONNECTION_QUALITY_GOOD = 2;
     */
    ConnectionQuality[ConnectionQuality["GOOD"] = 2] = "GOOD";
    /**
     * @generated from protobuf enum value: CONNECTION_QUALITY_EXCELLENT = 3;
     */
    ConnectionQuality[ConnectionQuality["EXCELLENT"] = 3] = "EXCELLENT";
})(ConnectionQuality || (ConnectionQuality = {}));
/**
 * @generated from protobuf enum stream.video.sfu.models.VideoQuality
 */
var VideoQuality;
(function (VideoQuality) {
    /**
     * @generated from protobuf enum value: VIDEO_QUALITY_LOW_UNSPECIFIED = 0;
     */
    VideoQuality[VideoQuality["LOW_UNSPECIFIED"] = 0] = "LOW_UNSPECIFIED";
    /**
     * @generated from protobuf enum value: VIDEO_QUALITY_MID = 1;
     */
    VideoQuality[VideoQuality["MID"] = 1] = "MID";
    /**
     * @generated from protobuf enum value: VIDEO_QUALITY_HIGH = 2;
     */
    VideoQuality[VideoQuality["HIGH"] = 2] = "HIGH";
    /**
     * @generated from protobuf enum value: VIDEO_QUALITY_OFF = 3;
     */
    VideoQuality[VideoQuality["OFF"] = 3] = "OFF";
})(VideoQuality || (VideoQuality = {}));
/**
 * @generated from protobuf enum stream.video.sfu.models.TrackType
 */
var TrackType;
(function (TrackType) {
    /**
     * @generated from protobuf enum value: TRACK_TYPE_UNSPECIFIED = 0;
     */
    TrackType[TrackType["UNSPECIFIED"] = 0] = "UNSPECIFIED";
    /**
     * @generated from protobuf enum value: TRACK_TYPE_AUDIO = 1;
     */
    TrackType[TrackType["AUDIO"] = 1] = "AUDIO";
    /**
     * @generated from protobuf enum value: TRACK_TYPE_VIDEO = 2;
     */
    TrackType[TrackType["VIDEO"] = 2] = "VIDEO";
    /**
     * @generated from protobuf enum value: TRACK_TYPE_SCREEN_SHARE = 3;
     */
    TrackType[TrackType["SCREEN_SHARE"] = 3] = "SCREEN_SHARE";
    /**
     * @generated from protobuf enum value: TRACK_TYPE_SCREEN_SHARE_AUDIO = 4;
     */
    TrackType[TrackType["SCREEN_SHARE_AUDIO"] = 4] = "SCREEN_SHARE_AUDIO";
})(TrackType || (TrackType = {}));
/**
 * @generated from protobuf enum stream.video.sfu.models.ErrorCode
 */
var ErrorCode;
(function (ErrorCode) {
    /**
     * @generated from protobuf enum value: ERROR_CODE_UNSPECIFIED = 0;
     */
    ErrorCode[ErrorCode["UNSPECIFIED"] = 0] = "UNSPECIFIED";
    /**
     * @generated from protobuf enum value: ERROR_CODE_PUBLISH_TRACK_NOT_FOUND = 100;
     */
    ErrorCode[ErrorCode["PUBLISH_TRACK_NOT_FOUND"] = 100] = "PUBLISH_TRACK_NOT_FOUND";
    /**
     * @generated from protobuf enum value: ERROR_CODE_PUBLISH_TRACKS_MISMATCH = 101;
     */
    ErrorCode[ErrorCode["PUBLISH_TRACKS_MISMATCH"] = 101] = "PUBLISH_TRACKS_MISMATCH";
    /**
     * @generated from protobuf enum value: ERROR_CODE_PUBLISH_TRACK_OUT_OF_ORDER = 102;
     */
    ErrorCode[ErrorCode["PUBLISH_TRACK_OUT_OF_ORDER"] = 102] = "PUBLISH_TRACK_OUT_OF_ORDER";
    /**
     * @generated from protobuf enum value: ERROR_CODE_PUBLISH_TRACK_VIDEO_LAYER_NOT_FOUND = 103;
     */
    ErrorCode[ErrorCode["PUBLISH_TRACK_VIDEO_LAYER_NOT_FOUND"] = 103] = "PUBLISH_TRACK_VIDEO_LAYER_NOT_FOUND";
    /**
     * @generated from protobuf enum value: ERROR_CODE_LIVE_ENDED = 104;
     */
    ErrorCode[ErrorCode["LIVE_ENDED"] = 104] = "LIVE_ENDED";
    /**
     * @generated from protobuf enum value: ERROR_CODE_PARTICIPANT_NOT_FOUND = 200;
     */
    ErrorCode[ErrorCode["PARTICIPANT_NOT_FOUND"] = 200] = "PARTICIPANT_NOT_FOUND";
    /**
     * @generated from protobuf enum value: ERROR_CODE_PARTICIPANT_MIGRATING_OUT = 201;
     */
    ErrorCode[ErrorCode["PARTICIPANT_MIGRATING_OUT"] = 201] = "PARTICIPANT_MIGRATING_OUT";
    /**
     * @generated from protobuf enum value: ERROR_CODE_PARTICIPANT_MIGRATION_FAILED = 202;
     */
    ErrorCode[ErrorCode["PARTICIPANT_MIGRATION_FAILED"] = 202] = "PARTICIPANT_MIGRATION_FAILED";
    /**
     * @generated from protobuf enum value: ERROR_CODE_PARTICIPANT_MIGRATING = 203;
     */
    ErrorCode[ErrorCode["PARTICIPANT_MIGRATING"] = 203] = "PARTICIPANT_MIGRATING";
    /**
     * @generated from protobuf enum value: ERROR_CODE_PARTICIPANT_RECONNECT_FAILED = 204;
     */
    ErrorCode[ErrorCode["PARTICIPANT_RECONNECT_FAILED"] = 204] = "PARTICIPANT_RECONNECT_FAILED";
    /**
     * @generated from protobuf enum value: ERROR_CODE_PARTICIPANT_MEDIA_TRANSPORT_FAILURE = 205;
     */
    ErrorCode[ErrorCode["PARTICIPANT_MEDIA_TRANSPORT_FAILURE"] = 205] = "PARTICIPANT_MEDIA_TRANSPORT_FAILURE";
    /**
     * @generated from protobuf enum value: ERROR_CODE_CALL_NOT_FOUND = 300;
     */
    ErrorCode[ErrorCode["CALL_NOT_FOUND"] = 300] = "CALL_NOT_FOUND";
    /**
     * @generated from protobuf enum value: ERROR_CODE_REQUEST_VALIDATION_FAILED = 400;
     */
    ErrorCode[ErrorCode["REQUEST_VALIDATION_FAILED"] = 400] = "REQUEST_VALIDATION_FAILED";
    /**
     * @generated from protobuf enum value: ERROR_CODE_UNAUTHENTICATED = 401;
     */
    ErrorCode[ErrorCode["UNAUTHENTICATED"] = 401] = "UNAUTHENTICATED";
    /**
     * @generated from protobuf enum value: ERROR_CODE_PERMISSION_DENIED = 403;
     */
    ErrorCode[ErrorCode["PERMISSION_DENIED"] = 403] = "PERMISSION_DENIED";
    /**
     * @generated from protobuf enum value: ERROR_CODE_TOO_MANY_REQUESTS = 429;
     */
    ErrorCode[ErrorCode["TOO_MANY_REQUESTS"] = 429] = "TOO_MANY_REQUESTS";
    /**
     * @generated from protobuf enum value: ERROR_CODE_INTERNAL_SERVER_ERROR = 500;
     */
    ErrorCode[ErrorCode["INTERNAL_SERVER_ERROR"] = 500] = "INTERNAL_SERVER_ERROR";
    /**
     * @generated from protobuf enum value: ERROR_CODE_SFU_SHUTTING_DOWN = 600;
     */
    ErrorCode[ErrorCode["SFU_SHUTTING_DOWN"] = 600] = "SFU_SHUTTING_DOWN";
    /**
     * @generated from protobuf enum value: ERROR_CODE_SFU_FULL = 700;
     */
    ErrorCode[ErrorCode["SFU_FULL"] = 700] = "SFU_FULL";
})(ErrorCode || (ErrorCode = {}));
/**
 * @generated from protobuf enum stream.video.sfu.models.SdkType
 */
var SdkType;
(function (SdkType) {
    /**
     * @generated from protobuf enum value: SDK_TYPE_UNSPECIFIED = 0;
     */
    SdkType[SdkType["UNSPECIFIED"] = 0] = "UNSPECIFIED";
    /**
     * @generated from protobuf enum value: SDK_TYPE_REACT = 1;
     */
    SdkType[SdkType["REACT"] = 1] = "REACT";
    /**
     * @generated from protobuf enum value: SDK_TYPE_ANGULAR = 2;
     */
    SdkType[SdkType["ANGULAR"] = 2] = "ANGULAR";
    /**
     * @generated from protobuf enum value: SDK_TYPE_ANDROID = 3;
     */
    SdkType[SdkType["ANDROID"] = 3] = "ANDROID";
    /**
     * @generated from protobuf enum value: SDK_TYPE_IOS = 4;
     */
    SdkType[SdkType["IOS"] = 4] = "IOS";
    /**
     * @generated from protobuf enum value: SDK_TYPE_FLUTTER = 5;
     */
    SdkType[SdkType["FLUTTER"] = 5] = "FLUTTER";
    /**
     * @generated from protobuf enum value: SDK_TYPE_REACT_NATIVE = 6;
     */
    SdkType[SdkType["REACT_NATIVE"] = 6] = "REACT_NATIVE";
    /**
     * @generated from protobuf enum value: SDK_TYPE_UNITY = 7;
     */
    SdkType[SdkType["UNITY"] = 7] = "UNITY";
    /**
     * @generated from protobuf enum value: SDK_TYPE_GO = 8;
     */
    SdkType[SdkType["GO"] = 8] = "GO";
    /**
     * @generated from protobuf enum value: SDK_TYPE_PLAIN_JAVASCRIPT = 9;
     */
    SdkType[SdkType["PLAIN_JAVASCRIPT"] = 9] = "PLAIN_JAVASCRIPT";
})(SdkType || (SdkType = {}));
/**
 * @generated from protobuf enum stream.video.sfu.models.TrackUnpublishReason
 */
var TrackUnpublishReason;
(function (TrackUnpublishReason) {
    /**
     * Default value which is used when the specific reason
     * for muting the track is not known.
     *
     * @generated from protobuf enum value: TRACK_UNPUBLISH_REASON_UNSPECIFIED = 0;
     */
    TrackUnpublishReason[TrackUnpublishReason["UNSPECIFIED"] = 0] = "UNSPECIFIED";
    /**
     * Represents user muting their tracks.
     *
     * @generated from protobuf enum value: TRACK_UNPUBLISH_REASON_USER_MUTED = 1;
     */
    TrackUnpublishReason[TrackUnpublishReason["USER_MUTED"] = 1] = "USER_MUTED";
    /**
     * Represents muting the track because the permission to
     * publish the track has been revoked.
     *
     * @generated from protobuf enum value: TRACK_UNPUBLISH_REASON_PERMISSION_REVOKED = 2;
     */
    TrackUnpublishReason[TrackUnpublishReason["PERMISSION_REVOKED"] = 2] = "PERMISSION_REVOKED";
    /**
     * Represents muting the track due to moderation actions.
     * This is different from permission revoked because the
     * participant can unmute themselves here whereas in case
     * of "permission revoke" it is not possible until the
     * call permissions are updated.
     *
     * @generated from protobuf enum value: TRACK_UNPUBLISH_REASON_MODERATION = 3;
     */
    TrackUnpublishReason[TrackUnpublishReason["MODERATION"] = 3] = "MODERATION";
})(TrackUnpublishReason || (TrackUnpublishReason = {}));
/**
 * GoAwayReason represents the reason for the SFU to
 * disconnect the client.
 *
 * @generated from protobuf enum stream.video.sfu.models.GoAwayReason
 */
var GoAwayReason;
(function (GoAwayReason) {
    /**
     * @generated from protobuf enum value: GO_AWAY_REASON_UNSPECIFIED = 0;
     */
    GoAwayReason[GoAwayReason["UNSPECIFIED"] = 0] = "UNSPECIFIED";
    /**
     * @generated from protobuf enum value: GO_AWAY_REASON_SHUTTING_DOWN = 1;
     */
    GoAwayReason[GoAwayReason["SHUTTING_DOWN"] = 1] = "SHUTTING_DOWN";
    /**
     * @generated from protobuf enum value: GO_AWAY_REASON_REBALANCE = 2;
     */
    GoAwayReason[GoAwayReason["REBALANCE"] = 2] = "REBALANCE";
})(GoAwayReason || (GoAwayReason = {}));
/**
 * CallEndedReason represents the reason for the call to end.
 *
 * @generated from protobuf enum stream.video.sfu.models.CallEndedReason
 */
var CallEndedReason;
(function (CallEndedReason) {
    /**
     * @generated from protobuf enum value: CALL_ENDED_REASON_UNSPECIFIED = 0;
     */
    CallEndedReason[CallEndedReason["UNSPECIFIED"] = 0] = "UNSPECIFIED";
    /**
     * @generated from protobuf enum value: CALL_ENDED_REASON_ENDED = 1;
     */
    CallEndedReason[CallEndedReason["ENDED"] = 1] = "ENDED";
    /**
     * @generated from protobuf enum value: CALL_ENDED_REASON_LIVE_ENDED = 2;
     */
    CallEndedReason[CallEndedReason["LIVE_ENDED"] = 2] = "LIVE_ENDED";
    /**
     * @generated from protobuf enum value: CALL_ENDED_REASON_KICKED = 3;
     */
    CallEndedReason[CallEndedReason["KICKED"] = 3] = "KICKED";
    /**
     * @generated from protobuf enum value: CALL_ENDED_REASON_SESSION_ENDED = 4;
     */
    CallEndedReason[CallEndedReason["SESSION_ENDED"] = 4] = "SESSION_ENDED";
})(CallEndedReason || (CallEndedReason = {}));
/**
 * WebsocketReconnectStrategy defines the ws strategies available for handling reconnections.
 *
 * @generated from protobuf enum stream.video.sfu.models.WebsocketReconnectStrategy
 */
var WebsocketReconnectStrategy;
(function (WebsocketReconnectStrategy) {
    /**
     * @generated from protobuf enum value: WEBSOCKET_RECONNECT_STRATEGY_UNSPECIFIED = 0;
     */
    WebsocketReconnectStrategy[WebsocketReconnectStrategy["UNSPECIFIED"] = 0] = "UNSPECIFIED";
    /**
     * Sent after reaching the maximum reconnection attempts, or any other unrecoverable error leading to permanent disconnect.
     *
     * @generated from protobuf enum value: WEBSOCKET_RECONNECT_STRATEGY_DISCONNECT = 1;
     */
    WebsocketReconnectStrategy[WebsocketReconnectStrategy["DISCONNECT"] = 1] = "DISCONNECT";
    /**
     * SDK should maintaining existing publisher/subscriber pc instances
     * and establish a new WebSocket connection.
     *
     * @generated from protobuf enum value: WEBSOCKET_RECONNECT_STRATEGY_FAST = 2;
     */
    WebsocketReconnectStrategy[WebsocketReconnectStrategy["FAST"] = 2] = "FAST";
    /**
     * SDK should obtain new credentials from the coordinator, drops existing pc instances, set a new session_id and initializes
     * a completely new WebSocket connection, ensuring a comprehensive reset.
     *
     * @generated from protobuf enum value: WEBSOCKET_RECONNECT_STRATEGY_REJOIN = 3;
     */
    WebsocketReconnectStrategy[WebsocketReconnectStrategy["REJOIN"] = 3] = "REJOIN";
    /**
     * SDK should migrate to a new SFU instance
     *
     * @generated from protobuf enum value: WEBSOCKET_RECONNECT_STRATEGY_MIGRATE = 4;
     */
    WebsocketReconnectStrategy[WebsocketReconnectStrategy["MIGRATE"] = 4] = "MIGRATE";
})(WebsocketReconnectStrategy || (WebsocketReconnectStrategy = {}));
/**
 * AndroidThermalState is reported by the Android API. The full list of values is documented here
 * https://developer.android.com/reference/android/os/PowerManager.html#getCurrentThermalStatus()
 *
 * @generated from protobuf enum stream.video.sfu.models.AndroidThermalState
 */
var AndroidThermalState;
(function (AndroidThermalState) {
    /**
     * @generated from protobuf enum value: ANDROID_THERMAL_STATE_UNSPECIFIED = 0;
     */
    AndroidThermalState[AndroidThermalState["UNSPECIFIED"] = 0] = "UNSPECIFIED";
    /**
     * @generated from protobuf enum value: ANDROID_THERMAL_STATE_NONE = 1;
     */
    AndroidThermalState[AndroidThermalState["NONE"] = 1] = "NONE";
    /**
     * @generated from protobuf enum value: ANDROID_THERMAL_STATE_LIGHT = 2;
     */
    AndroidThermalState[AndroidThermalState["LIGHT"] = 2] = "LIGHT";
    /**
     * @generated from protobuf enum value: ANDROID_THERMAL_STATE_MODERATE = 3;
     */
    AndroidThermalState[AndroidThermalState["MODERATE"] = 3] = "MODERATE";
    /**
     * @generated from protobuf enum value: ANDROID_THERMAL_STATE_SEVERE = 4;
     */
    AndroidThermalState[AndroidThermalState["SEVERE"] = 4] = "SEVERE";
    /**
     * @generated from protobuf enum value: ANDROID_THERMAL_STATE_CRITICAL = 5;
     */
    AndroidThermalState[AndroidThermalState["CRITICAL"] = 5] = "CRITICAL";
    /**
     * @generated from protobuf enum value: ANDROID_THERMAL_STATE_EMERGENCY = 6;
     */
    AndroidThermalState[AndroidThermalState["EMERGENCY"] = 6] = "EMERGENCY";
    /**
     * @generated from protobuf enum value: ANDROID_THERMAL_STATE_SHUTDOWN = 7;
     */
    AndroidThermalState[AndroidThermalState["SHUTDOWN"] = 7] = "SHUTDOWN";
})(AndroidThermalState || (AndroidThermalState = {}));
/**
 * AppleThermalState is the thermal state as reported by Apple devices when available or applicable to the platform.
 * The full list of states (enum) is available here: https://developer.apple.com/documentation/foundation/processinfo/thermalstate
 *
 * @generated from protobuf enum stream.video.sfu.models.AppleThermalState
 */
var AppleThermalState;
(function (AppleThermalState) {
    /**
     * @generated from protobuf enum value: APPLE_THERMAL_STATE_UNSPECIFIED = 0;
     */
    AppleThermalState[AppleThermalState["UNSPECIFIED"] = 0] = "UNSPECIFIED";
    /**
     * @generated from protobuf enum value: APPLE_THERMAL_STATE_NOMINAL = 1;
     */
    AppleThermalState[AppleThermalState["NOMINAL"] = 1] = "NOMINAL";
    /**
     * @generated from protobuf enum value: APPLE_THERMAL_STATE_FAIR = 2;
     */
    AppleThermalState[AppleThermalState["FAIR"] = 2] = "FAIR";
    /**
     * @generated from protobuf enum value: APPLE_THERMAL_STATE_SERIOUS = 3;
     */
    AppleThermalState[AppleThermalState["SERIOUS"] = 3] = "SERIOUS";
    /**
     * @generated from protobuf enum value: APPLE_THERMAL_STATE_CRITICAL = 4;
     */
    AppleThermalState[AppleThermalState["CRITICAL"] = 4] = "CRITICAL";
})(AppleThermalState || (AppleThermalState = {}));
// @generated message type with reflection information, may provide speed optimized methods
class CallState$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.CallState', [
            {
                no: 1,
                name: 'participants',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => Participant,
            },
            { no: 2, name: 'started_at', kind: 'message', T: () => Timestamp },
            {
                no: 3,
                name: 'participant_count',
                kind: 'message',
                T: () => ParticipantCount,
            },
            {
                no: 4,
                name: 'pins',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => Pin,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.CallState
 */
const CallState$1 = new CallState$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ParticipantCount$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.ParticipantCount', [
            { no: 1, name: 'total', kind: 'scalar', T: 13 /*ScalarType.UINT32*/ },
            { no: 2, name: 'anonymous', kind: 'scalar', T: 13 /*ScalarType.UINT32*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.ParticipantCount
 */
const ParticipantCount = new ParticipantCount$Type();
// @generated message type with reflection information, may provide speed optimized methods
class Pin$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.Pin', [
            { no: 1, name: 'user_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.Pin
 */
const Pin = new Pin$Type();
// @generated message type with reflection information, may provide speed optimized methods
class Participant$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.Participant', [
            { no: 1, name: 'user_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 3,
                name: 'published_tracks',
                kind: 'enum',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => [
                    'stream.video.sfu.models.TrackType',
                    TrackType,
                    'TRACK_TYPE_',
                ],
            },
            { no: 4, name: 'joined_at', kind: 'message', T: () => Timestamp },
            {
                no: 5,
                name: 'track_lookup_prefix',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            {
                no: 6,
                name: 'connection_quality',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.ConnectionQuality',
                    ConnectionQuality,
                    'CONNECTION_QUALITY_',
                ],
            },
            { no: 7, name: 'is_speaking', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
            {
                no: 8,
                name: 'is_dominant_speaker',
                kind: 'scalar',
                T: 8 /*ScalarType.BOOL*/,
            },
            { no: 9, name: 'audio_level', kind: 'scalar', T: 2 /*ScalarType.FLOAT*/ },
            { no: 10, name: 'name', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 11, name: 'image', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 12, name: 'custom', kind: 'message', T: () => Struct },
            {
                no: 13,
                name: 'roles',
                kind: 'scalar',
                repeat: 2 /*RepeatType.UNPACKED*/,
                T: 9 /*ScalarType.STRING*/,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.Participant
 */
const Participant = new Participant$Type();
// @generated message type with reflection information, may provide speed optimized methods
class StreamQuality$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.StreamQuality', [
            {
                no: 1,
                name: 'video_quality',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.VideoQuality',
                    VideoQuality,
                    'VIDEO_QUALITY_',
                ],
            },
            { no: 2, name: 'user_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.StreamQuality
 */
const StreamQuality = new StreamQuality$Type();
// @generated message type with reflection information, may provide speed optimized methods
class VideoDimension$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.VideoDimension', [
            { no: 1, name: 'width', kind: 'scalar', T: 13 /*ScalarType.UINT32*/ },
            { no: 2, name: 'height', kind: 'scalar', T: 13 /*ScalarType.UINT32*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.VideoDimension
 */
const VideoDimension = new VideoDimension$Type();
// @generated message type with reflection information, may provide speed optimized methods
class VideoLayer$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.VideoLayer', [
            { no: 1, name: 'rid', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 2,
                name: 'video_dimension',
                kind: 'message',
                T: () => VideoDimension,
            },
            { no: 4, name: 'bitrate', kind: 'scalar', T: 13 /*ScalarType.UINT32*/ },
            { no: 5, name: 'fps', kind: 'scalar', T: 13 /*ScalarType.UINT32*/ },
            {
                no: 6,
                name: 'quality',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.VideoQuality',
                    VideoQuality,
                    'VIDEO_QUALITY_',
                ],
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.VideoLayer
 */
const VideoLayer = new VideoLayer$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SubscribeOption$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.SubscribeOption', [
            {
                no: 1,
                name: 'track_type',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.TrackType',
                    TrackType,
                    'TRACK_TYPE_',
                ],
            },
            {
                no: 2,
                name: 'codecs',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => Codec,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.SubscribeOption
 */
const SubscribeOption = new SubscribeOption$Type();
// @generated message type with reflection information, may provide speed optimized methods
class PublishOption$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.PublishOption', [
            {
                no: 1,
                name: 'track_type',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.TrackType',
                    TrackType,
                    'TRACK_TYPE_',
                ],
            },
            { no: 2, name: 'codec', kind: 'message', T: () => Codec },
            { no: 3, name: 'bitrate', kind: 'scalar', T: 5 /*ScalarType.INT32*/ },
            { no: 4, name: 'fps', kind: 'scalar', T: 5 /*ScalarType.INT32*/ },
            {
                no: 5,
                name: 'max_spatial_layers',
                kind: 'scalar',
                T: 5 /*ScalarType.INT32*/,
            },
            {
                no: 6,
                name: 'max_temporal_layers',
                kind: 'scalar',
                T: 5 /*ScalarType.INT32*/,
            },
            {
                no: 7,
                name: 'video_dimension',
                kind: 'message',
                T: () => VideoDimension,
            },
            { no: 8, name: 'id', kind: 'scalar', T: 5 /*ScalarType.INT32*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.PublishOption
 */
const PublishOption = new PublishOption$Type();
// @generated message type with reflection information, may provide speed optimized methods
class Codec$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.Codec', [
            {
                no: 16,
                name: 'payload_type',
                kind: 'scalar',
                T: 13 /*ScalarType.UINT32*/,
            },
            { no: 10, name: 'name', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 14,
                name: 'clock_rate',
                kind: 'scalar',
                T: 13 /*ScalarType.UINT32*/,
            },
            {
                no: 15,
                name: 'encoding_parameters',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            { no: 12, name: 'fmtp', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.Codec
 */
const Codec = new Codec$Type();
// @generated message type with reflection information, may provide speed optimized methods
let ICETrickle$Type$1 = class ICETrickle$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.ICETrickle', [
            {
                no: 1,
                name: 'peer_type',
                kind: 'enum',
                T: () => ['stream.video.sfu.models.PeerType', PeerType, 'PEER_TYPE_'],
            },
            {
                no: 2,
                name: 'ice_candidate',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            { no: 3, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
};
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.ICETrickle
 */
const ICETrickle$1 = new ICETrickle$Type$1();
// @generated message type with reflection information, may provide speed optimized methods
class TrackInfo$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.TrackInfo', [
            { no: 1, name: 'track_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 2,
                name: 'track_type',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.TrackType',
                    TrackType,
                    'TRACK_TYPE_',
                ],
            },
            {
                no: 5,
                name: 'layers',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => VideoLayer,
            },
            { no: 6, name: 'mid', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 7, name: 'dtx', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
            { no: 8, name: 'stereo', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
            { no: 9, name: 'red', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
            { no: 10, name: 'muted', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
            { no: 11, name: 'codec', kind: 'message', T: () => Codec },
            {
                no: 12,
                name: 'publish_option_id',
                kind: 'scalar',
                T: 5 /*ScalarType.INT32*/,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.TrackInfo
 */
const TrackInfo = new TrackInfo$Type();
// @generated message type with reflection information, may provide speed optimized methods
let Error$Type$1 = class Error$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.Error', [
            {
                no: 1,
                name: 'code',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.ErrorCode',
                    ErrorCode,
                    'ERROR_CODE_',
                ],
            },
            { no: 2, name: 'message', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 3, name: 'should_retry', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
        ]);
    }
};
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.Error
 */
const Error$2 = new Error$Type$1();
// @generated message type with reflection information, may provide speed optimized methods
class ClientDetails$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.ClientDetails', [
            { no: 1, name: 'sdk', kind: 'message', T: () => Sdk },
            { no: 2, name: 'os', kind: 'message', T: () => OS },
            { no: 3, name: 'browser', kind: 'message', T: () => Browser },
            { no: 4, name: 'device', kind: 'message', T: () => Device },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.ClientDetails
 */
const ClientDetails = new ClientDetails$Type();
// @generated message type with reflection information, may provide speed optimized methods
class Sdk$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.Sdk', [
            {
                no: 1,
                name: 'type',
                kind: 'enum',
                T: () => ['stream.video.sfu.models.SdkType', SdkType, 'SDK_TYPE_'],
            },
            { no: 2, name: 'major', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 3, name: 'minor', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 4, name: 'patch', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.Sdk
 */
const Sdk = new Sdk$Type();
// @generated message type with reflection information, may provide speed optimized methods
class OS$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.OS', [
            { no: 1, name: 'name', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'version', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 3,
                name: 'architecture',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.OS
 */
const OS = new OS$Type();
// @generated message type with reflection information, may provide speed optimized methods
class Browser$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.Browser', [
            { no: 1, name: 'name', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'version', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.Browser
 */
const Browser = new Browser$Type();
// @generated message type with reflection information, may provide speed optimized methods
class RTMPIngress$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.RTMPIngress', [
            { no: 1, name: 'width', kind: 'scalar', T: 13 /*ScalarType.UINT32*/ },
            { no: 2, name: 'height', kind: 'scalar', T: 13 /*ScalarType.UINT32*/ },
            { no: 3, name: 'frame_rate', kind: 'scalar', T: 1 /*ScalarType.DOUBLE*/ },
            { no: 4, name: 'software', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 5, name: 'version', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 6, name: 'encoder', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 7,
                name: 'remote_addr',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.RTMPIngress
 */
const RTMPIngress = new RTMPIngress$Type();
// @generated message type with reflection information, may provide speed optimized methods
class Device$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.Device', [
            { no: 1, name: 'name', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'version', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.Device
 */
const Device = new Device$Type();
// @generated message type with reflection information, may provide speed optimized methods
class Call$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.Call', [
            { no: 1, name: 'type', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 3,
                name: 'created_by_user_id',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            {
                no: 4,
                name: 'host_user_id',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            { no: 5, name: 'custom', kind: 'message', T: () => Struct },
            { no: 6, name: 'created_at', kind: 'message', T: () => Timestamp },
            { no: 7, name: 'updated_at', kind: 'message', T: () => Timestamp },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.Call
 */
const Call$1 = new Call$Type();
// @generated message type with reflection information, may provide speed optimized methods
class CallGrants$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.CallGrants', [
            {
                no: 1,
                name: 'can_publish_audio',
                kind: 'scalar',
                T: 8 /*ScalarType.BOOL*/,
            },
            {
                no: 2,
                name: 'can_publish_video',
                kind: 'scalar',
                T: 8 /*ScalarType.BOOL*/,
            },
            {
                no: 3,
                name: 'can_screenshare',
                kind: 'scalar',
                T: 8 /*ScalarType.BOOL*/,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.CallGrants
 */
const CallGrants = new CallGrants$Type();
// @generated message type with reflection information, may provide speed optimized methods
class InputDevices$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.InputDevices', [
            {
                no: 1,
                name: 'available_devices',
                kind: 'scalar',
                repeat: 2 /*RepeatType.UNPACKED*/,
                T: 9 /*ScalarType.STRING*/,
            },
            {
                no: 2,
                name: 'current_device',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            { no: 3, name: 'is_permitted', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.InputDevices
 */
const InputDevices = new InputDevices$Type();
// @generated message type with reflection information, may provide speed optimized methods
class AndroidState$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.AndroidState', [
            {
                no: 1,
                name: 'thermal_state',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.AndroidThermalState',
                    AndroidThermalState,
                    'ANDROID_THERMAL_STATE_',
                ],
            },
            {
                no: 2,
                name: 'is_power_saver_mode',
                kind: 'scalar',
                T: 8 /*ScalarType.BOOL*/,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.AndroidState
 */
const AndroidState = new AndroidState$Type();
// @generated message type with reflection information, may provide speed optimized methods
class AppleState$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.models.AppleState', [
            {
                no: 1,
                name: 'thermal_state',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.AppleThermalState',
                    AppleThermalState,
                    'APPLE_THERMAL_STATE_',
                ],
            },
            {
                no: 2,
                name: 'is_low_power_mode_enabled',
                kind: 'scalar',
                T: 8 /*ScalarType.BOOL*/,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.models.AppleState
 */
const AppleState = new AppleState$Type();

var models = /*#__PURE__*/Object.freeze({
    __proto__: null,
    AndroidState: AndroidState,
    get AndroidThermalState () { return AndroidThermalState; },
    AppleState: AppleState,
    get AppleThermalState () { return AppleThermalState; },
    Browser: Browser,
    Call: Call$1,
    get CallEndedReason () { return CallEndedReason; },
    CallGrants: CallGrants,
    CallState: CallState$1,
    ClientDetails: ClientDetails,
    Codec: Codec,
    get ConnectionQuality () { return ConnectionQuality; },
    Device: Device,
    Error: Error$2,
    get ErrorCode () { return ErrorCode; },
    get GoAwayReason () { return GoAwayReason; },
    ICETrickle: ICETrickle$1,
    InputDevices: InputDevices,
    OS: OS,
    Participant: Participant,
    ParticipantCount: ParticipantCount,
    get PeerType () { return PeerType; },
    Pin: Pin,
    PublishOption: PublishOption,
    RTMPIngress: RTMPIngress,
    Sdk: Sdk,
    get SdkType () { return SdkType; },
    StreamQuality: StreamQuality,
    SubscribeOption: SubscribeOption,
    TrackInfo: TrackInfo,
    get TrackType () { return TrackType; },
    get TrackUnpublishReason () { return TrackUnpublishReason; },
    VideoDimension: VideoDimension,
    VideoLayer: VideoLayer,
    get VideoQuality () { return VideoQuality; },
    get WebsocketReconnectStrategy () { return WebsocketReconnectStrategy; }
});

// @generated by protobuf-ts 2.9.6 with parameter long_type_string,client_generic,server_none,eslint_disable,optimize_code_size
// @generated from protobuf file "video/sfu/signal_rpc/signal.proto" (package "stream.video.sfu.signal", syntax proto3)
// tslint:disable
// @generated message type with reflection information, may provide speed optimized methods
class StartNoiseCancellationRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.StartNoiseCancellationRequest', [
            { no: 1, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.StartNoiseCancellationRequest
 */
const StartNoiseCancellationRequest = new StartNoiseCancellationRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class StartNoiseCancellationResponse$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.StartNoiseCancellationResponse', [
            { no: 1, name: 'error', kind: 'message', T: () => Error$2 },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.StartNoiseCancellationResponse
 */
const StartNoiseCancellationResponse = new StartNoiseCancellationResponse$Type();
// @generated message type with reflection information, may provide speed optimized methods
class StopNoiseCancellationRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.StopNoiseCancellationRequest', [
            { no: 1, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.StopNoiseCancellationRequest
 */
const StopNoiseCancellationRequest = new StopNoiseCancellationRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class StopNoiseCancellationResponse$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.StopNoiseCancellationResponse', [
            { no: 1, name: 'error', kind: 'message', T: () => Error$2 },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.StopNoiseCancellationResponse
 */
const StopNoiseCancellationResponse = new StopNoiseCancellationResponse$Type();
// @generated message type with reflection information, may provide speed optimized methods
class Reconnection$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.Reconnection', [
            {
                no: 1,
                name: 'time_seconds',
                kind: 'scalar',
                T: 2 /*ScalarType.FLOAT*/,
            },
            {
                no: 2,
                name: 'strategy',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.WebsocketReconnectStrategy',
                    WebsocketReconnectStrategy,
                    'WEBSOCKET_RECONNECT_STRATEGY_',
                ],
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.Reconnection
 */
const Reconnection = new Reconnection$Type();
// @generated message type with reflection information, may provide speed optimized methods
class Telemetry$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.Telemetry', [
            {
                no: 1,
                name: 'connection_time_seconds',
                kind: 'scalar',
                oneof: 'data',
                T: 2 /*ScalarType.FLOAT*/,
            },
            {
                no: 2,
                name: 'reconnection',
                kind: 'message',
                oneof: 'data',
                T: () => Reconnection,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.Telemetry
 */
const Telemetry = new Telemetry$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SendStatsRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.SendStatsRequest', [
            { no: 1, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 2,
                name: 'subscriber_stats',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            {
                no: 3,
                name: 'publisher_stats',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            {
                no: 4,
                name: 'webrtc_version',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            { no: 5, name: 'sdk', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 6,
                name: 'sdk_version',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            { no: 7, name: 'audio_devices', kind: 'message', T: () => InputDevices },
            { no: 8, name: 'video_devices', kind: 'message', T: () => InputDevices },
            {
                no: 9,
                name: 'android',
                kind: 'message',
                oneof: 'deviceState',
                T: () => AndroidState,
            },
            {
                no: 10,
                name: 'apple',
                kind: 'message',
                oneof: 'deviceState',
                T: () => AppleState,
            },
            { no: 11, name: 'telemetry', kind: 'message', T: () => Telemetry },
            { no: 12, name: 'rtmp', kind: 'message', T: () => RTMPIngress },
            {
                no: 13,
                name: 'subscriber_rtc_stats',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            {
                no: 14,
                name: 'publisher_rtc_stats',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.SendStatsRequest
 */
const SendStatsRequest = new SendStatsRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SendStatsResponse$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.SendStatsResponse', [
            { no: 1, name: 'error', kind: 'message', T: () => Error$2 },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.SendStatsResponse
 */
const SendStatsResponse = new SendStatsResponse$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ICERestartRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.ICERestartRequest', [
            { no: 1, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 2,
                name: 'peer_type',
                kind: 'enum',
                T: () => ['stream.video.sfu.models.PeerType', PeerType, 'PEER_TYPE_'],
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.ICERestartRequest
 */
const ICERestartRequest = new ICERestartRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ICERestartResponse$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.ICERestartResponse', [
            { no: 1, name: 'error', kind: 'message', T: () => Error$2 },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.ICERestartResponse
 */
const ICERestartResponse = new ICERestartResponse$Type();
// @generated message type with reflection information, may provide speed optimized methods
class UpdateMuteStatesRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.UpdateMuteStatesRequest', [
            { no: 1, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 3,
                name: 'mute_states',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => TrackMuteState,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.UpdateMuteStatesRequest
 */
const UpdateMuteStatesRequest = new UpdateMuteStatesRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class UpdateMuteStatesResponse$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.UpdateMuteStatesResponse', [
            { no: 4, name: 'error', kind: 'message', T: () => Error$2 },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.UpdateMuteStatesResponse
 */
const UpdateMuteStatesResponse = new UpdateMuteStatesResponse$Type();
// @generated message type with reflection information, may provide speed optimized methods
class TrackMuteState$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.TrackMuteState', [
            {
                no: 1,
                name: 'track_type',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.TrackType',
                    TrackType,
                    'TRACK_TYPE_',
                ],
            },
            { no: 2, name: 'muted', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.TrackMuteState
 */
const TrackMuteState = new TrackMuteState$Type();
// @generated message type with reflection information, may provide speed optimized methods
class AudioMuteChanged$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.AudioMuteChanged', [
            { no: 1, name: 'muted', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.AudioMuteChanged
 */
new AudioMuteChanged$Type();
// @generated message type with reflection information, may provide speed optimized methods
class VideoMuteChanged$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.VideoMuteChanged', [
            { no: 2, name: 'muted', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.VideoMuteChanged
 */
new VideoMuteChanged$Type();
// @generated message type with reflection information, may provide speed optimized methods
class UpdateSubscriptionsRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.UpdateSubscriptionsRequest', [
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 3,
                name: 'tracks',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => TrackSubscriptionDetails,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.UpdateSubscriptionsRequest
 */
const UpdateSubscriptionsRequest = new UpdateSubscriptionsRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class UpdateSubscriptionsResponse$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.UpdateSubscriptionsResponse', [
            { no: 4, name: 'error', kind: 'message', T: () => Error$2 },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.UpdateSubscriptionsResponse
 */
const UpdateSubscriptionsResponse = new UpdateSubscriptionsResponse$Type();
// @generated message type with reflection information, may provide speed optimized methods
class TrackSubscriptionDetails$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.TrackSubscriptionDetails', [
            { no: 1, name: 'user_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 3,
                name: 'track_type',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.TrackType',
                    TrackType,
                    'TRACK_TYPE_',
                ],
            },
            { no: 4, name: 'dimension', kind: 'message', T: () => VideoDimension },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.TrackSubscriptionDetails
 */
const TrackSubscriptionDetails = new TrackSubscriptionDetails$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SendAnswerRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.SendAnswerRequest', [
            {
                no: 1,
                name: 'peer_type',
                kind: 'enum',
                T: () => ['stream.video.sfu.models.PeerType', PeerType, 'PEER_TYPE_'],
            },
            { no: 2, name: 'sdp', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 3, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.SendAnswerRequest
 */
const SendAnswerRequest = new SendAnswerRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SendAnswerResponse$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.SendAnswerResponse', [
            { no: 4, name: 'error', kind: 'message', T: () => Error$2 },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.SendAnswerResponse
 */
const SendAnswerResponse = new SendAnswerResponse$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ICETrickleResponse$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.ICETrickleResponse', [
            { no: 4, name: 'error', kind: 'message', T: () => Error$2 },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.ICETrickleResponse
 */
const ICETrickleResponse = new ICETrickleResponse$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SetPublisherRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.SetPublisherRequest', [
            { no: 1, name: 'sdp', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 3,
                name: 'tracks',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => TrackInfo,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.SetPublisherRequest
 */
const SetPublisherRequest = new SetPublisherRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SetPublisherResponse$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.signal.SetPublisherResponse', [
            { no: 1, name: 'sdp', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 3, name: 'ice_restart', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
            { no: 4, name: 'error', kind: 'message', T: () => Error$2 },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.signal.SetPublisherResponse
 */
const SetPublisherResponse = new SetPublisherResponse$Type();
/**
 * @generated ServiceType for protobuf service stream.video.sfu.signal.SignalServer
 */
const SignalServer = new runtimeRpc.ServiceType('stream.video.sfu.signal.SignalServer', [
    {
        name: 'SetPublisher',
        options: {},
        I: SetPublisherRequest,
        O: SetPublisherResponse,
    },
    {
        name: 'SendAnswer',
        options: {},
        I: SendAnswerRequest,
        O: SendAnswerResponse,
    },
    { name: 'IceTrickle', options: {}, I: ICETrickle$1, O: ICETrickleResponse },
    {
        name: 'UpdateSubscriptions',
        options: {},
        I: UpdateSubscriptionsRequest,
        O: UpdateSubscriptionsResponse,
    },
    {
        name: 'UpdateMuteStates',
        options: {},
        I: UpdateMuteStatesRequest,
        O: UpdateMuteStatesResponse,
    },
    {
        name: 'IceRestart',
        options: {},
        I: ICERestartRequest,
        O: ICERestartResponse,
    },
    {
        name: 'SendStats',
        options: {},
        I: SendStatsRequest,
        O: SendStatsResponse,
    },
    {
        name: 'StartNoiseCancellation',
        options: {},
        I: StartNoiseCancellationRequest,
        O: StartNoiseCancellationResponse,
    },
    {
        name: 'StopNoiseCancellation',
        options: {},
        I: StopNoiseCancellationRequest,
        O: StopNoiseCancellationResponse,
    },
]);

// @generated by protobuf-ts 2.9.6 with parameter long_type_string,client_generic,server_none,eslint_disable,optimize_code_size
// @generated from protobuf file "video/sfu/event/events.proto" (package "stream.video.sfu.event", syntax proto3)
// tslint:disable
// @generated message type with reflection information, may provide speed optimized methods
class SfuEvent$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.SfuEvent', [
            {
                no: 1,
                name: 'subscriber_offer',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => SubscriberOffer,
            },
            {
                no: 2,
                name: 'publisher_answer',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => PublisherAnswer,
            },
            {
                no: 3,
                name: 'connection_quality_changed',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => ConnectionQualityChanged,
            },
            {
                no: 4,
                name: 'audio_level_changed',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => AudioLevelChanged,
            },
            {
                no: 5,
                name: 'ice_trickle',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => ICETrickle$1,
            },
            {
                no: 6,
                name: 'change_publish_quality',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => ChangePublishQuality,
            },
            {
                no: 10,
                name: 'participant_joined',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => ParticipantJoined,
            },
            {
                no: 11,
                name: 'participant_left',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => ParticipantLeft,
            },
            {
                no: 12,
                name: 'dominant_speaker_changed',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => DominantSpeakerChanged,
            },
            {
                no: 13,
                name: 'join_response',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => JoinResponse,
            },
            {
                no: 14,
                name: 'health_check_response',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => HealthCheckResponse,
            },
            {
                no: 16,
                name: 'track_published',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => TrackPublished,
            },
            {
                no: 17,
                name: 'track_unpublished',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => TrackUnpublished,
            },
            {
                no: 18,
                name: 'error',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => Error$1,
            },
            {
                no: 19,
                name: 'call_grants_updated',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => CallGrantsUpdated,
            },
            {
                no: 20,
                name: 'go_away',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => GoAway,
            },
            {
                no: 21,
                name: 'ice_restart',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => ICERestart,
            },
            {
                no: 22,
                name: 'pins_updated',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => PinsChanged,
            },
            {
                no: 23,
                name: 'call_ended',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => CallEnded,
            },
            {
                no: 24,
                name: 'participant_updated',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => ParticipantUpdated,
            },
            {
                no: 25,
                name: 'participant_migration_complete',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => ParticipantMigrationComplete,
            },
            {
                no: 27,
                name: 'change_publish_options',
                kind: 'message',
                oneof: 'eventPayload',
                T: () => ChangePublishOptions,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.SfuEvent
 */
const SfuEvent = new SfuEvent$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ChangePublishOptions$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.ChangePublishOptions', [
            {
                no: 1,
                name: 'publish_options',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => PublishOption,
            },
            { no: 2, name: 'reason', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.ChangePublishOptions
 */
const ChangePublishOptions = new ChangePublishOptions$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ChangePublishOptionsComplete$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.ChangePublishOptionsComplete', []);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.ChangePublishOptionsComplete
 */
const ChangePublishOptionsComplete = new ChangePublishOptionsComplete$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ParticipantMigrationComplete$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.ParticipantMigrationComplete', []);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.ParticipantMigrationComplete
 */
const ParticipantMigrationComplete = new ParticipantMigrationComplete$Type();
// @generated message type with reflection information, may provide speed optimized methods
class PinsChanged$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.PinsChanged', [
            {
                no: 1,
                name: 'pins',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => Pin,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.PinsChanged
 */
const PinsChanged = new PinsChanged$Type();
// @generated message type with reflection information, may provide speed optimized methods
class Error$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.Error', [
            { no: 4, name: 'error', kind: 'message', T: () => Error$2 },
            {
                no: 5,
                name: 'reconnect_strategy',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.WebsocketReconnectStrategy',
                    WebsocketReconnectStrategy,
                    'WEBSOCKET_RECONNECT_STRATEGY_',
                ],
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.Error
 */
const Error$1 = new Error$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ICETrickle$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.ICETrickle', [
            {
                no: 1,
                name: 'peer_type',
                kind: 'enum',
                T: () => ['stream.video.sfu.models.PeerType', PeerType, 'PEER_TYPE_'],
            },
            {
                no: 2,
                name: 'ice_candidate',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.ICETrickle
 */
const ICETrickle = new ICETrickle$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ICERestart$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.ICERestart', [
            {
                no: 1,
                name: 'peer_type',
                kind: 'enum',
                T: () => ['stream.video.sfu.models.PeerType', PeerType, 'PEER_TYPE_'],
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.ICERestart
 */
const ICERestart = new ICERestart$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SfuRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.SfuRequest', [
            {
                no: 1,
                name: 'join_request',
                kind: 'message',
                oneof: 'requestPayload',
                T: () => JoinRequest,
            },
            {
                no: 2,
                name: 'health_check_request',
                kind: 'message',
                oneof: 'requestPayload',
                T: () => HealthCheckRequest,
            },
            {
                no: 3,
                name: 'leave_call_request',
                kind: 'message',
                oneof: 'requestPayload',
                T: () => LeaveCallRequest,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.SfuRequest
 */
const SfuRequest = new SfuRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class LeaveCallRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.LeaveCallRequest', [
            { no: 1, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'reason', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.LeaveCallRequest
 */
const LeaveCallRequest = new LeaveCallRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class HealthCheckRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.HealthCheckRequest', []);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.HealthCheckRequest
 */
const HealthCheckRequest = new HealthCheckRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class HealthCheckResponse$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.HealthCheckResponse', [
            {
                no: 1,
                name: 'participant_count',
                kind: 'message',
                T: () => ParticipantCount,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.HealthCheckResponse
 */
const HealthCheckResponse = new HealthCheckResponse$Type();
// @generated message type with reflection information, may provide speed optimized methods
class TrackPublished$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.TrackPublished', [
            { no: 1, name: 'user_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 3,
                name: 'type',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.TrackType',
                    TrackType,
                    'TRACK_TYPE_',
                ],
            },
            { no: 4, name: 'participant', kind: 'message', T: () => Participant },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.TrackPublished
 */
const TrackPublished = new TrackPublished$Type();
// @generated message type with reflection information, may provide speed optimized methods
class TrackUnpublished$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.TrackUnpublished', [
            { no: 1, name: 'user_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 3,
                name: 'type',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.TrackType',
                    TrackType,
                    'TRACK_TYPE_',
                ],
            },
            {
                no: 4,
                name: 'cause',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.TrackUnpublishReason',
                    TrackUnpublishReason,
                    'TRACK_UNPUBLISH_REASON_',
                ],
            },
            { no: 5, name: 'participant', kind: 'message', T: () => Participant },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.TrackUnpublished
 */
const TrackUnpublished = new TrackUnpublished$Type();
// @generated message type with reflection information, may provide speed optimized methods
class JoinRequest$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.JoinRequest', [
            { no: 1, name: 'token', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 3,
                name: 'subscriber_sdp',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            {
                no: 8,
                name: 'publisher_sdp',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            {
                no: 4,
                name: 'client_details',
                kind: 'message',
                T: () => ClientDetails,
            },
            { no: 5, name: 'migration', kind: 'message', T: () => Migration },
            {
                no: 6,
                name: 'fast_reconnect',
                kind: 'scalar',
                T: 8 /*ScalarType.BOOL*/,
            },
            {
                no: 7,
                name: 'reconnect_details',
                kind: 'message',
                T: () => ReconnectDetails,
            },
            {
                no: 9,
                name: 'preferred_publish_options',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => PublishOption,
            },
            {
                no: 10,
                name: 'preferred_subscribe_options',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => SubscribeOption,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.JoinRequest
 */
const JoinRequest = new JoinRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ReconnectDetails$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.ReconnectDetails', [
            {
                no: 1,
                name: 'strategy',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.WebsocketReconnectStrategy',
                    WebsocketReconnectStrategy,
                    'WEBSOCKET_RECONNECT_STRATEGY_',
                ],
            },
            {
                no: 3,
                name: 'announced_tracks',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => TrackInfo,
            },
            {
                no: 4,
                name: 'subscriptions',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => TrackSubscriptionDetails,
            },
            {
                no: 5,
                name: 'reconnect_attempt',
                kind: 'scalar',
                T: 13 /*ScalarType.UINT32*/,
            },
            {
                no: 6,
                name: 'from_sfu_id',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            {
                no: 7,
                name: 'previous_session_id',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            { no: 8, name: 'reason', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.ReconnectDetails
 */
const ReconnectDetails = new ReconnectDetails$Type();
// @generated message type with reflection information, may provide speed optimized methods
class Migration$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.Migration', [
            {
                no: 1,
                name: 'from_sfu_id',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
            {
                no: 2,
                name: 'announced_tracks',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => TrackInfo,
            },
            {
                no: 3,
                name: 'subscriptions',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => TrackSubscriptionDetails,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.Migration
 */
const Migration = new Migration$Type();
// @generated message type with reflection information, may provide speed optimized methods
class JoinResponse$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.JoinResponse', [
            { no: 1, name: 'call_state', kind: 'message', T: () => CallState$1 },
            { no: 2, name: 'reconnected', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
            {
                no: 3,
                name: 'fast_reconnect_deadline_seconds',
                kind: 'scalar',
                T: 5 /*ScalarType.INT32*/,
            },
            {
                no: 4,
                name: 'publish_options',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => PublishOption,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.JoinResponse
 */
const JoinResponse = new JoinResponse$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ParticipantJoined$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.ParticipantJoined', [
            { no: 1, name: 'call_cid', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'participant', kind: 'message', T: () => Participant },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.ParticipantJoined
 */
const ParticipantJoined = new ParticipantJoined$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ParticipantLeft$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.ParticipantLeft', [
            { no: 1, name: 'call_cid', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'participant', kind: 'message', T: () => Participant },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.ParticipantLeft
 */
const ParticipantLeft = new ParticipantLeft$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ParticipantUpdated$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.ParticipantUpdated', [
            { no: 1, name: 'call_cid', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'participant', kind: 'message', T: () => Participant },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.ParticipantUpdated
 */
const ParticipantUpdated = new ParticipantUpdated$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SubscriberOffer$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.SubscriberOffer', [
            { no: 1, name: 'ice_restart', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
            { no: 2, name: 'sdp', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.SubscriberOffer
 */
const SubscriberOffer = new SubscriberOffer$Type();
// @generated message type with reflection information, may provide speed optimized methods
class PublisherAnswer$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.PublisherAnswer', [
            { no: 1, name: 'sdp', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.PublisherAnswer
 */
const PublisherAnswer = new PublisherAnswer$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ConnectionQualityChanged$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.ConnectionQualityChanged', [
            {
                no: 1,
                name: 'connection_quality_updates',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => ConnectionQualityInfo,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.ConnectionQualityChanged
 */
const ConnectionQualityChanged = new ConnectionQualityChanged$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ConnectionQualityInfo$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.ConnectionQualityInfo', [
            { no: 1, name: 'user_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            {
                no: 3,
                name: 'connection_quality',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.ConnectionQuality',
                    ConnectionQuality,
                    'CONNECTION_QUALITY_',
                ],
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.ConnectionQualityInfo
 */
const ConnectionQualityInfo = new ConnectionQualityInfo$Type();
// @generated message type with reflection information, may provide speed optimized methods
class DominantSpeakerChanged$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.DominantSpeakerChanged', [
            { no: 1, name: 'user_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.DominantSpeakerChanged
 */
const DominantSpeakerChanged = new DominantSpeakerChanged$Type();
// @generated message type with reflection information, may provide speed optimized methods
class AudioLevel$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.AudioLevel', [
            { no: 1, name: 'user_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'session_id', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 3, name: 'level', kind: 'scalar', T: 2 /*ScalarType.FLOAT*/ },
            { no: 4, name: 'is_speaking', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.AudioLevel
 */
const AudioLevel = new AudioLevel$Type();
// @generated message type with reflection information, may provide speed optimized methods
class AudioLevelChanged$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.AudioLevelChanged', [
            {
                no: 1,
                name: 'audio_levels',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => AudioLevel,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.AudioLevelChanged
 */
const AudioLevelChanged = new AudioLevelChanged$Type();
// @generated message type with reflection information, may provide speed optimized methods
class AudioSender$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.AudioSender', [
            { no: 2, name: 'codec', kind: 'message', T: () => Codec },
            {
                no: 3,
                name: 'track_type',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.TrackType',
                    TrackType,
                    'TRACK_TYPE_',
                ],
            },
            {
                no: 4,
                name: 'publish_option_id',
                kind: 'scalar',
                T: 5 /*ScalarType.INT32*/,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.AudioSender
 */
const AudioSender = new AudioSender$Type();
// @generated message type with reflection information, may provide speed optimized methods
class VideoLayerSetting$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.VideoLayerSetting', [
            { no: 1, name: 'name', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: 'active', kind: 'scalar', T: 8 /*ScalarType.BOOL*/ },
            { no: 3, name: 'max_bitrate', kind: 'scalar', T: 5 /*ScalarType.INT32*/ },
            {
                no: 4,
                name: 'scale_resolution_down_by',
                kind: 'scalar',
                T: 2 /*ScalarType.FLOAT*/,
            },
            { no: 6, name: 'codec', kind: 'message', T: () => Codec },
            {
                no: 7,
                name: 'max_framerate',
                kind: 'scalar',
                T: 13 /*ScalarType.UINT32*/,
            },
            {
                no: 8,
                name: 'scalability_mode',
                kind: 'scalar',
                T: 9 /*ScalarType.STRING*/,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.VideoLayerSetting
 */
const VideoLayerSetting = new VideoLayerSetting$Type();
// @generated message type with reflection information, may provide speed optimized methods
class VideoSender$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.VideoSender', [
            { no: 2, name: 'codec', kind: 'message', T: () => Codec },
            {
                no: 3,
                name: 'layers',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => VideoLayerSetting,
            },
            {
                no: 4,
                name: 'track_type',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.TrackType',
                    TrackType,
                    'TRACK_TYPE_',
                ],
            },
            {
                no: 5,
                name: 'publish_option_id',
                kind: 'scalar',
                T: 5 /*ScalarType.INT32*/,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.VideoSender
 */
const VideoSender = new VideoSender$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ChangePublishQuality$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.ChangePublishQuality', [
            {
                no: 1,
                name: 'audio_senders',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => AudioSender,
            },
            {
                no: 2,
                name: 'video_senders',
                kind: 'message',
                repeat: 1 /*RepeatType.PACKED*/,
                T: () => VideoSender,
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.ChangePublishQuality
 */
const ChangePublishQuality = new ChangePublishQuality$Type();
// @generated message type with reflection information, may provide speed optimized methods
class CallGrantsUpdated$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.CallGrantsUpdated', [
            { no: 1, name: 'current_grants', kind: 'message', T: () => CallGrants },
            { no: 2, name: 'message', kind: 'scalar', T: 9 /*ScalarType.STRING*/ },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.CallGrantsUpdated
 */
const CallGrantsUpdated = new CallGrantsUpdated$Type();
// @generated message type with reflection information, may provide speed optimized methods
class GoAway$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.GoAway', [
            {
                no: 1,
                name: 'reason',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.GoAwayReason',
                    GoAwayReason,
                    'GO_AWAY_REASON_',
                ],
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.GoAway
 */
const GoAway = new GoAway$Type();
// @generated message type with reflection information, may provide speed optimized methods
class CallEnded$Type extends runtime.MessageType {
    constructor() {
        super('stream.video.sfu.event.CallEnded', [
            {
                no: 1,
                name: 'reason',
                kind: 'enum',
                T: () => [
                    'stream.video.sfu.models.CallEndedReason',
                    CallEndedReason,
                    'CALL_ENDED_REASON_',
                ],
            },
        ]);
    }
}
/**
 * @generated MessageType for protobuf message stream.video.sfu.event.CallEnded
 */
const CallEnded = new CallEnded$Type();

var events = /*#__PURE__*/Object.freeze({
    __proto__: null,
    AudioLevel: AudioLevel,
    AudioLevelChanged: AudioLevelChanged,
    AudioSender: AudioSender,
    CallEnded: CallEnded,
    CallGrantsUpdated: CallGrantsUpdated,
    ChangePublishOptions: ChangePublishOptions,
    ChangePublishOptionsComplete: ChangePublishOptionsComplete,
    ChangePublishQuality: ChangePublishQuality,
    ConnectionQualityChanged: ConnectionQualityChanged,
    ConnectionQualityInfo: ConnectionQualityInfo,
    DominantSpeakerChanged: DominantSpeakerChanged,
    Error: Error$1,
    GoAway: GoAway,
    HealthCheckRequest: HealthCheckRequest,
    HealthCheckResponse: HealthCheckResponse,
    ICERestart: ICERestart,
    ICETrickle: ICETrickle,
    JoinRequest: JoinRequest,
    JoinResponse: JoinResponse,
    LeaveCallRequest: LeaveCallRequest,
    Migration: Migration,
    ParticipantJoined: ParticipantJoined,
    ParticipantLeft: ParticipantLeft,
    ParticipantMigrationComplete: ParticipantMigrationComplete,
    ParticipantUpdated: ParticipantUpdated,
    PinsChanged: PinsChanged,
    PublisherAnswer: PublisherAnswer,
    ReconnectDetails: ReconnectDetails,
    SfuEvent: SfuEvent,
    SfuRequest: SfuRequest,
    SubscriberOffer: SubscriberOffer,
    TrackPublished: TrackPublished,
    TrackUnpublished: TrackUnpublished,
    VideoLayerSetting: VideoLayerSetting,
    VideoSender: VideoSender
});

exports.VisibilityState = void 0;
(function (VisibilityState) {
    VisibilityState["UNKNOWN"] = "UNKNOWN";
    VisibilityState["VISIBLE"] = "VISIBLE";
    VisibilityState["INVISIBLE"] = "INVISIBLE";
})(exports.VisibilityState || (exports.VisibilityState = {}));
exports.DebounceType = void 0;
(function (DebounceType) {
    DebounceType[DebounceType["IMMEDIATE"] = 20] = "IMMEDIATE";
    DebounceType[DebounceType["FAST"] = 100] = "FAST";
    DebounceType[DebounceType["MEDIUM"] = 600] = "MEDIUM";
    DebounceType[DebounceType["SLOW"] = 1200] = "SLOW";
})(exports.DebounceType || (exports.DebounceType = {}));

/**
 * @generated from protobuf service stream.video.sfu.signal.SignalServer
 */
class SignalServerClient {
    constructor(_transport) {
        this._transport = _transport;
        this.typeName = SignalServer.typeName;
        this.methods = SignalServer.methods;
        this.options = SignalServer.options;
    }
    /**
     * SetPublisher sends the WebRTC offer for the peer connection used to publish A/V
     *
     * @generated from protobuf rpc: SetPublisher(stream.video.sfu.signal.SetPublisherRequest) returns (stream.video.sfu.signal.SetPublisherResponse);
     */
    setPublisher(input, options) {
        const method = this.methods[0], opt = this._transport.mergeOptions(options);
        return runtimeRpc.stackIntercept('unary', this._transport, method, opt, input);
    }
    /**
     * answer is sent by the client to the SFU after receiving a subscriber_offer.
     *
     * @generated from protobuf rpc: SendAnswer(stream.video.sfu.signal.SendAnswerRequest) returns (stream.video.sfu.signal.SendAnswerResponse);
     */
    sendAnswer(input, options) {
        const method = this.methods[1], opt = this._transport.mergeOptions(options);
        return runtimeRpc.stackIntercept('unary', this._transport, method, opt, input);
    }
    /**
     * SendICECandidate sends an ICE candidate to the client
     *
     * @generated from protobuf rpc: IceTrickle(stream.video.sfu.models.ICETrickle) returns (stream.video.sfu.signal.ICETrickleResponse);
     */
    iceTrickle(input, options) {
        const method = this.methods[2], opt = this._transport.mergeOptions(options);
        return runtimeRpc.stackIntercept('unary', this._transport, method, opt, input);
    }
    /**
     * UpdateSubscribers is used to notify the SFU about the list of video subscriptions
     * TODO: sync subscriptions based on this + update tracks using the dimension info sent by the user
     *
     * @generated from protobuf rpc: UpdateSubscriptions(stream.video.sfu.signal.UpdateSubscriptionsRequest) returns (stream.video.sfu.signal.UpdateSubscriptionsResponse);
     */
    updateSubscriptions(input, options) {
        const method = this.methods[3], opt = this._transport.mergeOptions(options);
        return runtimeRpc.stackIntercept('unary', this._transport, method, opt, input);
    }
    /**
     * @generated from protobuf rpc: UpdateMuteStates(stream.video.sfu.signal.UpdateMuteStatesRequest) returns (stream.video.sfu.signal.UpdateMuteStatesResponse);
     */
    updateMuteStates(input, options) {
        const method = this.methods[4], opt = this._transport.mergeOptions(options);
        return runtimeRpc.stackIntercept('unary', this._transport, method, opt, input);
    }
    /**
     * @generated from protobuf rpc: IceRestart(stream.video.sfu.signal.ICERestartRequest) returns (stream.video.sfu.signal.ICERestartResponse);
     */
    iceRestart(input, options) {
        const method = this.methods[5], opt = this._transport.mergeOptions(options);
        return runtimeRpc.stackIntercept('unary', this._transport, method, opt, input);
    }
    /**
     * @generated from protobuf rpc: SendStats(stream.video.sfu.signal.SendStatsRequest) returns (stream.video.sfu.signal.SendStatsResponse);
     */
    sendStats(input, options) {
        const method = this.methods[6], opt = this._transport.mergeOptions(options);
        return runtimeRpc.stackIntercept('unary', this._transport, method, opt, input);
    }
    /**
     * @generated from protobuf rpc: StartNoiseCancellation(stream.video.sfu.signal.StartNoiseCancellationRequest) returns (stream.video.sfu.signal.StartNoiseCancellationResponse);
     */
    startNoiseCancellation(input, options) {
        const method = this.methods[7], opt = this._transport.mergeOptions(options);
        return runtimeRpc.stackIntercept('unary', this._transport, method, opt, input);
    }
    /**
     * @generated from protobuf rpc: StopNoiseCancellation(stream.video.sfu.signal.StopNoiseCancellationRequest) returns (stream.video.sfu.signal.StopNoiseCancellationResponse);
     */
    stopNoiseCancellation(input, options) {
        const method = this.methods[8], opt = this._transport.mergeOptions(options);
        return runtimeRpc.stackIntercept('unary', this._transport, method, opt, input);
    }
}

const defaultOptions = {
    baseUrl: '',
    sendJson: true,
    timeout: 5 * 1000, // ms.
    jsonOptions: {
        ignoreUnknownFields: true,
    },
};
const withHeaders = (headers) => {
    return {
        interceptUnary(next, method, input, options) {
            options.meta = { ...options.meta, ...headers };
            return next(method, input, options);
        },
    };
};
const withRequestLogger = (logger, level) => {
    return {
        interceptUnary: (next, method, input, options) => {
            let invocation;
            try {
                invocation = next(method, input, options);
            }
            finally {
                logger(level, `Invoked SFU RPC method ${method.name}`, {
                    request: invocation?.request,
                    headers: invocation?.requestHeaders,
                    response: invocation?.response,
                });
            }
            return invocation;
        },
    };
};
const withRequestTracer = (trace) => {
    const exclusions = {
        SendStats: true,
    };
    return {
        interceptUnary(next, method, input, options) {
            if (exclusions[method.name]) {
                return next(method, input, options);
            }
            try {
                trace(method.name, input);
                return next(method, input, options);
            }
            catch (err) {
                trace(`${method.name}OnFailure`, [input, err]);
                throw err;
            }
        },
    };
};
/**
 * Creates new SignalServerClient instance.
 *
 * @param options the twirp options.
 */
const createSignalClient = (options) => {
    const transport = new twirpTransport.TwirpFetchTransport({
        ...defaultOptions,
        ...options,
    });
    return new SignalServerClient(transport);
};

const sleep = (m) => new Promise((r) => setTimeout(r, m));
function isFunction(value) {
    return (value &&
        (Object.prototype.toString.call(value) === '[object Function]' ||
            'function' === typeof value ||
            value instanceof Function));
}
/**
 * A map of known error codes.
 */
const KnownCodes = {
    TOKEN_EXPIRED: 40,
    WS_CLOSED_SUCCESS: 1000,
};
/**
 * retryInterval - A retry interval which increases acc to number of failures
 *
 * @return {number} Duration to wait in milliseconds
 */
function retryInterval(numberOfFailures) {
    // try to reconnect in 0.25-5 seconds (random to spread out the load from failures)
    const max = Math.min(500 + numberOfFailures * 2000, 5000);
    const min = Math.min(Math.max(250, (numberOfFailures - 1) * 2000), 5000);
    return Math.floor(Math.random() * (max - min) + min);
}
function hex(bytes) {
    let s = '';
    for (let i = 0; i < bytes.length; i++) {
        s += bytes[i].toString(16).padStart(2, '0');
    }
    return s;
}
// https://tools.ietf.org/html/rfc4122
function generateUUIDv4() {
    const bytes = getRandomBytes(16);
    bytes[6] = (bytes[6] & 0x0f) | 0x40; // version
    bytes[8] = (bytes[8] & 0xbf) | 0x80; // variant
    return [
        hex(bytes.subarray(0, 4)),
        hex(bytes.subarray(4, 6)),
        hex(bytes.subarray(6, 8)),
        hex(bytes.subarray(8, 10)),
        hex(bytes.subarray(10, 16)),
    ].join('-');
}
const getRandomValues = (() => {
    if (typeof crypto !== 'undefined' && crypto.getRandomValues) {
        return crypto.getRandomValues.bind(crypto);
    }
    return function getRandomValuesWithMathRandom(bytes) {
        const max = Math.pow(2, (8 * bytes.byteLength) / bytes.length);
        for (let i = 0; i < bytes.length; i++) {
            bytes[i] = Math.random() * max;
        }
    };
})();
function getRandomBytes(length) {
    const bytes = new Uint8Array(length);
    getRandomValues(bytes);
    return bytes;
}
/**
 * listenForConnectionChanges - Adds an event listener fired on browser going online or offline
 */
function addConnectionEventListeners(cb) {
    if (typeof window !== 'undefined' && window.addEventListener) {
        window.addEventListener('offline', cb);
        window.addEventListener('online', cb);
    }
}
function removeConnectionEventListeners(cb) {
    if (typeof window !== 'undefined' && window.removeEventListener) {
        window.removeEventListener('offline', cb);
        window.removeEventListener('online', cb);
    }
}
function isErrorResponse(res) {
    return !res.status || res.status < 200 || 300 <= res.status;
}
// Type guards to check WebSocket error type
function isCloseEvent(res) {
    return res.code !== undefined;
}

/**
 * Checks whether we are using React Native
 */
const isReactNative = () => {
    if (typeof navigator === 'undefined')
        return false;
    return navigator.product?.toLowerCase() === 'reactnative';
};

// log levels, sorted by verbosity
const logLevels = Object.freeze({
    trace: 0,
    debug: 1,
    info: 2,
    warn: 3,
    error: 4,
});
let logger;
let level = 'info';
const logToConsole = (logLevel, message, ...args) => {
    let logMethod;
    switch (logLevel) {
        case 'error':
            if (isReactNative()) {
                message = `ERROR: ${message}`;
                logMethod = console.info;
                break;
            }
            logMethod = console.error;
            break;
        case 'warn':
            if (isReactNative()) {
                message = `WARN: ${message}`;
                logMethod = console.info;
                break;
            }
            logMethod = console.warn;
            break;
        case 'info':
            logMethod = console.info;
            break;
        case 'trace':
            logMethod = console.trace;
            break;
        default:
            logMethod = console.log;
            break;
    }
    logMethod(message, ...args);
};
const setLogger = (l, lvl) => {
    logger = l;
    if (lvl) {
        setLogLevel(lvl);
    }
};
const setLogLevel = (l) => {
    level = l;
};
const getLogLevel = () => level;
const getLogger = (withTags) => {
    const loggerMethod = logger || logToConsole;
    const tags = (withTags || []).filter(Boolean).join(':');
    const result = (logLevel, message, ...args) => {
        if (logLevels[logLevel] >= logLevels[level]) {
            loggerMethod(logLevel, `[${tags}]: ${message}`, ...args);
        }
    };
    return result;
};

/**
 * Creates a closure which wraps the given RPC call and retries invoking
 * the RPC until it succeeds or the maximum number of retries is reached.
 *
 * For each retry, there would be a delay to avoid request bursts toward the SFU.
 *
 * @param rpc the closure around the RPC call to execute.
 * @param signal the signal to abort the RPC call and retries loop.
 */
const retryable = async (rpc, signal) => {
    let attempt = 0;
    let result = undefined;
    do {
        if (attempt > 0)
            await sleep(retryInterval(attempt));
        try {
            result = await rpc();
        }
        catch (err) {
            const isRequestCancelled = err instanceof runtimeRpc.RpcError &&
                err.code === twirpTransport.TwirpErrorCode[twirpTransport.TwirpErrorCode.cancelled];
            const isAborted = signal?.aborted ?? false;
            if (isRequestCancelled || isAborted)
                throw err;
            getLogger(['sfu-client', 'rpc'])('debug', `rpc failed (${attempt})`, err);
            attempt++;
        }
    } while (!result || result.response.error?.shouldRetry);
    return result;
};

/**
 * Returns a generic SDP for the given direction.
 * We use this SDP to send it as part of our JoinRequest so that the SFU
 * can use it to determine the client's codec capabilities.
 *
 * @param direction the direction of the transceiver.
 */
const getGenericSdp = async (direction) => {
    const tempPc = new RTCPeerConnection();
    tempPc.addTransceiver('video', { direction });
    tempPc.addTransceiver('audio', { direction });
    const offer = await tempPc.createOffer();
    const sdp = offer.sdp ?? '';
    tempPc.getTransceivers().forEach((t) => {
        t.stop?.();
    });
    tempPc.close();
    return sdp;
};
/**
 * Returns whether the codec is an SVC codec.
 *
 * @param codecOrMimeType the codec to check.
 */
const isSvcCodec = (codecOrMimeType) => {
    if (!codecOrMimeType)
        return false;
    codecOrMimeType = codecOrMimeType.toLowerCase();
    return (codecOrMimeType === 'vp9' ||
        codecOrMimeType === 'av1' ||
        codecOrMimeType === 'video/vp9' ||
        codecOrMimeType === 'video/av1');
};

const sfuEventKinds = {
    subscriberOffer: undefined,
    publisherAnswer: undefined,
    connectionQualityChanged: undefined,
    audioLevelChanged: undefined,
    iceTrickle: undefined,
    changePublishQuality: undefined,
    participantJoined: undefined,
    participantLeft: undefined,
    dominantSpeakerChanged: undefined,
    joinResponse: undefined,
    healthCheckResponse: undefined,
    trackPublished: undefined,
    trackUnpublished: undefined,
    error: undefined,
    callGrantsUpdated: undefined,
    goAway: undefined,
    iceRestart: undefined,
    pinsUpdated: undefined,
    callEnded: undefined,
    participantUpdated: undefined,
    participantMigrationComplete: undefined,
    changePublishOptions: undefined,
};
const isSfuEvent = (eventName) => {
    return Object.prototype.hasOwnProperty.call(sfuEventKinds, eventName);
};
class Dispatcher {
    constructor() {
        this.logger = getLogger(['Dispatcher']);
        this.subscribers = {};
        this.dispatch = (message, logTag = '0') => {
            const eventKind = message.eventPayload.oneofKind;
            if (!eventKind)
                return;
            const payload = message.eventPayload[eventKind];
            this.logger('debug', `Dispatching ${eventKind}, tag=${logTag}`, payload);
            const listeners = this.subscribers[eventKind];
            if (!listeners)
                return;
            for (const fn of listeners) {
                try {
                    fn(payload);
                }
                catch (e) {
                    this.logger('warn', 'Listener failed with error', e);
                }
            }
        };
        this.on = (eventName, fn) => {
            var _a;
            ((_a = this.subscribers)[eventName] ?? (_a[eventName] = [])).push(fn);
            return () => {
                this.off(eventName, fn);
            };
        };
        this.off = (eventName, fn) => {
            this.subscribers[eventName] = (this.subscribers[eventName] || []).filter((f) => f !== fn);
        };
    }
}

/**
 * A buffer for ICE Candidates. Used for ICE Trickle:
 * - https://bloggeek.me/webrtcglossary/trickle-ice/
 */
class IceTrickleBuffer {
    constructor() {
        this.subscriberCandidates = new rxjs.ReplaySubject();
        this.publisherCandidates = new rxjs.ReplaySubject();
        this.push = (iceTrickle) => {
            const iceCandidate = toIceCandidate(iceTrickle);
            if (!iceCandidate)
                return;
            if (iceTrickle.peerType === PeerType.SUBSCRIBER) {
                this.subscriberCandidates.next(iceCandidate);
            }
            else if (iceTrickle.peerType === PeerType.PUBLISHER_UNSPECIFIED) {
                this.publisherCandidates.next(iceCandidate);
            }
            else {
                const logger = getLogger(['sfu-client']);
                logger('warn', `ICETrickle, Unknown peer type`, iceTrickle);
            }
        };
        this.dispose = () => {
            this.subscriberCandidates.complete();
            this.publisherCandidates.complete();
        };
    }
}
const toIceCandidate = (iceTrickle) => {
    try {
        return JSON.parse(iceTrickle.iceCandidate);
    }
    catch (e) {
        const logger = getLogger(['sfu-client']);
        logger('error', `Failed to parse ICE Trickle`, e, iceTrickle);
        return undefined;
    }
};

/**
 * Runs async functions serially. Useful for wrapping async actions that
 * should never run simultaneously: if marked with the same tag, functions
 * will run one after another.
 *
 * @param tag Async functions with the same tag will run serially. Async functions
 * with different tags can run in parallel.
 * @param cb Async function to run.
 * @returns Promise that resolves when async functions returns.
 */
const withoutConcurrency = createRunner(wrapWithContinuationTracking);
/**
 * Runs async functions serially, and cancels all other actions with the same tag
 * when a new action is scheduled. Useful for wrapping async actions that override
 * each other (e.g. enabling and disabling camera).
 *
 * If an async function hasn't started yet and was canceled, it will never run.
 * If an async function is already running and was canceled, it will be notified
 * via an abort signal passed as an argument.
 *
 * @param tag Async functions with the same tag will run serially and are canceled
 * when a new action with the same tag is scheduled.
 * @param cb Async function to run. Receives AbortSignal as the only argument.
 * @returns Promise that resolves when async functions returns. If the function didn't
 * start and was canceled, will resolve with 'canceled'. If the function started to run,
 * it's up to the function to decide how to react to cancelation.
 */
const withCancellation = createRunner(wrapWithCancellation);
const pendingPromises = new Map();
function hasPending(tag) {
    return pendingPromises.has(tag);
}
async function settled(tag) {
    let pending;
    while ((pending = pendingPromises.get(tag))) {
        await pending.promise;
    }
}
/**
 * Implements common functionality of running async functions serially, by chaining
 * their promises one after another.
 *
 * Before running, async function is "wrapped" using the provided wrapper. This wrapper
 * can add additional steps to run before or after the function.
 *
 * When async function is scheduled to run, the previous function is notified
 * by calling the associated onContinued callback. This behavior of this callback
 * is defined by the wrapper.
 */
function createRunner(wrapper) {
    return function run(tag, cb) {
        const { cb: wrapped, onContinued } = wrapper(tag, cb);
        const pending = pendingPromises.get(tag);
        pending?.onContinued();
        const promise = pending
            ? pending.promise.then(wrapped, wrapped)
            : wrapped();
        pendingPromises.set(tag, { promise, onContinued });
        return promise;
    };
}
/**
 * Wraps an async function with an additional step run after the function:
 * if the function is the last in the queue, it cleans up the whole chain
 * of promises after finishing.
 */
function wrapWithContinuationTracking(tag, cb) {
    let hasContinuation = false;
    const wrapped = () => cb().finally(() => {
        if (!hasContinuation) {
            pendingPromises.delete(tag);
        }
    });
    const onContinued = () => (hasContinuation = true);
    return { cb: wrapped, onContinued };
}
/**
 * Wraps an async function with additional functionalilty:
 * 1. Associates an abort signal with every function, that is passed to it
 *    as an argument. When a new function is scheduled to run after the current
 *    one, current signal is aborted.
 * 2. If current function didn't start and was aborted, in will never start.
 * 3. If the function is the last in the queue, it cleans up the whole chain
 *    of promises after finishing.
 */
function wrapWithCancellation(tag, cb) {
    const ac = new AbortController();
    const wrapped = () => {
        if (ac.signal.aborted) {
            return Promise.resolve('canceled');
        }
        return cb(ac.signal).finally(() => {
            if (!ac.signal.aborted) {
                pendingPromises.delete(tag);
            }
        });
    };
    const onContinued = () => ac.abort();
    return { cb: wrapped, onContinued };
}

/**
 * Checks if the provided update is a function patch.
 *
 * @param update the value to check.
 */
const isFunctionPatch = (update) => typeof update === 'function';
/**
 * Gets the current value of an observable, or undefined if the observable has
 * not emitted a value yet.
 *
 * @param observable$ the observable to get the value from.
 */
const getCurrentValue = (observable$) => {
    let value;
    let err = undefined;
    rxjs.combineLatest([observable$])
        .subscribe({
        next: ([v]) => {
            value = v;
        },
        error: (e) => {
            err = e;
        },
    })
        .unsubscribe();
    if (err)
        throw err;
    return value;
};
/**
 * Updates the value of the provided Subject.
 * An `update` can either be a new value or a function which takes
 * the current value and returns a new value.
 *
 * @param subject the subject to update.
 * @param update the update to apply to the subject.
 * @return the updated value.
 */
const setCurrentValue = (subject, update) => {
    const next = isFunctionPatch(update)
        ? update(getCurrentValue(subject))
        : update;
    subject.next(next);
    return next;
};
/**
 * Updates the value of the provided Subject and returns the previous value
 * and a function to roll back the update.
 * This is useful when you want to optimistically update a value
 * and roll back the update if an error occurs.
 *
 * @param subject the subject to update.
 * @param update the update to apply to the subject.
 */
const updateValue = (subject, update) => {
    const lastValue = subject.getValue();
    const value = setCurrentValue(subject, update);
    return {
        lastValue,
        value,
        rollback: () => setCurrentValue(subject, lastValue),
    };
};
/**
 * Creates a subscription and returns a function to unsubscribe.
 *
 * @param observable the observable to subscribe to.
 * @param handler the handler to call when the observable emits a value.
 * @param onError an optional error handler.
 */
const createSubscription = (observable, handler, onError = (error) => getLogger(['RxUtils'])('warn', 'An observable emitted an error', error)) => {
    const subscription = observable.subscribe({ next: handler, error: onError });
    return () => {
        subscription.unsubscribe();
    };
};
/**
 * Creates a subscription and returns a function to unsubscribe. Makes sure that
 * only one async handler runs at the same time. If updates come in quicker than
 * it takes for the current handler to finish, other handlers will wait.
 *
 * @param observable the observable to subscribe to.
 * @param handler the async handler to call when the observable emits a value.
 */
const createSafeAsyncSubscription = (observable, handler) => {
    const tag = Symbol();
    return createSubscription(observable, (value) => {
        withoutConcurrency(tag, () => handler(value));
    });
};

var rxUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    createSafeAsyncSubscription: createSafeAsyncSubscription,
    createSubscription: createSubscription,
    getCurrentValue: getCurrentValue,
    setCurrentValue: setCurrentValue,
    updateValue: updateValue
});

/**
 * Represents the state of the current call.
 */
exports.CallingState = void 0;
(function (CallingState) {
    /**
     * The call is in an unknown state.
     */
    CallingState["UNKNOWN"] = "unknown";
    /**
     * The call is in an idle state.
     */
    CallingState["IDLE"] = "idle";
    /**
     * The call is in the process of ringing.
     * (User hasn't accepted nor rejected the call yet.)
     */
    CallingState["RINGING"] = "ringing";
    /**
     * The call is in the process of joining.
     */
    CallingState["JOINING"] = "joining";
    /**
     * The call is currently active.
     */
    CallingState["JOINED"] = "joined";
    /**
     * The call has been left.
     */
    CallingState["LEFT"] = "left";
    /**
     * The call is in the process of reconnecting.
     */
    CallingState["RECONNECTING"] = "reconnecting";
    /**
     * The call is in the process of migrating from one node to another.
     */
    CallingState["MIGRATING"] = "migrating";
    /**
     * The call has failed to reconnect.
     */
    CallingState["RECONNECTING_FAILED"] = "reconnecting-failed";
    /**
     * The call is in offline mode.
     */
    CallingState["OFFLINE"] = "offline";
})(exports.CallingState || (exports.CallingState = {}));

class StreamVideoWriteableStateStore {
    constructor() {
        /**
         * A store keeping data of a successfully connected user over WS to the coordinator server.
         */
        this.connectedUserSubject = new rxjs.BehaviorSubject(undefined);
        /**
         * A list of {@link Call} objects created/tracked by this client.
         */
        this.callsSubject = new rxjs.BehaviorSubject([]);
        /**
         * Sets the currently connected user.
         *
         * @internal
         * @param user the user to set as connected.
         */
        this.setConnectedUser = (user) => {
            return setCurrentValue(this.connectedUserSubject, user);
        };
        /**
         * Sets the list of {@link Call} objects created/tracked by this client.
         * @param calls
         */
        this.setCalls = (calls) => {
            return setCurrentValue(this.callsSubject, calls);
        };
        /**
         * Adds a {@link Call} object to the list of {@link Call} objects created/tracked by this client.
         *
         * @param call the call to add.
         */
        this.registerCall = (call) => {
            if (!this.calls.find((c) => c.cid === call.cid)) {
                this.setCalls((calls) => [...calls, call]);
            }
        };
        /**
         * Removes a {@link Call} object from the list of {@link Call} objects created/tracked by this client.
         *
         * @param call the call to remove
         */
        this.unregisterCall = (call) => {
            const logger = getLogger(['client-state']);
            logger('trace', `Unregistering call: ${call.cid}`);
            return this.setCalls((calls) => calls.filter((c) => c !== call));
        };
        /**
         * Finds a {@link Call} object in the list of {@link Call} objects created/tracked by this client.
         *
         * @param type the type of call to find.
         * @param id the id of the call to find.
         */
        this.findCall = (type, id) => {
            return this.calls.find((c) => c.type === type && c.id === id);
        };
        this.connectedUserSubject.subscribe(async (user) => {
            // leave all calls when the user disconnects.
            if (!user) {
                const logger = getLogger(['client-state']);
                for (const call of this.calls) {
                    if (call.state.callingState === exports.CallingState.LEFT)
                        continue;
                    logger('info', `User disconnected, leaving call: ${call.cid}`);
                    await call
                        .leave({ reason: 'client.disconnectUser() called' })
                        .catch((err) => {
                        logger('error', `Error leaving call: ${call.cid}`, err);
                    });
                }
            }
        });
    }
    /**
     * The currently connected user.
     */
    get connectedUser() {
        return getCurrentValue(this.connectedUserSubject);
    }
    /**
     * A list of {@link Call} objects created/tracked by this client.
     */
    get calls() {
        return getCurrentValue(this.callsSubject);
    }
}
/**
 * A reactive store that exposes state variables in a reactive manner.
 * You can subscribe to changes of the different state variables.
 * This central store contains all the state variables related to [`StreamVideoClient`](./StreamVideClient.md) and [`Call`](./Call.md).
 */
class StreamVideoReadOnlyStateStore {
    constructor(store) {
        /**
         * This method allows you the get the current value of a state variable.
         *
         * @param observable the observable to get the current value of.
         * @returns the current value of the observable.
         */
        this.getCurrentValue = getCurrentValue;
        // convert and expose subjects as observables
        this.connectedUser$ = store.connectedUserSubject.asObservable();
        this.calls$ = store.callsSubject.asObservable();
    }
    /**
     * The current user connected over WS to the backend.
     */
    get connectedUser() {
        return getCurrentValue(this.connectedUser$);
    }
    /**
     * A list of {@link Call} objects created/tracked by this client.
     */
    get calls() {
        return getCurrentValue(this.calls$);
    }
}

/**
 * Creates a new combined {@link Comparator<T>} which sorts items by the given comparators.
 * The comparators are applied in the order they are given (left -> right).
 *
 * @param comparators the comparators to use for sorting.
 * @returns a combined {@link Comparator<T>}.
 */
const combineComparators = (...comparators) => {
    return (a, b) => {
        for (const comparator of comparators) {
            const result = comparator(a, b);
            if (result !== 0)
                return result;
        }
        return 0;
    };
};
/**
 * Creates a new comparator which sorts items in descending order.
 *
 * @example
 * const byValue = (a, b) => a < b ? - 1 : a > b ? 1 : 0;
 * const byValueDesc = descending(byValue);
 *
 * @param comparator the comparator to wrap.
 */
const descending = (comparator) => {
    return (a, b) => comparator(b, a);
};
/**
 * Creates a new comparator which conditionally applies the given comparator.
 *
 * @example
 * const shouldSortByValue = (a, b) => a % 2 === 0; // return false to turn it off
 * const byValue = (a, b) => a < b ? - 1 : a > b ? 1 : 0;
 * const comparator = conditional(shouldSortByValue)(byValue);
 *
 * @param predicate the predicate to use for determining whether to apply the comparator.
 */
const conditional = (predicate) => {
    return (comparator) => {
        return (a, b) => {
            if (!predicate(a, b))
                return 0;
            return comparator(a, b);
        };
    };
};
/**
 * A no-op comparator which always returns 0.
 */
const noopComparator = () => {
    return () => 0;
};

/**
 * Check if a participant has a video.
 *
 * @param p the participant to check.
 */
const hasVideo = (p) => p.publishedTracks.includes(TrackType.VIDEO);
/**
 * Check if a participant has audio.
 *
 * @param p the participant to check.
 */
const hasAudio = (p) => p.publishedTracks.includes(TrackType.AUDIO);
/**
 * Check if a participant is screen sharing.
 *
 * @param p the participant to check.
 */
const hasScreenShare = (p) => p.publishedTracks.includes(TrackType.SCREEN_SHARE);
/**
 * Check if a participant is screen sharing audio.
 *
 * @param p the participant to check.
 */
const hasScreenShareAudio = (p) => p.publishedTracks.includes(TrackType.SCREEN_SHARE_AUDIO);
/**
 * Check if the participant is pinned.
 *
 * @param p the participant.
 */
const isPinned = (p) => !!p.pin && (p.pin.isLocalPin || p.pin.pinnedAt > 0);

/**
 * A comparator which sorts participants by the fact that they are the dominant speaker or not.
 *
 * @param a the first participant.
 * @param b the second participant.
 */
const dominantSpeaker = (a, b) => {
    if (a.isDominantSpeaker && !b.isDominantSpeaker)
        return -1;
    if (!a.isDominantSpeaker && b.isDominantSpeaker)
        return 1;
    return 0;
};
/**
 * A comparator which sorts participants by the fact that they are speaking or not.
 *
 * @param a the first participant.
 * @param b the second participant.
 */
const speaking = (a, b) => {
    if (a.isSpeaking && !b.isSpeaking)
        return -1;
    if (!a.isSpeaking && b.isSpeaking)
        return 1;
    return 0;
};
/**
 * A comparator which sorts participants by screen sharing status.
 *
 * @param a the first participant.
 * @param b the second participant.
 */
const screenSharing = (a, b) => {
    if (hasScreenShare(a) && !hasScreenShare(b))
        return -1;
    if (!hasScreenShare(a) && hasScreenShare(b))
        return 1;
    return 0;
};
/**
 * A comparator which sorts participants by video status.
 *
 * @param a the first participant.
 * @param b the second participant.
 */
const publishingVideo = (a, b) => {
    if (hasVideo(a) && !hasVideo(b))
        return -1;
    if (!hasVideo(a) && hasVideo(b))
        return 1;
    return 0;
};
/**
 * A comparator which sorts participants by audio status.
 *
 * @param a the first participant.
 * @param b the second participant.
 */
const publishingAudio = (a, b) => {
    if (hasAudio(a) && !hasAudio(b))
        return -1;
    if (!hasAudio(a) && hasAudio(b))
        return 1;
    return 0;
};
/**
 * A comparator which prioritizes participants who are pinned.
 *
 * @param a the first participant.
 * @param b the second participant.
 */
const pinned = (a, b) => {
    if (a.pin && b.pin) {
        if (!a.pin.isLocalPin && b.pin.isLocalPin)
            return -1;
        if (a.pin.isLocalPin && !b.pin.isLocalPin)
            return 1;
        if (a.pin.pinnedAt > b.pin.pinnedAt)
            return -1;
        if (a.pin.pinnedAt < b.pin.pinnedAt)
            return 1;
    }
    if (a.pin && !b.pin)
        return -1;
    if (!a.pin && b.pin)
        return 1;
    return 0;
};
/**
 * A comparator creator which will set up a comparator which prioritizes
 * participants who have a specific reaction.
 *
 * @param type the reaction type.
 */
const reactionType = (type) => {
    return (a, b) => {
        if (a.reaction?.type === type && b.reaction?.type !== type)
            return -1;
        if (a.reaction?.type !== type && b.reaction?.type === type)
            return 1;
        return 0;
    };
};
/**
 * A comparator creator which will set up a comparator which prioritizes
 * participants who have a specific role.
 *
 * @param roles the roles to prioritize.
 */
const role = (...roles) => (a, b) => {
    if (hasAnyRole(a, roles) && !hasAnyRole(b, roles))
        return -1;
    if (!hasAnyRole(a, roles) && hasAnyRole(b, roles))
        return 1;
    return 0;
};
/**
 * A comparator which sorts participants by name.
 *
 * @param a the first participant.
 * @param b the second participant.
 */
const name = (a, b) => {
    if (a.name < b.name)
        return -1;
    if (a.name > b.name)
        return 1;
    return 0;
};
const hasAnyRole = (p, roles) => (p.roles || []).some((r) => roles.includes(r));

// a comparator decorator which applies the decorated comparator only if the
// participant is invisible.
// This ensures stable sorting when all participants are visible.
const ifInvisibleBy = conditional((a, b) => a.viewportVisibilityState?.videoTrack === exports.VisibilityState.INVISIBLE ||
    b.viewportVisibilityState?.videoTrack === exports.VisibilityState.INVISIBLE);
/**
 * A comparator that applies the decorated comparator when a participant is
 * either invisible or its visibility state isn't known.
 * For visible participants, it ensures stable sorting.
 */
const ifInvisibleOrUnknownBy = conditional((a, b) => a.viewportVisibilityState?.videoTrack === exports.VisibilityState.INVISIBLE ||
    a.viewportVisibilityState?.videoTrack === exports.VisibilityState.UNKNOWN ||
    b.viewportVisibilityState?.videoTrack === exports.VisibilityState.INVISIBLE ||
    b.viewportVisibilityState?.videoTrack === exports.VisibilityState.UNKNOWN);
/**
 * The default sorting preset.
 */
const defaultSortPreset = combineComparators(pinned, screenSharing, ifInvisibleBy(combineComparators(dominantSpeaker, speaking, reactionType('raised-hand'), publishingVideo, publishingAudio)));
/**
 * The sorting preset for speaker layout.
 */
const speakerLayoutSortPreset = combineComparators(pinned, screenSharing, dominantSpeaker, ifInvisibleBy(combineComparators(speaking, reactionType('raised-hand'), publishingVideo, publishingAudio)));
/**
 * The sorting preset for layouts that don't render all participants but
 * instead, render them in pages.
 */
const paginatedLayoutSortPreset = combineComparators(pinned, ifInvisibleOrUnknownBy(combineComparators(dominantSpeaker, speaking, reactionType('raised-hand'), publishingVideo, publishingAudio)));
/**
 * The sorting preset for livestreams and audio rooms.
 */
const livestreamOrAudioRoomSortPreset = combineComparators(ifInvisibleBy(combineComparators(dominantSpeaker, speaking, reactionType('raised-hand'), publishingVideo, publishingAudio)), role('admin', 'host', 'speaker'));

/**
 * Returns the default egress object - when no egress data is available.
 */
const defaultEgress = {
    broadcasting: false,
    hls: { playlist_url: '', status: '' },
    rtmps: [],
};
/**
 * Holds the state of the current call.
 * @react You don't have to use this class directly, as we are exposing the state through Hooks.
 */
class CallState {
    /**
     * Creates a new instance of the CallState class.
     *
     */
    constructor() {
        this.backstageSubject = new rxjs.BehaviorSubject(true);
        this.blockedUserIdsSubject = new rxjs.BehaviorSubject([]);
        this.createdAtSubject = new rxjs.BehaviorSubject(new Date());
        this.endedAtSubject = new rxjs.BehaviorSubject(undefined);
        this.startsAtSubject = new rxjs.BehaviorSubject(undefined);
        this.updatedAtSubject = new rxjs.BehaviorSubject(new Date());
        this.createdBySubject = new rxjs.BehaviorSubject(undefined);
        this.customSubject = new rxjs.BehaviorSubject({});
        this.egressSubject = new rxjs.BehaviorSubject(undefined);
        this.ingressSubject = new rxjs.BehaviorSubject(undefined);
        this.recordingSubject = new rxjs.BehaviorSubject(false);
        this.sessionSubject = new rxjs.BehaviorSubject(undefined);
        this.settingsSubject = new rxjs.BehaviorSubject(undefined);
        this.transcribingSubject = new rxjs.BehaviorSubject(false);
        this.captioningSubject = new rxjs.BehaviorSubject(false);
        this.endedBySubject = new rxjs.BehaviorSubject(undefined);
        this.thumbnailsSubject = new rxjs.BehaviorSubject(undefined);
        this.membersSubject = new rxjs.BehaviorSubject([]);
        this.ownCapabilitiesSubject = new rxjs.BehaviorSubject([]);
        this.callingStateSubject = new rxjs.BehaviorSubject(exports.CallingState.UNKNOWN);
        this.startedAtSubject = new rxjs.BehaviorSubject(undefined);
        this.participantCountSubject = new rxjs.BehaviorSubject(0);
        this.anonymousParticipantCountSubject = new rxjs.BehaviorSubject(0);
        this.participantsSubject = new rxjs.BehaviorSubject([]);
        this.callStatsReportSubject = new rxjs.BehaviorSubject(undefined);
        this.closedCaptionsSubject = new rxjs.BehaviorSubject([]);
        // These are tracks that were delivered to the Subscriber's onTrack event
        // that we couldn't associate with a participant yet.
        // This happens when the participantJoined event hasn't been received yet.
        // We keep these tracks around until we can associate them with a participant.
        this.orphanedTracks = [];
        this.logger = getLogger(['CallState']);
        /**
         * A list of comparators that are used to sort the participants.
         */
        this.sortParticipantsBy = defaultSortPreset;
        this.closedCaptionsTasks = new Map();
        /**
         * Runs the cleanup tasks.
         */
        this.dispose = () => {
            for (const [ccKey, taskId] of this.closedCaptionsTasks.entries()) {
                clearTimeout(taskId);
                this.closedCaptionsTasks.delete(ccKey);
            }
        };
        /**
         * Sets the list of criteria that are used to sort the participants.
         * To disable sorting, you can pass `noopComparator()`.
         *
         * @param comparator the comparator to use to sort the participants.
         */
        this.setSortParticipantsBy = (comparator) => {
            this.sortParticipantsBy = comparator;
            // trigger re-sorting of participants
            this.setCurrentValue(this.participantsSubject, (ps) => ps);
        };
        /**
         * Gets the current value of an observable, or undefined if the observable has
         * not emitted a value yet.
         *
         * @param observable$ the observable to get the value from.
         */
        this.getCurrentValue = getCurrentValue;
        /**
         * Updates the value of the provided Subject.
         * An `update` can either be a new value or a function which takes
         * the current value and returns a new value.
         *
         * @internal
         *
         * @param subject the subject to update.
         * @param update the update to apply to the subject.
         * @return the updated value.
         */
        this.setCurrentValue = setCurrentValue;
        /**
         * Sets the number of participants in the current call.
         *
         * @internal
         * @param count the number of participants.
         */
        this.setParticipantCount = (count) => {
            return this.setCurrentValue(this.participantCountSubject, count);
        };
        /**
         * Sets the time the call session actually started.
         *
         * @internal
         * @param startedAt the time the call session actually started.
         */
        this.setStartedAt = (startedAt) => {
            return this.setCurrentValue(this.startedAtSubject, startedAt);
        };
        /**
         * Sets the closed captioning state of the current call.
         *
         * @internal
         * @param captioning the closed captioning state.
         */
        this.setCaptioning = (captioning) => {
            return updateValue(this.captioningSubject, captioning);
        };
        /**
         * Sets the number of anonymous participants in the current call.
         *
         * @internal
         * @param count the number of anonymous participants.
         */
        this.setAnonymousParticipantCount = (count) => {
            return this.setCurrentValue(this.anonymousParticipantCountSubject, count);
        };
        /**
         * Sets the list of participants in the current call.
         *
         * @internal
         *
         * @param participants the list of participants.
         */
        this.setParticipants = (participants) => {
            return this.setCurrentValue(this.participantsSubject, participants);
        };
        /**
         * Sets the calling state.
         *
         * @internal
         * @param state the new calling state.
         */
        this.setCallingState = (state) => {
            return this.setCurrentValue(this.callingStateSubject, state);
        };
        /**
         * Sets the call stats report.
         *
         * @internal
         * @param report the report to set.
         */
        this.setCallStatsReport = (report) => {
            return this.setCurrentValue(this.callStatsReportSubject, report);
        };
        /**
         * Sets the members of the current call.
         *
         * @internal
         * @param members the members to set.
         */
        this.setMembers = (members) => {
            this.setCurrentValue(this.membersSubject, members);
        };
        /**
         * Sets the own capabilities.
         *
         * @internal
         * @param capabilities the capabilities to set.
         */
        this.setOwnCapabilities = (capabilities) => {
            return this.setCurrentValue(this.ownCapabilitiesSubject, capabilities);
        };
        /**
         * Sets the backstage state.
         * @param backstage the backstage state.
         */
        this.setBackstage = (backstage) => {
            return this.setCurrentValue(this.backstageSubject, backstage);
        };
        /**
         * Sets the time when this call has been ended.
         * @param endedAt the time when this call has been ended.
         */
        this.setEndedAt = (endedAt) => {
            return this.setCurrentValue(this.endedAtSubject, endedAt);
        };
        /**
         * Will try to find the participant with the given sessionId in the current call.
         *
         * @param sessionId the sessionId of the participant to find.
         * @returns the participant with the given sessionId or undefined if not found.
         */
        this.findParticipantBySessionId = (sessionId) => {
            return this.participants.find((p) => p.sessionId === sessionId);
        };
        /**
         * Returns a new lookup table of participants indexed by their session ID.
         */
        this.getParticipantLookupBySessionId = () => {
            return this.participants.reduce((lookupTable, participant) => {
                lookupTable[participant.sessionId] = participant;
                return lookupTable;
            }, {});
        };
        /**
         * Updates a participant in the current call identified by the given `sessionId`.
         * If the participant can't be found, this operation is no-op.
         *
         * @internal
         *
         * @param sessionId the session ID of the participant to update.
         * @param patch the patch to apply to the participant.
         * @returns the updated participant or `undefined` if the participant couldn't be found.
         */
        this.updateParticipant = (sessionId, patch) => {
            const participant = this.findParticipantBySessionId(sessionId);
            if (!participant) {
                this.logger('warn', `Participant with sessionId ${sessionId} not found`);
                return;
            }
            const thePatch = typeof patch === 'function' ? patch(participant) : patch;
            const updatedParticipant = {
                ...participant,
                ...thePatch,
            };
            return this.setParticipants((participants) => participants.map((p) => p.sessionId === sessionId ? updatedParticipant : p));
        };
        /**
         * Updates a participant in the current call identified by the given `sessionId`.
         * If a participant with matching `sessionId` can't be found, the provided
         * `participant` is added to the list of participants.
         *
         * @param sessionId the session ID of the participant to update.
         * @param participant the participant to update or add.
         */
        this.updateOrAddParticipant = (sessionId, participant) => {
            return this.setParticipants((participants) => {
                let add = true;
                const nextParticipants = participants.map((p) => {
                    if (p.sessionId === sessionId) {
                        add = false;
                        return {
                            ...p,
                            ...participant,
                        };
                    }
                    return p;
                });
                if (add)
                    nextParticipants.push(participant);
                return nextParticipants;
            });
        };
        /**
         * Updates all participants in the current call whose session ID is in the given `sessionIds`.
         * If no patches are provided, this operation is no-op.
         *
         * @internal
         *
         * @param patch the patch to apply to the participants.
         * @returns all participants, with all patch applied.
         */
        this.updateParticipants = (patch) => {
            if (Object.keys(patch).length === 0)
                return this.participants;
            return this.setParticipants((participants) => participants.map((p) => {
                const thePatch = patch[p.sessionId];
                if (thePatch) {
                    return {
                        ...p,
                        ...thePatch,
                    };
                }
                return p;
            }));
        };
        /**
         * Update track subscription configuration for one or more participants.
         * You have to create a subscription for each participant for all the different kinds of tracks you want to receive.
         * You can only subscribe for tracks after the participant started publishing the given kind of track.
         *
         * @param trackType the kind of subscription to update.
         * @param changes the list of subscription changes to do.
         */
        this.updateParticipantTracks = (trackType, changes) => {
            return this.updateParticipants(Object.entries(changes).reduce((acc, [sessionId, change]) => {
                if (change.dimension) {
                    change.dimension.height = Math.ceil(change.dimension.height);
                    change.dimension.width = Math.ceil(change.dimension.width);
                }
                const prop = trackType === 'videoTrack'
                    ? 'videoDimension'
                    : trackType === 'screenShareTrack'
                        ? 'screenShareDimension'
                        : undefined;
                if (prop) {
                    acc[sessionId] = {
                        [prop]: change.dimension,
                    };
                }
                return acc;
            }, {}));
        };
        /**
         * Updates the call state with the data received from the server.
         *
         * @internal
         *
         * @param event the video event that our backend sent us.
         */
        this.updateFromEvent = (event) => {
            const update = this.eventHandlers[event.type];
            if (update) {
                update(event);
            }
        };
        /**
         * Updates the participant pinned state with server side pinning data.
         *
         * @param pins the latest pins from the server.
         */
        this.setServerSidePins = (pins) => {
            const pinsLookup = pins.reduce((lookup, pin) => {
                lookup[pin.sessionId] = Date.now();
                return lookup;
            }, {});
            return this.setParticipants((participants) => participants.map((participant) => {
                const serverSidePinnedAt = pinsLookup[participant.sessionId];
                // the participant is newly pinned
                if (serverSidePinnedAt) {
                    return {
                        ...participant,
                        pin: {
                            isLocalPin: false,
                            pinnedAt: serverSidePinnedAt,
                        },
                    };
                }
                // the participant is no longer pinned server side
                // we need to reset the pin
                if (participant.pin && !participant.pin.isLocalPin) {
                    return {
                        ...participant,
                        pin: undefined,
                    };
                }
                // no changes to be applied
                return participant;
            }));
        };
        /**
         * Adds an orphaned track to the call state.
         *
         * @internal
         *
         * @param orphanedTrack the orphaned track to add.
         */
        this.registerOrphanedTrack = (orphanedTrack) => {
            this.orphanedTracks.push(orphanedTrack);
        };
        /**
         * Removes an orphaned track from the call state.
         *
         * @internal
         *
         * @param id the ID of the orphaned track to remove.
         */
        this.removeOrphanedTrack = (id) => {
            this.orphanedTracks = this.orphanedTracks.filter((o) => o.id !== id);
        };
        /**
         * Takes all orphaned tracks with the given track lookup prefix.
         * All orphaned tracks with the given track lookup prefix are removed from the call state.
         *
         * @internal
         *
         * @param trackLookupPrefix the track lookup prefix to match the orphaned tracks by.
         */
        this.takeOrphanedTracks = (trackLookupPrefix) => {
            const orphans = this.orphanedTracks.filter((orphan) => orphan.trackLookupPrefix === trackLookupPrefix);
            if (orphans.length > 0) {
                this.orphanedTracks = this.orphanedTracks.filter((orphan) => orphan.trackLookupPrefix !== trackLookupPrefix);
            }
            return orphans;
        };
        /**
         * Updates the closed captions settings.
         *
         * @param config the new closed captions settings.
         */
        this.updateClosedCaptionSettings = (config) => {
            this.closedCaptionsSettings = { ...this.closedCaptionsSettings, ...config };
        };
        /**
         * Updates the call state with the data received from the server.
         *
         * @internal
         *
         * @param call the call response from the server.
         */
        this.updateFromCallResponse = (call) => {
            this.setBackstage(call.backstage);
            this.setCurrentValue(this.blockedUserIdsSubject, call.blocked_user_ids);
            this.setCurrentValue(this.createdAtSubject, new Date(call.created_at));
            this.setCurrentValue(this.updatedAtSubject, new Date(call.updated_at));
            this.setCurrentValue(this.startsAtSubject, call.starts_at ? new Date(call.starts_at) : undefined);
            this.setEndedAt(call.ended_at ? new Date(call.ended_at) : undefined);
            this.setCurrentValue(this.createdBySubject, call.created_by);
            this.setCurrentValue(this.customSubject, call.custom);
            this.setCurrentValue(this.egressSubject, call.egress);
            this.setCurrentValue(this.ingressSubject, call.ingress);
            this.setCurrentValue(this.recordingSubject, call.recording);
            const s = this.setCurrentValue(this.sessionSubject, call.session);
            this.updateParticipantCountFromSession(s);
            this.setCurrentValue(this.settingsSubject, call.settings);
            this.setCurrentValue(this.transcribingSubject, call.transcribing);
            this.setCurrentValue(this.captioningSubject, call.captioning);
            this.setCurrentValue(this.thumbnailsSubject, call.thumbnails);
        };
        /**
         * Updates the call state with the data received from the SFU server.
         *
         * @internal
         *
         * @param callState the call state from the SFU server.
         * @param currentSessionId the session ID of the current user.
         * @param reconnectDetails optional reconnect details.
         */
        this.updateFromSfuCallState = (callState, currentSessionId, reconnectDetails) => {
            const { participants, participantCount, startedAt, pins } = callState;
            const localPublishedTracks = reconnectDetails?.announcedTracks.map((t) => t.trackType) ?? [];
            this.setParticipants(() => {
                const participantLookup = this.getParticipantLookupBySessionId();
                return participants.map((p) => {
                    // We need to preserve the local state of the participant
                    // (e.g. videoDimension, visibilityState, pinnedAt, etc.)
                    // as it doesn't exist on the server.
                    const existingParticipant = participantLookup[p.sessionId];
                    const isLocalParticipant = p.sessionId === currentSessionId;
                    return Object.assign({}, existingParticipant, p, {
                        isLocalParticipant,
                        publishedTracks: isLocalParticipant
                            ? localPublishedTracks
                            : p.publishedTracks,
                        viewportVisibilityState: existingParticipant?.viewportVisibilityState ?? {
                            videoTrack: exports.VisibilityState.UNKNOWN,
                            screenShareTrack: exports.VisibilityState.UNKNOWN,
                        },
                    });
                });
            });
            this.setParticipantCount(participantCount?.total || 0);
            this.setAnonymousParticipantCount(participantCount?.anonymous || 0);
            this.setStartedAt(startedAt ? Timestamp.toDate(startedAt) : new Date());
            this.setServerSidePins(pins);
        };
        this.updateFromMemberRemoved = (event) => {
            this.updateFromCallResponse(event.call);
            this.setCurrentValue(this.membersSubject, (members) => members.filter((m) => event.members.indexOf(m.user_id) === -1));
        };
        this.updateFromMemberAdded = (event) => {
            this.updateFromCallResponse(event.call);
            this.setCurrentValue(this.membersSubject, (members) => [
                ...members,
                ...event.members,
            ]);
        };
        this.updateFromHLSBroadcastStopped = () => {
            this.setCurrentValue(this.egressSubject, (egress = defaultEgress) => ({
                ...egress,
                broadcasting: false,
                hls: {
                    ...egress.hls,
                    status: '',
                },
            }));
        };
        this.updateFromHLSBroadcastingFailed = () => {
            this.setCurrentValue(this.egressSubject, (egress = defaultEgress) => ({
                ...egress,
                broadcasting: false,
                hls: {
                    ...egress.hls,
                    status: '',
                },
            }));
        };
        this.updateParticipantCountFromSession = (session) => {
            // when in JOINED state, we should use the participant count coming through
            // the SFU healthcheck event, as it's more accurate.
            if (!session || this.callingState === exports.CallingState.JOINED)
                return;
            const byRoleCount = Object.values(session.participants_count_by_role).reduce((total, countByRole) => total + countByRole, 0);
            const participantCount = Math.max(byRoleCount, session.participants.length);
            this.setParticipantCount(participantCount);
            this.setAnonymousParticipantCount(session.anonymous_participant_count || 0);
        };
        this.updateFromSessionParticipantCountUpdate = (event) => {
            const s = this.setCurrentValue(this.sessionSubject, (session) => {
                if (!session)
                    return session;
                return {
                    ...session,
                    anonymous_participant_count: event.anonymous_participant_count,
                    participants_count_by_role: event.participants_count_by_role,
                };
            });
            this.updateParticipantCountFromSession(s);
        };
        this.updateFromSessionParticipantLeft = (event) => {
            const s = this.setCurrentValue(this.sessionSubject, (session) => {
                if (!session)
                    return session;
                const { participants, participants_count_by_role } = session;
                const { user, user_session_id } = event.participant;
                return {
                    ...session,
                    participants: participants.filter((p) => p.user_session_id !== user_session_id),
                    participants_count_by_role: {
                        ...participants_count_by_role,
                        [user.role]: Math.max(0, (participants_count_by_role[user.role] || 0) - 1),
                    },
                };
            });
            this.updateParticipantCountFromSession(s);
        };
        this.updateFromSessionParticipantJoined = (event) => {
            const s = this.setCurrentValue(this.sessionSubject, (session) => {
                if (!session)
                    return session;
                const { participants, participants_count_by_role } = session;
                const { user, user_session_id } = event.participant;
                // It could happen that the backend delivers the same participant more than once.
                // Once with the call.session_started event and once again with the
                // call.session_participant_joined event. In this case,
                // we should update the existing participant and prevent duplicating it.
                let shouldInsertParticipant = true;
                const updatedParticipants = participants.map((p) => {
                    if (p.user_session_id === user_session_id) {
                        shouldInsertParticipant = false;
                        return event.participant;
                    }
                    return p;
                });
                if (shouldInsertParticipant) {
                    // this is a new array, we can safely push the new participant
                    updatedParticipants.push(event.participant);
                }
                // If we are updating an existing participant, we don't want to increment
                // the participant_by_role count.
                const increment = shouldInsertParticipant ? 1 : 0;
                return {
                    ...session,
                    participants: updatedParticipants,
                    participants_count_by_role: {
                        ...participants_count_by_role,
                        [user.role]: (participants_count_by_role[user.role] || 0) + increment,
                    },
                };
            });
            this.updateParticipantCountFromSession(s);
        };
        this.updateMembers = (event) => {
            this.updateFromCallResponse(event.call);
            this.setCurrentValue(this.membersSubject, (members) => members.map((member) => {
                const memberUpdate = event.members.find((m) => m.user_id === member.user_id);
                return memberUpdate ? memberUpdate : member;
            }));
        };
        this.updateParticipantReaction = (event) => {
            const { user, custom, type, emoji_code } = event.reaction;
            this.setParticipants((participants) => {
                return participants.map((p) => {
                    // skip if the reaction is not for this participant
                    if (p.userId !== user.id)
                        return p;
                    // update the participant with the new reaction
                    return {
                        ...p,
                        reaction: {
                            type,
                            emoji_code,
                            custom,
                        },
                    };
                });
            });
        };
        this.unblockUser = (event) => {
            this.setCurrentValue(this.blockedUserIdsSubject, (current) => {
                if (!current)
                    return current;
                return current.filter((id) => id !== event.user.id);
            });
        };
        this.blockUser = (event) => {
            this.setCurrentValue(this.blockedUserIdsSubject, (current) => [
                ...(current || []),
                event.user.id,
            ]);
        };
        this.updateOwnCapabilities = (event) => {
            if (event.user.id === this.localParticipant?.userId) {
                this.setCurrentValue(this.ownCapabilitiesSubject, event.own_capabilities);
            }
        };
        this.updateFromClosedCaptions = (event) => {
            this.setCurrentValue(this.closedCaptionsSubject, (queue) => {
                const { closed_caption } = event;
                const keyOf = (c) => `${c.speaker_id}/${c.start_time}`;
                const currentKey = keyOf(closed_caption);
                const duplicate = queue.some((caption) => keyOf(caption) === currentKey);
                if (duplicate)
                    return queue;
                const nextQueue = [...queue, closed_caption];
                const { visibilityDurationMs = 2700, maxVisibleCaptions = 2 } = this.closedCaptionsSettings || {};
                // schedule the removal of the closed caption after the retention time
                if (visibilityDurationMs > 0) {
                    const taskId = setTimeout(() => {
                        this.setCurrentValue(this.closedCaptionsSubject, (captions) => captions.filter((caption) => caption !== closed_caption));
                        this.closedCaptionsTasks.delete(currentKey);
                    }, visibilityDurationMs);
                    this.closedCaptionsTasks.set(currentKey, taskId);
                    // cancel the cleanup tasks for the closed captions that are no longer in the queue
                    for (let i = 0; i < nextQueue.length - maxVisibleCaptions; i++) {
                        const key = keyOf(nextQueue[i]);
                        const task = this.closedCaptionsTasks.get(key);
                        clearTimeout(task);
                        this.closedCaptionsTasks.delete(key);
                    }
                }
                // trim the queue
                return nextQueue.slice(-maxVisibleCaptions);
            });
        };
        this.participants$ = this.participantsSubject.asObservable().pipe(
        // maintain stable-sort by mutating the participants stored
        // in the original subject
        rxjs.map((ps) => ps.sort(this.sortParticipantsBy)), rxjs.shareReplay({ bufferSize: 1, refCount: true }));
        this.localParticipant$ = this.participants$.pipe(rxjs.map((participants) => participants.find((p) => p.isLocalParticipant)), rxjs.shareReplay({ bufferSize: 1, refCount: true }));
        this.remoteParticipants$ = this.participants$.pipe(rxjs.map((participants) => participants.filter((p) => !p.isLocalParticipant)), rxjs.shareReplay({ bufferSize: 1, refCount: true }));
        this.pinnedParticipants$ = this.participants$.pipe(rxjs.map((participants) => participants.filter((p) => !!p.pin)), rxjs.shareReplay({ bufferSize: 1, refCount: true }));
        this.dominantSpeaker$ = this.participants$.pipe(rxjs.map((participants) => participants.find((p) => p.isDominantSpeaker)), rxjs.shareReplay({ bufferSize: 1, refCount: true }));
        this.hasOngoingScreenShare$ = this.participants$.pipe(rxjs.map((participants) => participants.some((p) => hasScreenShare(p))), rxjs.distinctUntilChanged(), rxjs.shareReplay({ bufferSize: 1, refCount: true }));
        // dates
        this.createdAt$ = this.createdAtSubject.asObservable();
        this.endedAt$ = this.endedAtSubject.asObservable();
        this.startsAt$ = this.startsAtSubject.asObservable();
        this.startedAt$ = this.startedAtSubject.asObservable();
        this.updatedAt$ = this.updatedAtSubject.asObservable();
        this.callStatsReport$ = this.callStatsReportSubject.asObservable();
        this.members$ = this.membersSubject.asObservable();
        // complex objects should work as streams of data
        this.createdBy$ = this.createdBySubject.asObservable();
        this.custom$ = this.customSubject.asObservable();
        this.egress$ = this.egressSubject.asObservable();
        this.ingress$ = this.ingressSubject.asObservable();
        this.session$ = this.sessionSubject.asObservable();
        this.settings$ = this.settingsSubject.asObservable();
        this.endedBy$ = this.endedBySubject.asObservable();
        this.thumbnails$ = this.thumbnailsSubject.asObservable();
        this.closedCaptions$ = this.closedCaptionsSubject.asObservable();
        /**
         * Performs shallow comparison of two arrays.
         * Expects primitive values: [1, 2, 3] is equal to [2, 1, 3].
         */
        const isShallowEqual = (a, b) => {
            if (a.length !== b.length)
                return false;
            for (const item of a)
                if (!b.includes(item))
                    return false;
            for (const item of b)
                if (!a.includes(item))
                    return false;
            return true;
        };
        /**
         * Creates an Observable from the given subject by piping to the
         * `distinctUntilChanged()` operator.
         */
        const duc = (subject, comparator) => subject.asObservable().pipe(rxjs.distinctUntilChanged(comparator));
        // primitive values should only emit once the value they hold changes
        this.anonymousParticipantCount$ = duc(this.anonymousParticipantCountSubject);
        this.blockedUserIds$ = duc(this.blockedUserIdsSubject, isShallowEqual);
        this.backstage$ = duc(this.backstageSubject);
        this.callingState$ = duc(this.callingStateSubject);
        this.ownCapabilities$ = duc(this.ownCapabilitiesSubject, isShallowEqual);
        this.participantCount$ = duc(this.participantCountSubject);
        this.recording$ = duc(this.recordingSubject);
        this.transcribing$ = duc(this.transcribingSubject);
        this.captioning$ = duc(this.captioningSubject);
        this.eventHandlers = {
            // these events are not updating the call state:
            'call.frame_recording_ready': undefined,
            'call.permission_request': undefined,
            'call.recording_ready': undefined,
            'call.rtmp_broadcast_failed': undefined,
            'call.rtmp_broadcast_started': undefined,
            'call.rtmp_broadcast_stopped': undefined,
            'call.transcription_ready': undefined,
            'call.user_muted': undefined,
            'connection.error': undefined,
            'connection.ok': undefined,
            'health.check': undefined,
            'user.updated': undefined,
            custom: undefined,
            // events that update call state:
            'call.accepted': (e) => this.updateFromCallResponse(e.call),
            'call.blocked_user': this.blockUser,
            'call.closed_caption': this.updateFromClosedCaptions,
            'call.closed_captions_failed': () => {
                this.setCurrentValue(this.captioningSubject, false);
            },
            'call.closed_captions_started': () => {
                this.setCurrentValue(this.captioningSubject, true);
            },
            'call.closed_captions_stopped': () => {
                this.setCurrentValue(this.captioningSubject, false);
            },
            'call.created': (e) => this.updateFromCallResponse(e.call),
            'call.deleted': (e) => this.updateFromCallResponse(e.call),
            'call.ended': (e) => {
                this.updateFromCallResponse(e.call);
                this.setCurrentValue(this.endedBySubject, e.user);
            },
            'call.frame_recording_failed': (e) => {
                this.updateFromCallResponse(e.call);
            },
            'call.frame_recording_started': (e) => {
                this.updateFromCallResponse(e.call);
            },
            'call.frame_recording_stopped': (e) => {
                this.updateFromCallResponse(e.call);
            },
            'call.hls_broadcasting_failed': this.updateFromHLSBroadcastingFailed,
            'call.hls_broadcasting_started': (e) => {
                this.updateFromCallResponse(e.call);
            },
            'call.hls_broadcasting_stopped': this.updateFromHLSBroadcastStopped,
            'call.live_started': (e) => this.updateFromCallResponse(e.call),
            'call.member_added': this.updateFromMemberAdded,
            'call.member_removed': this.updateFromMemberRemoved,
            'call.member_updated_permission': this.updateMembers,
            'call.member_updated': this.updateMembers,
            'call.notification': (e) => {
                this.updateFromCallResponse(e.call);
                this.setMembers(e.members);
            },
            'call.permissions_updated': this.updateOwnCapabilities,
            'call.reaction_new': this.updateParticipantReaction,
            'call.recording_started': () => this.setCurrentValue(this.recordingSubject, true),
            'call.recording_stopped': () => this.setCurrentValue(this.recordingSubject, false),
            'call.recording_failed': () => this.setCurrentValue(this.recordingSubject, false),
            'call.rejected': (e) => this.updateFromCallResponse(e.call),
            'call.ring': (e) => this.updateFromCallResponse(e.call),
            'call.missed': (e) => this.updateFromCallResponse(e.call),
            'call.session_ended': (e) => this.updateFromCallResponse(e.call),
            'call.session_participant_count_updated': this.updateFromSessionParticipantCountUpdate,
            'call.session_participant_joined': this.updateFromSessionParticipantJoined,
            'call.session_participant_left': this.updateFromSessionParticipantLeft,
            'call.session_started': (e) => this.updateFromCallResponse(e.call),
            'call.transcription_started': () => {
                this.setCurrentValue(this.transcribingSubject, true);
            },
            'call.transcription_stopped': () => {
                this.setCurrentValue(this.transcribingSubject, false);
            },
            'call.transcription_failed': () => {
                this.setCurrentValue(this.transcribingSubject, false);
            },
            'call.unblocked_user': this.unblockUser,
            'call.updated': (e) => this.updateFromCallResponse(e.call),
        };
    }
    /**
     * The server-side counted number of participants connected to the current call.
     * This number includes the anonymous participants as well.
     */
    get participantCount() {
        return this.getCurrentValue(this.participantCount$);
    }
    /**
     * The time the call session actually started.
     * Useful for displaying the call duration.
     */
    get startedAt() {
        return this.getCurrentValue(this.startedAt$);
    }
    /**
     * Returns whether closed captions are enabled in the current call.
     */
    get captioning() {
        return this.getCurrentValue(this.captioning$);
    }
    /**
     * The server-side counted number of anonymous participants connected to the current call.
     * This number includes the anonymous participants as well.
     */
    get anonymousParticipantCount() {
        return this.getCurrentValue(this.anonymousParticipantCount$);
    }
    /**
     * The list of participants in the current call.
     */
    get participants() {
        return this.getCurrentValue(this.participants$);
    }
    /**
     * The local participant in the current call.
     */
    get localParticipant() {
        return this.getCurrentValue(this.localParticipant$);
    }
    /**
     * The list of remote participants in the current call.
     */
    get remoteParticipants() {
        return this.getCurrentValue(this.remoteParticipants$);
    }
    /**
     * The dominant speaker in the current call.
     */
    get dominantSpeaker() {
        return this.getCurrentValue(this.dominantSpeaker$);
    }
    /**
     * The list of pinned participants in the current call.
     */
    get pinnedParticipants() {
        return this.getCurrentValue(this.pinnedParticipants$);
    }
    /**
     * Tell if there is an ongoing screen share in this call.
     */
    get hasOngoingScreenShare() {
        return this.getCurrentValue(this.hasOngoingScreenShare$);
    }
    /**
     * The calling state.
     */
    get callingState() {
        return this.getCurrentValue(this.callingState$);
    }
    /**
     * The call stats report.
     */
    get callStatsReport() {
        return this.getCurrentValue(this.callStatsReport$);
    }
    /**
     * The members of the current call.
     */
    get members() {
        return this.getCurrentValue(this.members$);
    }
    /**
     * The capabilities of the current user for the current call.
     */
    get ownCapabilities() {
        return this.getCurrentValue(this.ownCapabilities$);
    }
    /**
     * The backstage state.
     */
    get backstage() {
        return this.getCurrentValue(this.backstage$);
    }
    /**
     * Will provide the list of blocked user IDs.
     */
    get blockedUserIds() {
        return this.getCurrentValue(this.blockedUserIds$);
    }
    /**
     * Will provide the time when this call has been created.
     */
    get createdAt() {
        return this.getCurrentValue(this.createdAt$);
    }
    /**
     * Will provide the time when this call has been ended.
     */
    get endedAt() {
        return this.getCurrentValue(this.endedAt$);
    }
    /**
     * Will provide the time when this call has been scheduled to start.
     */
    get startsAt() {
        return this.getCurrentValue(this.startsAt$);
    }
    /**
     * Will provide the time when this call has been updated.
     */
    get updatedAt() {
        return this.getCurrentValue(this.updatedAt$);
    }
    /**
     * Will provide the user who created this call.
     */
    get createdBy() {
        return this.getCurrentValue(this.createdBy$);
    }
    /**
     * Will provide the custom data of this call.
     */
    get custom() {
        return this.getCurrentValue(this.custom$);
    }
    /**
     * Will provide the egress data of this call.
     */
    get egress() {
        return this.getCurrentValue(this.egress$);
    }
    /**
     * Will provide the ingress data of this call.
     */
    get ingress() {
        return this.getCurrentValue(this.ingress$);
    }
    /**
     * Will provide the recording state of this call.
     */
    get recording() {
        return this.getCurrentValue(this.recording$);
    }
    /**
     * Will provide the session data of this call.
     */
    get session() {
        return this.getCurrentValue(this.session$);
    }
    /**
     * Will provide the settings of this call.
     */
    get settings() {
        return this.getCurrentValue(this.settings$);
    }
    /**
     * Will provide the transcribing state of this call.
     */
    get transcribing() {
        return this.getCurrentValue(this.transcribing$);
    }
    /**
     * Will provide the user who ended this call.
     */
    get endedBy() {
        return this.getCurrentValue(this.endedBy$);
    }
    /**
     * Will provide the thumbnails of this call, if enabled in the call settings.
     */
    get thumbnails() {
        return this.getCurrentValue(this.thumbnails$);
    }
    /**
     * Returns the current queue of closed captions.
     */
    get closedCaptions() {
        return this.getCurrentValue(this.closedCaptions$);
    }
}

/**
 * Flatten the stats report into an array of stats objects.
 *
 * @param report the report to flatten.
 */
const flatten = (report) => {
    const stats = [];
    report.forEach((s) => {
        stats.push(s);
    });
    return stats;
};
const getSdkSignature = (clientDetails) => {
    const { sdk, ...platform } = clientDetails;
    const sdkName = getSdkName(sdk);
    const sdkVersion = getSdkVersion(sdk);
    return {
        sdkName,
        sdkVersion,
        ...platform,
    };
};
const getSdkName = (sdk) => {
    return sdk && sdk.type === SdkType.REACT
        ? 'stream-react'
        : sdk && sdk.type === SdkType.REACT_NATIVE
            ? 'stream-react-native'
            : 'stream-js';
};
const getSdkVersion = (sdk) => {
    return sdk ? `${sdk.major}.${sdk.minor}.${sdk.patch}` : '0.0.0-development';
};

/**
 * Checks whether the current browser is Safari.
 */
const isSafari = () => {
    if (typeof navigator === 'undefined')
        return false;
    return /^((?!chrome|android).)*safari/i.test(navigator.userAgent || '');
};
/**
 * Checks whether the current browser is Firefox.
 */
const isFirefox = () => {
    if (typeof navigator === 'undefined')
        return false;
    return navigator.userAgent?.includes('Firefox');
};
/**
 * Checks whether the current browser is Google Chrome.
 */
const isChrome = () => {
    if (typeof navigator === 'undefined')
        return false;
    return navigator.userAgent?.includes('Chrome');
};

var browsers = /*#__PURE__*/Object.freeze({
    __proto__: null,
    isChrome: isChrome,
    isFirefox: isFirefox,
    isSafari: isSafari
});

/**
 * Creates a new StatsReporter instance that collects metrics about the ongoing call and reports them to the state store
 */
const createStatsReporter = ({ subscriber, publisher, state, datacenter, pollingIntervalInMs = 2000, }) => {
    const logger = getLogger(['stats']);
    const getRawStatsForTrack = async (kind, selector) => {
        if (kind === 'subscriber' && subscriber) {
            return subscriber.getStats(selector);
        }
        else if (kind === 'publisher' && publisher) {
            return publisher.getStats(selector);
        }
        else {
            return undefined;
        }
    };
    const getStatsForStream = async (kind, tracks) => {
        const pc = kind === 'subscriber' ? subscriber : publisher;
        if (!pc)
            return [];
        const statsForStream = [];
        for (const track of tracks) {
            const report = await pc.getStats(track);
            const stats = transform(report, {
                trackKind: track.kind,
                kind,
                publisher: undefined,
            });
            statsForStream.push(stats);
        }
        return statsForStream;
    };
    const startReportingStatsFor = (sessionId) => {
        sessionIdsToTrack.add(sessionId);
        void run();
    };
    const stopReportingStatsFor = (sessionId) => {
        sessionIdsToTrack.delete(sessionId);
        void run();
    };
    const sessionIdsToTrack = new Set();
    /**
     * The main stats reporting loop.
     */
    const run = async () => {
        const participantStats = {};
        if (sessionIdsToTrack.size > 0) {
            const sessionIds = new Set(sessionIdsToTrack);
            for (const participant of state.participants) {
                if (!sessionIds.has(participant.sessionId))
                    continue;
                const { audioStream, isLocalParticipant, sessionId, userId, videoStream, } = participant;
                const kind = isLocalParticipant ? 'publisher' : 'subscriber';
                try {
                    const tracks = isLocalParticipant
                        ? publisher?.getPublishedTracks() || []
                        : [
                            ...(videoStream?.getVideoTracks() || []),
                            ...(audioStream?.getAudioTracks() || []),
                        ];
                    participantStats[sessionId] = await getStatsForStream(kind, tracks);
                }
                catch (e) {
                    logger('warn', `Failed to collect ${kind} stats for ${userId}`, e);
                }
            }
        }
        const [subscriberStats, publisherStats] = await Promise.all([
            subscriber
                .getStats()
                .then((report) => transform(report, {
                kind: 'subscriber',
                trackKind: 'video',
                publisher,
            }))
                .then(aggregate),
            publisher
                ? publisher
                    .getStats()
                    .then((report) => transform(report, {
                    kind: 'publisher',
                    trackKind: 'video',
                    publisher,
                }))
                    .then(aggregate)
                : getEmptyStats(),
        ]);
        const [subscriberRawStats, publisherRawStats] = await Promise.all([
            getRawStatsForTrack('subscriber'),
            publisher ? getRawStatsForTrack('publisher') : undefined,
        ]);
        state.setCallStatsReport({
            datacenter,
            publisherStats,
            subscriberStats,
            subscriberRawStats,
            publisherRawStats,
            participants: participantStats,
            timestamp: Date.now(),
        });
    };
    let timeoutId;
    if (pollingIntervalInMs > 0) {
        const loop = async () => {
            await run().catch((e) => {
                logger('debug', 'Failed to collect stats', e);
            });
            timeoutId = setTimeout(loop, pollingIntervalInMs);
        };
        void loop();
    }
    const stop = () => {
        if (timeoutId) {
            clearTimeout(timeoutId);
        }
    };
    return {
        getRawStatsForTrack,
        getStatsForStream,
        startReportingStatsFor,
        stopReportingStatsFor,
        stop,
    };
};
/**
 * Transforms raw RTC stats into a slimmer and uniform across browsers format.
 *
 * @param report the report to transform.
 * @param opts the transform options.
 */
const transform = (report, opts) => {
    const { trackKind, kind, publisher } = opts;
    const direction = kind === 'subscriber' ? 'inbound-rtp' : 'outbound-rtp';
    const stats = flatten(report);
    const streams = stats
        .filter((stat) => stat.type === direction &&
        stat.kind === trackKind)
        .map((stat) => {
        const rtcStreamStats = stat;
        const codec = stats.find((s) => s.type === 'codec' && s.id === rtcStreamStats.codecId);
        const transport = stats.find((s) => s.type === 'transport' && s.id === rtcStreamStats.transportId);
        let roundTripTime;
        if (transport && transport.dtlsState === 'connected') {
            const candidatePair = stats.find((s) => s.type === 'candidate-pair' &&
                s.id === transport.selectedCandidatePairId);
            roundTripTime = candidatePair?.currentRoundTripTime;
        }
        let trackType;
        if (kind === 'publisher' && publisher) {
            const firefox = isFirefox();
            const mediaSource = stats.find((s) => s.type === 'media-source' &&
                // Firefox doesn't have mediaSourceId, so we need to guess the media source
                (firefox ? true : s.id === rtcStreamStats.mediaSourceId));
            if (mediaSource) {
                trackType = publisher.getTrackType(mediaSource.trackIdentifier);
            }
        }
        return {
            bytesSent: rtcStreamStats.bytesSent,
            bytesReceived: rtcStreamStats.bytesReceived,
            codec: codec?.mimeType,
            currentRoundTripTime: roundTripTime,
            frameHeight: rtcStreamStats.frameHeight,
            frameWidth: rtcStreamStats.frameWidth,
            framesPerSecond: rtcStreamStats.framesPerSecond,
            jitter: rtcStreamStats.jitter,
            kind: rtcStreamStats.kind,
            mediaSourceId: rtcStreamStats.mediaSourceId,
            qualityLimitationReason: rtcStreamStats.qualityLimitationReason,
            rid: rtcStreamStats.rid,
            ssrc: rtcStreamStats.ssrc,
            trackType,
        };
    });
    return {
        rawStats: report,
        streams,
        timestamp: Date.now(),
    };
};
const getEmptyStats = (stats) => {
    return {
        rawReport: stats ?? { streams: [], timestamp: Date.now() },
        totalBytesSent: 0,
        totalBytesReceived: 0,
        averageJitterInMs: 0,
        averageRoundTripTimeInMs: 0,
        qualityLimitationReasons: 'none',
        highestFrameWidth: 0,
        highestFrameHeight: 0,
        highestFramesPerSecond: 0,
        codec: '',
        codecPerTrackType: {},
        timestamp: Date.now(),
    };
};
/**
 * Aggregates generic stats.
 *
 * @param stats the stats to aggregate.
 */
const aggregate = (stats) => {
    const aggregatedStats = getEmptyStats(stats);
    let maxArea = -1;
    const area = (w, h) => w * h;
    const qualityLimitationReasons = new Set();
    const streams = stats.streams;
    const report = streams.reduce((acc, stream) => {
        acc.totalBytesSent += stream.bytesSent || 0;
        acc.totalBytesReceived += stream.bytesReceived || 0;
        acc.averageJitterInMs += stream.jitter || 0;
        acc.averageRoundTripTimeInMs += stream.currentRoundTripTime || 0;
        // naive calculation of the highest resolution
        const streamArea = area(stream.frameWidth || 0, stream.frameHeight || 0);
        if (streamArea > maxArea) {
            acc.highestFrameWidth = stream.frameWidth || 0;
            acc.highestFrameHeight = stream.frameHeight || 0;
            acc.highestFramesPerSecond = stream.framesPerSecond || 0;
            maxArea = streamArea;
        }
        qualityLimitationReasons.add(stream.qualityLimitationReason || '');
        return acc;
    }, aggregatedStats);
    if (streams.length > 0) {
        report.averageJitterInMs = Math.round((report.averageJitterInMs / streams.length) * 1000);
        report.averageRoundTripTimeInMs = Math.round((report.averageRoundTripTimeInMs / streams.length) * 1000);
        // we take the first codec we find, as it should be the same for all streams
        report.codec = streams[0].codec || '';
        report.codecPerTrackType = streams.reduce((acc, stream) => {
            if (stream.trackType) {
                acc[stream.trackType] = stream.codec || '';
            }
            return acc;
        }, {});
    }
    const qualityLimitationReason = [
        qualityLimitationReasons.has('cpu') && 'cpu',
        qualityLimitationReasons.has('bandwidth') && 'bandwidth',
        qualityLimitationReasons.has('other') && 'other',
    ]
        .filter(Boolean)
        .join(', ');
    if (qualityLimitationReason) {
        report.qualityLimitationReasons = qualityLimitationReason;
    }
    return report;
};

const version = "1.20.0";
const [major, minor, patch] = version.split('.');
let sdkInfo = {
    type: SdkType.PLAIN_JAVASCRIPT,
    major,
    minor,
    patch,
};
let osInfo;
let deviceInfo;
let webRtcInfo;
let deviceState = { oneofKind: undefined };
const setSdkInfo = (info) => {
    sdkInfo = info;
};
const getSdkInfo = () => {
    return sdkInfo;
};
const setOSInfo = (info) => {
    osInfo = info;
};
const setDeviceInfo = (info) => {
    deviceInfo = info;
};
const getWebRTCInfo = () => {
    return webRtcInfo;
};
const setWebRTCInfo = (info) => {
    webRtcInfo = info;
};
const setThermalState = (state) => {
    if (!osInfo) {
        deviceState = { oneofKind: undefined };
        return;
    }
    if (osInfo.name === 'android') {
        const thermalState = AndroidThermalState[state] ||
            AndroidThermalState.UNSPECIFIED;
        deviceState = {
            oneofKind: 'android',
            android: {
                thermalState,
                isPowerSaverMode: deviceState?.oneofKind === 'android' &&
                    deviceState.android.isPowerSaverMode,
            },
        };
    }
    if (osInfo.name.toLowerCase() === 'ios') {
        const thermalState = AppleThermalState[state] ||
            AppleThermalState.UNSPECIFIED;
        deviceState = {
            oneofKind: 'apple',
            apple: {
                thermalState,
                isLowPowerModeEnabled: deviceState?.oneofKind === 'apple' &&
                    deviceState.apple.isLowPowerModeEnabled,
            },
        };
    }
};
const setPowerState = (powerMode) => {
    if (!osInfo) {
        deviceState = { oneofKind: undefined };
        return;
    }
    if (osInfo.name === 'android') {
        deviceState = {
            oneofKind: 'android',
            android: {
                thermalState: deviceState?.oneofKind === 'android'
                    ? deviceState.android.thermalState
                    : AndroidThermalState.UNSPECIFIED,
                isPowerSaverMode: powerMode,
            },
        };
    }
    if (osInfo.name.toLowerCase() === 'ios') {
        deviceState = {
            oneofKind: 'apple',
            apple: {
                thermalState: deviceState?.oneofKind === 'apple'
                    ? deviceState.apple.thermalState
                    : AppleThermalState.UNSPECIFIED,
                isLowPowerModeEnabled: powerMode,
            },
        };
    }
};
const getDeviceState = () => {
    return deviceState;
};
const getClientDetails = async () => {
    if (isReactNative()) {
        // Since RN doesn't support web, sharing browser info is not required
        return {
            sdk: sdkInfo,
            os: osInfo,
            device: deviceInfo,
        };
    }
    // @ts-expect-error - userAgentData is not yet in the TS types
    const userAgentDataApi = navigator.userAgentData;
    let userAgentData;
    if (userAgentDataApi && userAgentDataApi.getHighEntropyValues) {
        try {
            userAgentData = await userAgentDataApi.getHighEntropyValues([
                'platform',
                'platformVersion',
            ]);
        }
        catch {
            // Ignore the error
        }
    }
    const userAgent = new uaParserJs.UAParser(navigator.userAgent);
    const { browser, os, device, cpu } = userAgent.getResult();
    return {
        sdk: sdkInfo,
        browser: {
            name: browser.name || navigator.userAgent,
            version: browser.version || '',
        },
        os: {
            name: userAgentData?.platform || os.name || '',
            version: userAgentData?.platformVersion || os.version || '',
            architecture: cpu.architecture || '',
        },
        device: {
            name: [device.vendor, device.model, device.type]
                .filter(Boolean)
                .join(' '),
            version: '',
        },
    };
};

class SfuStatsReporter {
    constructor(sfuClient, { options, clientDetails, subscriber, publisher, microphone, camera, state, }) {
        this.logger = getLogger(['SfuStatsReporter']);
        this.inputDevices = new Map();
        this.observeDevice = (device, kind) => {
            const { hasBrowserPermission$ } = device.state;
            this.unsubscribeDevicePermissionsSubscription?.();
            this.unsubscribeDevicePermissionsSubscription = createSubscription(rxjs.combineLatest([hasBrowserPermission$, this.state.ownCapabilities$]), ([hasPermission, ownCapabilities]) => {
                // cleanup the previous listDevices() subscription in case
                // permissions or capabilities have changed.
                // we will subscribe again if everything is in order.
                this.unsubscribeListDevicesSubscription?.();
                const hasCapability = kind === 'mic'
                    ? ownCapabilities.includes(OwnCapability.SEND_AUDIO)
                    : ownCapabilities.includes(OwnCapability.SEND_VIDEO);
                if (!hasPermission || !hasCapability) {
                    this.inputDevices.set(kind, {
                        currentDevice: '',
                        availableDevices: [],
                        isPermitted: false,
                    });
                    return;
                }
                this.unsubscribeListDevicesSubscription = createSubscription(rxjs.combineLatest([device.listDevices(), device.state.selectedDevice$]), ([devices, deviceId]) => {
                    const selected = devices.find((d) => d.deviceId === deviceId);
                    this.inputDevices.set(kind, {
                        currentDevice: selected?.label || deviceId || '',
                        availableDevices: devices.map((d) => d.label),
                        isPermitted: true,
                    });
                });
            });
        };
        this.sendConnectionTime = (connectionTimeSeconds) => {
            this.sendTelemetryData({
                data: {
                    oneofKind: 'connectionTimeSeconds',
                    connectionTimeSeconds,
                },
            });
        };
        this.sendReconnectionTime = (strategy, timeSeconds) => {
            this.sendTelemetryData({
                data: {
                    oneofKind: 'reconnection',
                    reconnection: { strategy, timeSeconds },
                },
            });
        };
        this.sendTelemetryData = (telemetryData) => {
            // intentionally not awaiting the promise here
            // to avoid impeding with the ongoing actions.
            this.run(telemetryData).catch((err) => {
                this.logger('warn', 'Failed to send telemetry data', err);
            });
        };
        this.run = async (telemetry) => {
            const [subscriberStats, publisherStats] = await Promise.all([
                this.subscriber.getStats().then(flatten).then(JSON.stringify),
                this.publisher?.getStats().then(flatten).then(JSON.stringify) ?? '[]',
            ]);
            const subscriberTrace = this.subscriber.getTrace();
            const publisherTrace = this.publisher?.getTrace();
            const mediaTrace = tracer.take();
            const sfuTrace = this.sfuClient.getTrace();
            const publisherTraces = [
                ...mediaTrace.snapshot,
                ...(sfuTrace?.snapshot ?? []),
                ...(publisherTrace?.snapshot ?? []),
            ];
            try {
                await this.sfuClient.sendStats({
                    sdk: this.sdkName,
                    sdkVersion: this.sdkVersion,
                    webrtcVersion: this.webRTCVersion,
                    subscriberStats,
                    subscriberRtcStats: subscriberTrace
                        ? JSON.stringify(subscriberTrace.snapshot)
                        : '',
                    publisherStats,
                    publisherRtcStats: publisherTraces.length > 0 ? JSON.stringify(publisherTraces) : '',
                    audioDevices: this.inputDevices.get('mic'),
                    videoDevices: this.inputDevices.get('camera'),
                    deviceState: getDeviceState(),
                    telemetry,
                });
            }
            catch (err) {
                publisherTrace?.rollback();
                subscriberTrace?.rollback();
                mediaTrace.rollback();
                sfuTrace?.rollback();
                throw err;
            }
        };
        this.start = () => {
            if (this.options.reporting_interval_ms <= 0)
                return;
            this.observeDevice(this.microphone, 'mic');
            this.observeDevice(this.camera, 'camera');
            clearInterval(this.intervalId);
            this.intervalId = setInterval(() => {
                this.run().catch((err) => {
                    this.logger('warn', 'Failed to report stats', err);
                });
            }, this.options.reporting_interval_ms);
        };
        this.stop = () => {
            this.unsubscribeDevicePermissionsSubscription?.();
            this.unsubscribeDevicePermissionsSubscription = undefined;
            this.unsubscribeListDevicesSubscription?.();
            this.unsubscribeListDevicesSubscription = undefined;
            this.inputDevices.clear();
            clearInterval(this.intervalId);
            this.intervalId = undefined;
        };
        this.sfuClient = sfuClient;
        this.options = options;
        this.subscriber = subscriber;
        this.publisher = publisher;
        this.microphone = microphone;
        this.camera = camera;
        this.state = state;
        const { sdk, browser } = clientDetails;
        this.sdkName = getSdkName(sdk);
        this.sdkVersion = getSdkVersion(sdk);
        // use the WebRTC version if set by the SDK (React Native) otherwise,
        // use the browser version as a fallback
        const webRTCInfo = getWebRTCInfo();
        this.webRTCVersion =
            webRTCInfo?.version ||
                `${browser?.name || ''}-${browser?.version || ''}` ||
                'N/A';
    }
}

const traceRTCPeerConnection = (pc, trace) => {
    pc.addEventListener('icecandidate', (e) => {
        trace('onicecandidate', e.candidate);
    });
    pc.addEventListener('track', (e) => {
        const streams = e.streams.map((stream) => `stream:${stream.id}`);
        trace('ontrack', `${e.track.kind}:${e.track.id} ${streams}`);
    });
    pc.addEventListener('signalingstatechange', () => {
        trace('onsignalingstatechange', pc.signalingState);
    });
    pc.addEventListener('iceconnectionstatechange', () => {
        trace('oniceconnectionstatechange', pc.iceConnectionState);
    });
    pc.addEventListener('icegatheringstatechange', () => {
        trace('onicegatheringstatechange', pc.iceGatheringState);
    });
    pc.addEventListener('connectionstatechange', () => {
        trace('onconnectionstatechange', pc.connectionState);
    });
    pc.addEventListener('negotiationneeded', () => {
        trace('onnegotiationneeded', undefined);
    });
    pc.addEventListener('datachannel', ({ channel }) => {
        trace('ondatachannel', [channel.id, channel.label]);
    });
    let prev = {};
    const getStats = () => {
        pc.getStats(null)
            .then((stats) => {
            const now = toObject(stats);
            trace('getstats', deltaCompression(prev, now));
            prev = now;
        })
            .catch((err) => {
            trace('getstatsOnFailure', err.toString());
        });
    };
    const interval = setInterval(() => {
        getStats();
    }, 8000);
    pc.addEventListener('connectionstatechange', () => {
        const state = pc.connectionState;
        if (state === 'connected' || state === 'failed') {
            getStats();
        }
    });
    const origClose = pc.close;
    pc.close = function tracedClose() {
        clearInterval(interval);
        trace('close', undefined);
        return origClose.call(this);
    };
    for (const method of [
        'createOffer',
        'createAnswer',
        'setLocalDescription',
        'setRemoteDescription',
        'addIceCandidate',
    ]) {
        const original = pc[method];
        if (!original)
            continue;
        // @ts-expect-error we don't use deprecated APIs
        pc[method] = async function tracedMethod(...args) {
            try {
                trace(method, args);
                // @ts-expect-error improper types
                const result = await original.apply(this, args);
                trace(`${method}OnSuccess`, result);
                return result;
            }
            catch (err) {
                trace(`${method}OnFailure`, err.toString());
                throw err;
            }
        };
    }
};
const toObject = (s) => {
    const obj = {};
    s.forEach((v, k) => {
        obj[k] = v;
    });
    return obj;
};
/**
 * Apply delta compression to the stats report.
 * Reduces size by ~90%.
 * To reduce further, report keys could be compressed.
 */
const deltaCompression = (oldStats, newStats) => {
    newStats = JSON.parse(JSON.stringify(newStats));
    for (const [id, report] of Object.entries(newStats)) {
        delete report.id;
        if (!oldStats[id])
            continue;
        for (const [name, value] of Object.entries(report)) {
            if (value === oldStats[id][name]) {
                delete report[name];
            }
        }
    }
    let timestamp = -Infinity;
    for (const report of Object.values(newStats)) {
        if (report.timestamp > timestamp) {
            timestamp = report.timestamp;
        }
    }
    for (const report of Object.values(newStats)) {
        if (report.timestamp === timestamp) {
            report.timestamp = 0;
        }
    }
    newStats.timestamp = timestamp;
    return newStats;
};

/**
 * A base class for the `Publisher` and `Subscriber` classes.
 * @internal
 */
class BasePeerConnection {
    /**
     * Constructs a new `BasePeerConnection` instance.
     */
    constructor(peerType, { sfuClient, connectionConfig, state, dispatcher, onUnrecoverableError, logTag, clientDetails, enableTracing, }) {
        this.isIceRestarting = false;
        this.isDisposed = false;
        this.subscriptions = [];
        /**
         * Handles events synchronously.
         * Consecutive events are queued and executed one after the other.
         */
        this.on = (event, fn) => {
            this.subscriptions.push(this.dispatcher.on(event, (e) => {
                withoutConcurrency(`pc.${event}`, async () => fn(e)).catch((err) => {
                    if (this.isDisposed)
                        return;
                    this.logger('warn', `Error handling ${event}`, err);
                });
            }));
        };
        /**
         * Appends the trickled ICE candidates to the `RTCPeerConnection`.
         */
        this.addTrickledIceCandidates = () => {
            const { iceTrickleBuffer } = this.sfuClient;
            const observable = this.peerType === PeerType.SUBSCRIBER
                ? iceTrickleBuffer.subscriberCandidates
                : iceTrickleBuffer.publisherCandidates;
            this.unsubscribeIceTrickle?.();
            this.unsubscribeIceTrickle = createSafeAsyncSubscription(observable, async (candidate) => {
                return this.pc.addIceCandidate(candidate).catch((e) => {
                    if (this.isDisposed)
                        return;
                    this.logger('warn', `ICE candidate error`, e, candidate);
                });
            });
        };
        /**
         * Sets the SFU client to use.
         *
         * @param sfuClient the SFU client to use.
         */
        this.setSfuClient = (sfuClient) => {
            this.sfuClient = sfuClient;
        };
        /**
         * Returns the result of the `RTCPeerConnection.getStats()` method
         * @param selector an optional `MediaStreamTrack` to get the stats for.
         */
        this.getStats = (selector) => {
            return this.pc.getStats(selector);
        };
        /**
         * Returns the current tracing buffer.
         */
        this.getTrace = () => {
            return this.tracer?.take();
        };
        /**
         * Handles the ICECandidate event and
         * Initiates an ICE Trickle process with the SFU.
         */
        this.onIceCandidate = (e) => {
            const { candidate } = e;
            if (!candidate) {
                this.logger('debug', 'null ice candidate');
                return;
            }
            const iceCandidate = this.asJSON(candidate);
            this.sfuClient
                .iceTrickle({ peerType: this.peerType, iceCandidate })
                .catch((err) => {
                if (this.isDisposed)
                    return;
                this.logger('warn', `ICETrickle failed`, err);
            });
        };
        /**
         * Converts the ICE candidate to a JSON string.
         */
        this.asJSON = (candidate) => {
            if (!candidate.usernameFragment) {
                // react-native-webrtc doesn't include usernameFragment in the candidate
                const segments = candidate.candidate.split(' ');
                const ufragIndex = segments.findIndex((s) => s === 'ufrag') + 1;
                const usernameFragment = segments[ufragIndex];
                return JSON.stringify({ ...candidate, usernameFragment });
            }
            return JSON.stringify(candidate.toJSON());
        };
        /**
         * Handles the ICE connection state change event.
         */
        this.onIceConnectionStateChange = () => {
            const state = this.pc.iceConnectionState;
            this.logger('debug', `ICE connection state changed`, state);
            if (this.state.callingState === exports.CallingState.OFFLINE)
                return;
            if (this.state.callingState === exports.CallingState.RECONNECTING)
                return;
            // do nothing when ICE is restarting
            if (this.isIceRestarting)
                return;
            if (state === 'failed' || state === 'disconnected') {
                this.logger('debug', `Attempting to restart ICE`);
                this.restartIce().catch((e) => {
                    if (this.isDisposed)
                        return;
                    const reason = `ICE restart failed`;
                    this.logger('error', reason, e);
                    this.onUnrecoverableError?.(`${reason}: ${e}`);
                });
            }
        };
        /**
         * Handles the ICE candidate error event.
         */
        this.onIceCandidateError = (e) => {
            const errorMessage = e instanceof RTCPeerConnectionIceErrorEvent &&
                `${e.errorCode}: ${e.errorText}`;
            const iceState = this.pc.iceConnectionState;
            const logLevel = iceState === 'connected' || iceState === 'checking' ? 'debug' : 'warn';
            this.logger(logLevel, `ICE Candidate error`, errorMessage);
        };
        /**
         * Handles the ICE gathering state change event.
         */
        this.onIceGatherChange = () => {
            this.logger('debug', `ICE Gathering State`, this.pc.iceGatheringState);
        };
        /**
         * Handles the signaling state change event.
         */
        this.onSignalingChange = () => {
            this.logger('debug', `Signaling state changed`, this.pc.signalingState);
        };
        this.peerType = peerType;
        this.sfuClient = sfuClient;
        this.state = state;
        this.dispatcher = dispatcher;
        this.onUnrecoverableError = onUnrecoverableError;
        this.logger = getLogger([
            peerType === PeerType.SUBSCRIBER ? 'Subscriber' : 'Publisher',
            logTag,
        ]);
        this.pc = new RTCPeerConnection(connectionConfig);
        if (enableTracing) {
            const tag = `${logTag}-${peerType === PeerType.SUBSCRIBER ? 'sub' : 'pub'}`;
            this.tracer = new Tracer(tag);
            this.tracer.trace('clientDetails', clientDetails);
            this.tracer.trace('create', connectionConfig);
            traceRTCPeerConnection(this.pc, this.tracer.trace);
        }
        this.pc.addEventListener('icecandidate', this.onIceCandidate);
        this.pc.addEventListener('icecandidateerror', this.onIceCandidateError);
        this.pc.addEventListener('iceconnectionstatechange', this.onIceConnectionStateChange);
        this.pc.addEventListener('icegatheringstatechange', this.onIceGatherChange);
        this.pc.addEventListener('signalingstatechange', this.onSignalingChange);
    }
    /**
     * Disposes the `RTCPeerConnection` instance.
     */
    dispose() {
        this.onUnrecoverableError = undefined;
        this.isDisposed = true;
        this.detachEventHandlers();
        this.pc.close();
        this.tracer?.dispose();
    }
    /**
     * Detaches the event handlers from the `RTCPeerConnection`.
     */
    detachEventHandlers() {
        this.pc.removeEventListener('icecandidate', this.onIceCandidate);
        this.pc.removeEventListener('icecandidateerror', this.onIceCandidateError);
        this.pc.removeEventListener('signalingstatechange', this.onSignalingChange);
        this.pc.removeEventListener('iceconnectionstatechange', this.onIceConnectionStateChange);
        this.pc.removeEventListener('icegatheringstatechange', this.onIceGatherChange);
        this.unsubscribeIceTrickle?.();
        this.subscriptions.forEach((unsubscribe) => unsubscribe());
    }
}

class TransceiverCache {
    constructor() {
        this.cache = [];
        this.layers = [];
        /**
         * An array maintaining the order how transceivers were added to the peer connection.
         * This is needed because some browsers (Firefox) don't reliably report
         * trackId and `mid` parameters.
         */
        this.transceiverOrder = [];
        /**
         * Adds a transceiver to the cache.
         */
        this.add = (publishOption, transceiver) => {
            this.cache.push({ publishOption, transceiver });
            this.transceiverOrder.push(transceiver);
        };
        /**
         * Gets the transceiver for the given publish option.
         */
        this.get = (publishOption) => {
            return this.findTransceiver(publishOption)?.transceiver;
        };
        /**
         * Checks if the cache has the given publish option.
         */
        this.has = (publishOption) => {
            return !!this.get(publishOption);
        };
        /**
         * Finds the first transceiver that satisfies the given predicate.
         */
        this.find = (predicate) => {
            return this.cache.find(predicate);
        };
        /**
         * Provides all the items in the cache.
         */
        this.items = () => {
            return this.cache;
        };
        /**
         * Init index of the transceiver in the cache.
         */
        this.indexOf = (transceiver) => {
            return this.transceiverOrder.indexOf(transceiver);
        };
        /**
         * Gets cached video layers for the given track.
         */
        this.getLayers = (publishOption) => {
            const entry = this.layers.find((item) => item.publishOption.id === publishOption.id &&
                item.publishOption.trackType === publishOption.trackType);
            return entry?.layers;
        };
        /**
         * Sets the video layers for the given track.
         */
        this.setLayers = (publishOption, layers = []) => {
            const entry = this.findLayer(publishOption);
            if (entry) {
                entry.layers = layers;
            }
            else {
                this.layers.push({ publishOption, layers });
            }
        };
        this.findTransceiver = (publishOption) => {
            return this.cache.find((item) => item.publishOption.id === publishOption.id &&
                item.publishOption.trackType === publishOption.trackType);
        };
        this.findLayer = (publishOption) => {
            return this.layers.find((item) => item.publishOption.id === publishOption.id &&
                item.publishOption.trackType === publishOption.trackType);
        };
    }
}

const ensureExhausted = (x, message) => {
    getLogger(['helpers'])('warn', message, x);
};

const trackTypeToParticipantStreamKey = (trackType) => {
    switch (trackType) {
        case TrackType.SCREEN_SHARE:
            return 'screenShareStream';
        case TrackType.SCREEN_SHARE_AUDIO:
            return 'screenShareAudioStream';
        case TrackType.VIDEO:
            return 'videoStream';
        case TrackType.AUDIO:
            return 'audioStream';
        case TrackType.UNSPECIFIED:
            throw new Error('Track type is unspecified');
        default:
            ensureExhausted(trackType, 'Unknown track type');
    }
};
const muteTypeToTrackType = (muteType) => {
    switch (muteType) {
        case 'audio':
            return TrackType.AUDIO;
        case 'video':
            return TrackType.VIDEO;
        case 'screenshare':
            return TrackType.SCREEN_SHARE;
        case 'screenshare_audio':
            return TrackType.SCREEN_SHARE_AUDIO;
        default:
            ensureExhausted(muteType, 'Unknown mute type');
    }
};
const toTrackType = (trackType) => {
    switch (trackType) {
        case 'TRACK_TYPE_AUDIO':
            return TrackType.AUDIO;
        case 'TRACK_TYPE_VIDEO':
            return TrackType.VIDEO;
        case 'TRACK_TYPE_SCREEN_SHARE':
            return TrackType.SCREEN_SHARE;
        case 'TRACK_TYPE_SCREEN_SHARE_AUDIO':
            return TrackType.SCREEN_SHARE_AUDIO;
        default:
            return undefined;
    }
};
const isAudioTrackType = (trackType) => trackType === TrackType.AUDIO || trackType === TrackType.SCREEN_SHARE_AUDIO;

const defaultBitratePerRid = {
    q: 300000,
    h: 750000,
    f: 1250000,
};
/**
 * In SVC, we need to send only one video encoding (layer).
 * this layer will have the additional spatial and temporal layers
 * defined via the scalabilityMode property.
 *
 * @param layers the layers to process.
 */
const toSvcEncodings = (layers) => {
    if (!layers)
        return;
    // we take the highest quality layer, and we assign it to `q` encoder.
    const withRid = (rid) => (l) => l.rid === rid;
    const highestLayer = layers.find(withRid('f')) ||
        layers.find(withRid('h')) ||
        layers.find(withRid('q'));
    return [{ ...highestLayer, rid: 'q' }];
};
/**
 * Converts the rid to a video quality.
 */
const ridToVideoQuality = (rid) => {
    return rid === 'q'
        ? VideoQuality.LOW_UNSPECIFIED
        : rid === 'h'
            ? VideoQuality.MID
            : VideoQuality.HIGH; // default to HIGH
};
/**
 * Converts the given video layers to SFU video layers.
 */
const toVideoLayers = (layers = []) => {
    return layers.map((layer) => ({
        rid: layer.rid || '',
        bitrate: layer.maxBitrate || 0,
        fps: layer.maxFramerate || 0,
        quality: ridToVideoQuality(layer.rid || ''),
        videoDimension: { width: layer.width, height: layer.height },
    }));
};
/**
 * Converts the spatial and temporal layers to a scalability mode.
 */
const toScalabilityMode = (spatialLayers, temporalLayers) => `L${spatialLayers}T${temporalLayers}${spatialLayers > 1 ? '_KEY' : ''}`;
/**
 * Determines the most optimal video layers for the given track.
 *
 * @param videoTrack the video track to find optimal layers for.
 * @param publishOption the publish options for the track.
 */
const computeVideoLayers = (videoTrack, publishOption) => {
    if (isAudioTrackType(publishOption.trackType))
        return;
    const optimalVideoLayers = [];
    const settings = videoTrack.getSettings();
    const { width = 0, height = 0 } = settings;
    const { bitrate, codec, fps, maxSpatialLayers = 3, maxTemporalLayers = 3, videoDimension = { width: 1280, height: 720 }, } = publishOption;
    const maxBitrate = getComputedMaxBitrate(videoDimension, width, height, bitrate);
    let downscaleFactor = 1;
    let bitrateFactor = 1;
    const svcCodec = isSvcCodec(codec?.name);
    for (const rid of ['f', 'h', 'q'].slice(0, maxSpatialLayers)) {
        const layer = {
            active: true,
            rid,
            width: Math.round(width / downscaleFactor),
            height: Math.round(height / downscaleFactor),
            maxBitrate: Math.round(maxBitrate / bitrateFactor) || defaultBitratePerRid[rid],
            maxFramerate: fps,
        };
        if (svcCodec) {
            // for SVC codecs, we need to set the scalability mode, and the
            // codec will handle the rest (layers, temporal layers, etc.)
            layer.scalabilityMode = toScalabilityMode(maxSpatialLayers, maxTemporalLayers);
        }
        else {
            // for non-SVC codecs, we need to downscale proportionally (simulcast)
            layer.scaleResolutionDownBy = downscaleFactor;
        }
        downscaleFactor *= 2;
        bitrateFactor *= 2;
        // Reversing the order [f, h, q] to [q, h, f] as Chrome uses encoding index
        // when deciding which layer to disable when CPU or bandwidth is constrained.
        // Encodings should be ordered in increasing spatial resolution order.
        optimalVideoLayers.unshift(layer);
    }
    // for simplicity, we start with all layers enabled, then this function
    // will clear/reassign the layers that are not needed
    return withSimulcastConstraints(settings, optimalVideoLayers);
};
/**
 * Computes the maximum bitrate for a given resolution.
 * If the current resolution is lower than the target resolution,
 * we want to proportionally reduce the target bitrate.
 * If the current resolution is higher than the target resolution,
 * we want to use the target bitrate.
 *
 * @param targetResolution the target resolution.
 * @param currentWidth the current width of the track.
 * @param currentHeight the current height of the track.
 * @param bitrate the target bitrate.
 */
const getComputedMaxBitrate = (targetResolution, currentWidth, currentHeight, bitrate) => {
    // if the current resolution is lower than the target resolution,
    // we want to proportionally reduce the target bitrate
    const { width: targetWidth, height: targetHeight } = targetResolution;
    if (currentWidth < targetWidth || currentHeight < targetHeight) {
        const currentPixels = currentWidth * currentHeight;
        const targetPixels = targetWidth * targetHeight;
        const reductionFactor = currentPixels / targetPixels;
        return Math.round(bitrate * reductionFactor);
    }
    return bitrate;
};
/**
 * Browsers have different simulcast constraints for different video resolutions.
 *
 * This function modifies the provided list of video layers according to the
 * current implementation of simulcast constraints in the Chromium based browsers.
 *
 * https://chromium.googlesource.com/external/webrtc/+/refs/heads/main/media/engine/simulcast.cc#90
 */
const withSimulcastConstraints = (settings, optimalVideoLayers) => {
    let layers;
    const size = Math.max(settings.width || 0, settings.height || 0);
    if (size <= 320) {
        // provide only one layer 320x240 (q), the one with the highest quality
        layers = optimalVideoLayers.filter((layer) => layer.rid === 'f');
    }
    else if (size <= 640) {
        // provide two layers, 160x120 (q) and 640x480 (h)
        layers = optimalVideoLayers.filter((layer) => layer.rid !== 'h');
    }
    else {
        // provide three layers for sizes > 640x480
        layers = optimalVideoLayers;
    }
    const ridMapping = ['q', 'h', 'f'];
    return layers.map((layer, index) => ({
        ...layer,
        rid: ridMapping[index], // reassign rid
    }));
};

/**
 * Extracts the mid from the transceiver or the SDP.
 *
 * @param transceiver the transceiver.
 * @param transceiverInitIndex the index of the transceiver in the transceiver's init array.
 * @param sdp the SDP.
 */
const extractMid = (transceiver, transceiverInitIndex, sdp) => {
    if (transceiver.mid)
        return transceiver.mid;
    if (!sdp)
        return String(transceiverInitIndex);
    const track = transceiver.sender.track;
    const parsedSdp = sdpTransform.parse(sdp);
    const media = parsedSdp.media.find((m) => {
        return (m.type === track.kind &&
            // if `msid` is not present, we assume that the track is the first one
            (m.msid?.includes(track.id) ?? true));
    });
    if (typeof media?.mid !== 'undefined')
        return String(media.mid);
    if (transceiverInitIndex < 0)
        return '';
    return String(transceiverInitIndex);
};

/**
 * The `Publisher` is responsible for publishing/unpublishing media streams to/from the SFU
 *
 * @internal
 */
class Publisher extends BasePeerConnection {
    /**
     * Constructs a new `Publisher` instance.
     */
    constructor({ publishOptions, ...baseOptions }) {
        super(PeerType.PUBLISHER_UNSPECIFIED, baseOptions);
        this.transceiverCache = new TransceiverCache();
        this.clonedTracks = new Set();
        /**
         * Starts publishing the given track of the given media stream.
         *
         * Consecutive calls to this method will replace the stream.
         * The previous stream will be stopped.
         *
         * @param track the track to publish.
         * @param trackType the track type to publish.
         */
        this.publish = async (track, trackType) => {
            if (!this.publishOptions.some((o) => o.trackType === trackType)) {
                throw new Error(`No publish options found for ${TrackType[trackType]}`);
            }
            for (const publishOption of this.publishOptions) {
                if (publishOption.trackType !== trackType)
                    continue;
                // create a clone of the track as otherwise the same trackId will
                // appear in the SDP in multiple transceivers
                const trackToPublish = this.cloneTrack(track);
                const transceiver = this.transceiverCache.get(publishOption);
                if (!transceiver) {
                    await this.addTransceiver(trackToPublish, publishOption);
                }
                else {
                    const previousTrack = transceiver.sender.track;
                    await transceiver.sender.replaceTrack(trackToPublish);
                    if (!isReactNative()) {
                        this.stopTrack(previousTrack);
                    }
                }
            }
        };
        /**
         * Adds a new transceiver carrying the given track to the peer connection.
         */
        this.addTransceiver = async (track, publishOption) => {
            const videoEncodings = computeVideoLayers(track, publishOption);
            const sendEncodings = isSvcCodec(publishOption.codec?.name)
                ? toSvcEncodings(videoEncodings)
                : videoEncodings;
            const transceiver = this.pc.addTransceiver(track, {
                direction: 'sendonly',
                sendEncodings,
            });
            const trackType = publishOption.trackType;
            this.logger('debug', `Added ${TrackType[trackType]} transceiver`);
            this.transceiverCache.add(publishOption, transceiver);
            await this.negotiate();
        };
        /**
         * Synchronizes the current Publisher state with the provided publish options.
         */
        this.syncPublishOptions = async () => {
            // enable publishing with new options -> [av1, vp9]
            for (const publishOption of this.publishOptions) {
                const { trackType } = publishOption;
                if (!this.isPublishing(trackType))
                    continue;
                if (this.transceiverCache.has(publishOption))
                    continue;
                const item = this.transceiverCache.find((i) => !!i.transceiver.sender.track &&
                    i.publishOption.trackType === trackType);
                if (!item || !item.transceiver)
                    continue;
                // take the track from the existing transceiver for the same track type,
                // clone it and publish it with the new publish options
                const track = this.cloneTrack(item.transceiver.sender.track);
                await this.addTransceiver(track, publishOption);
            }
            // stop publishing with options not required anymore -> [vp9]
            for (const item of this.transceiverCache.items()) {
                const { publishOption, transceiver } = item;
                const hasPublishOption = this.publishOptions.some((option) => option.id === publishOption.id &&
                    option.trackType === publishOption.trackType);
                if (hasPublishOption)
                    continue;
                // it is safe to stop the track here, it is a clone
                this.stopTrack(transceiver.sender.track);
                await transceiver.sender.replaceTrack(null);
            }
        };
        /**
         * Returns true if the given track type is currently being published to the SFU.
         *
         * @param trackType the track type to check.
         */
        this.isPublishing = (trackType) => {
            for (const item of this.transceiverCache.items()) {
                if (item.publishOption.trackType !== trackType)
                    continue;
                const track = item.transceiver.sender.track;
                if (!track)
                    continue;
                if (track.readyState === 'live' && track.enabled)
                    return true;
            }
            return false;
        };
        /**
         * Maps the given track ID to the corresponding track type.
         */
        this.getTrackType = (trackId) => {
            for (const transceiverId of this.transceiverCache.items()) {
                const { publishOption, transceiver } = transceiverId;
                if (transceiver.sender.track?.id === trackId) {
                    return publishOption.trackType;
                }
            }
            return undefined;
        };
        /**
         * Stops the cloned track that is being published to the SFU.
         */
        this.stopTracks = (...trackTypes) => {
            for (const item of this.transceiverCache.items()) {
                const { publishOption, transceiver } = item;
                if (!trackTypes.includes(publishOption.trackType))
                    continue;
                this.stopTrack(transceiver.sender.track);
            }
        };
        /**
         * Stops all the cloned tracks that are being published to the SFU.
         */
        this.stopAllTracks = () => {
            for (const { transceiver } of this.transceiverCache.items()) {
                this.stopTrack(transceiver.sender.track);
            }
            for (const track of this.clonedTracks) {
                this.stopTrack(track);
            }
        };
        this.changePublishQuality = async (videoSender) => {
            const { trackType, layers, publishOptionId } = videoSender;
            const enabledLayers = layers.filter((l) => l.active);
            const tag = 'Update publish quality:';
            this.logger('info', `${tag} requested layers by SFU:`, enabledLayers);
            const transceiverId = this.transceiverCache.find((t) => t.publishOption.id === publishOptionId &&
                t.publishOption.trackType === trackType);
            const sender = transceiverId?.transceiver.sender;
            if (!sender) {
                return this.logger('warn', `${tag} no video sender found.`);
            }
            const params = sender.getParameters();
            if (params.encodings.length === 0) {
                return this.logger('warn', `${tag} there are no encodings set.`);
            }
            const codecInUse = transceiverId?.publishOption.codec?.name;
            const usesSvcCodec = codecInUse && isSvcCodec(codecInUse);
            let changed = false;
            for (const encoder of params.encodings) {
                const layer = usesSvcCodec
                    ? // for SVC, we only have one layer (q) and often rid is omitted
                        enabledLayers[0]
                    : // for non-SVC, we need to find the layer by rid (simulcast)
                        (enabledLayers.find((l) => l.name === encoder.rid) ??
                            (params.encodings.length === 1 ? enabledLayers[0] : undefined));
                // flip 'active' flag only when necessary
                const shouldActivate = !!layer?.active;
                if (shouldActivate !== encoder.active) {
                    encoder.active = shouldActivate;
                    changed = true;
                }
                // skip the rest of the settings if the layer is disabled or not found
                if (!layer)
                    continue;
                const { maxFramerate, scaleResolutionDownBy, maxBitrate, scalabilityMode, } = layer;
                if (scaleResolutionDownBy >= 1 &&
                    scaleResolutionDownBy !== encoder.scaleResolutionDownBy) {
                    encoder.scaleResolutionDownBy = scaleResolutionDownBy;
                    changed = true;
                }
                if (maxBitrate > 0 && maxBitrate !== encoder.maxBitrate) {
                    encoder.maxBitrate = maxBitrate;
                    changed = true;
                }
                if (maxFramerate > 0 && maxFramerate !== encoder.maxFramerate) {
                    encoder.maxFramerate = maxFramerate;
                    changed = true;
                }
                // @ts-expect-error scalabilityMode is not in the typedefs yet
                if (scalabilityMode && scalabilityMode !== encoder.scalabilityMode) {
                    // @ts-expect-error scalabilityMode is not in the typedefs yet
                    encoder.scalabilityMode = scalabilityMode;
                    changed = true;
                }
            }
            const activeEncoders = params.encodings.filter((e) => e.active);
            if (!changed) {
                return this.logger('info', `${tag} no change:`, activeEncoders);
            }
            await sender.setParameters(params);
            this.logger('info', `${tag} enabled rids:`, activeEncoders);
        };
        /**
         * Restarts the ICE connection and renegotiates with the SFU.
         */
        this.restartIce = async () => {
            this.logger('debug', 'Restarting ICE connection');
            const signalingState = this.pc.signalingState;
            if (this.isIceRestarting || signalingState === 'have-local-offer') {
                this.logger('debug', 'ICE restart is already in progress');
                return;
            }
            await this.negotiate({ iceRestart: true });
        };
        /**
         * Initiates a new offer/answer exchange with the currently connected SFU.
         *
         * @param options the optional offer options to use.
         */
        this.negotiate = async (options) => {
            return withoutConcurrency('publisher.negotiate', async () => {
                const offer = await this.pc.createOffer(options);
                const tracks = this.getAnnouncedTracks(offer.sdp);
                if (!tracks.length)
                    throw new Error(`Can't negotiate without any tracks`);
                try {
                    this.isIceRestarting = options?.iceRestart ?? false;
                    await this.pc.setLocalDescription(offer);
                    const { sdp = '' } = offer;
                    const { response } = await this.sfuClient.setPublisher({ sdp, tracks });
                    if (response.error)
                        throw new Error(response.error.message);
                    const { sdp: answerSdp } = response;
                    await this.pc.setRemoteDescription({ type: 'answer', sdp: answerSdp });
                }
                finally {
                    this.isIceRestarting = false;
                }
                this.addTrickledIceCandidates();
            });
        };
        /**
         * Returns a list of tracks that are currently being published.
         */
        this.getPublishedTracks = () => {
            const tracks = [];
            for (const { transceiver } of this.transceiverCache.items()) {
                const track = transceiver.sender.track;
                if (track && track.readyState === 'live')
                    tracks.push(track);
            }
            return tracks;
        };
        /**
         * Returns a list of tracks that are currently being published.
         * @param sdp an optional SDP to extract the `mid` from.
         */
        this.getAnnouncedTracks = (sdp) => {
            const trackInfos = [];
            for (const bundle of this.transceiverCache.items()) {
                const { transceiver, publishOption } = bundle;
                const track = transceiver.sender.track;
                if (!track)
                    continue;
                trackInfos.push(this.toTrackInfo(transceiver, publishOption, sdp));
            }
            return trackInfos;
        };
        /**
         * Returns a list of tracks that are currently being published.
         * This method shall be used for the reconnection flow.
         * There we shouldn't announce the tracks that have been stopped due to a codec switch.
         */
        this.getAnnouncedTracksForReconnect = () => {
            const sdp = this.pc.localDescription?.sdp;
            const trackInfos = [];
            for (const publishOption of this.publishOptions) {
                const transceiver = this.transceiverCache.get(publishOption);
                if (!transceiver || !transceiver.sender.track)
                    continue;
                trackInfos.push(this.toTrackInfo(transceiver, publishOption, sdp));
            }
            return trackInfos;
        };
        /**
         * Converts the given transceiver to a `TrackInfo` object.
         */
        this.toTrackInfo = (transceiver, publishOption, sdp) => {
            const track = transceiver.sender.track;
            const isTrackLive = track.readyState === 'live';
            const layers = isTrackLive
                ? computeVideoLayers(track, publishOption)
                : this.transceiverCache.getLayers(publishOption);
            this.transceiverCache.setLayers(publishOption, layers);
            const isAudioTrack = isAudioTrackType(publishOption.trackType);
            const isStereo = isAudioTrack && track.getSettings().channelCount === 2;
            const transceiverIndex = this.transceiverCache.indexOf(transceiver);
            const audioSettings = this.state.settings?.audio;
            return {
                trackId: track.id,
                layers: toVideoLayers(layers),
                trackType: publishOption.trackType,
                mid: extractMid(transceiver, transceiverIndex, sdp),
                stereo: isStereo,
                dtx: isAudioTrack && !!audioSettings?.opus_dtx_enabled,
                red: isAudioTrack && !!audioSettings?.redundant_coding_enabled,
                muted: !isTrackLive,
                codec: publishOption.codec,
                publishOptionId: publishOption.id,
            };
        };
        this.cloneTrack = (track) => {
            const clone = track.clone();
            this.clonedTracks.add(clone);
            return clone;
        };
        this.stopTrack = (track) => {
            if (!track)
                return;
            track.stop();
            this.clonedTracks.delete(track);
        };
        this.publishOptions = publishOptions;
        this.on('iceRestart', (iceRestart) => {
            if (iceRestart.peerType !== PeerType.PUBLISHER_UNSPECIFIED)
                return;
            this.restartIce().catch((err) => {
                const reason = `ICE restart failed`;
                this.logger('warn', reason, err);
                this.onUnrecoverableError?.(`${reason}: ${err}`);
            });
        });
        this.on('changePublishQuality', async (event) => {
            for (const videoSender of event.videoSenders) {
                await this.changePublishQuality(videoSender);
            }
        });
        this.on('changePublishOptions', (event) => {
            this.publishOptions = event.publishOptions;
            return this.syncPublishOptions();
        });
    }
    /**
     * Disposes this Publisher instance.
     */
    dispose() {
        super.dispose();
        this.stopAllTracks();
        this.clonedTracks.clear();
    }
}

/**
 * A wrapper around the `RTCPeerConnection` that handles the incoming
 * media streams from the SFU.
 *
 * @internal
 */
class Subscriber extends BasePeerConnection {
    /**
     * Constructs a new `Subscriber` instance.
     */
    constructor(opts) {
        super(PeerType.SUBSCRIBER, opts);
        /**
         * Restarts the ICE connection and renegotiates with the SFU.
         */
        this.restartIce = async () => {
            this.logger('debug', 'Restarting ICE connection');
            if (this.pc.signalingState === 'have-remote-offer') {
                this.logger('debug', 'ICE restart is already in progress');
                return;
            }
            if (this.pc.connectionState === 'new') {
                this.logger('debug', `ICE connection is not yet established, skipping restart.`);
                return;
            }
            const previousIsIceRestarting = this.isIceRestarting;
            try {
                this.isIceRestarting = true;
                await this.sfuClient.iceRestart({
                    peerType: PeerType.SUBSCRIBER,
                });
            }
            catch (e) {
                // restore the previous state, as our intent for restarting ICE failed
                this.isIceRestarting = previousIsIceRestarting;
                throw e;
            }
        };
        this.handleOnTrack = (e) => {
            const [primaryStream] = e.streams;
            // example: `e3f6aaf8-b03d-4911-be36-83f47d37a76a:TRACK_TYPE_VIDEO`
            const [trackId, rawTrackType] = primaryStream.id.split(':');
            const participantToUpdate = this.state.participants.find((p) => p.trackLookupPrefix === trackId);
            this.logger('debug', `[onTrack]: Got remote ${rawTrackType} track for userId: ${participantToUpdate?.userId}`, e.track.id, e.track);
            const trackDebugInfo = `${participantToUpdate?.userId} ${rawTrackType}:${trackId}`;
            e.track.addEventListener('mute', () => {
                this.logger('info', `[onTrack]: Track muted: ${trackDebugInfo}`);
            });
            e.track.addEventListener('unmute', () => {
                this.logger('info', `[onTrack]: Track unmuted: ${trackDebugInfo}`);
            });
            e.track.addEventListener('ended', () => {
                this.logger('info', `[onTrack]: Track ended: ${trackDebugInfo}`);
                this.state.removeOrphanedTrack(primaryStream.id);
            });
            const trackType = toTrackType(rawTrackType);
            if (!trackType) {
                return this.logger('error', `Unknown track type: ${rawTrackType}`);
            }
            if (!participantToUpdate) {
                this.logger('warn', `[onTrack]: Received track for unknown participant: ${trackId}`, e);
                this.state.registerOrphanedTrack({
                    id: primaryStream.id,
                    trackLookupPrefix: trackId,
                    track: primaryStream,
                    trackType,
                });
                return;
            }
            const streamKindProp = trackTypeToParticipantStreamKey(trackType);
            if (!streamKindProp) {
                this.logger('error', `Unknown track type: ${rawTrackType}`);
                return;
            }
            // get the previous stream to dispose it later
            // usually this happens during migration, when the stream is replaced
            // with a new one but the old one is still in the state
            const previousStream = participantToUpdate[streamKindProp];
            // replace the previous stream with the new one, prevents flickering
            this.state.updateParticipant(participantToUpdate.sessionId, {
                [streamKindProp]: primaryStream,
            });
            // now, dispose the previous stream if it exists
            if (previousStream) {
                this.logger('info', `[onTrack]: Cleaning up previous remote ${e.track.kind} tracks for userId: ${participantToUpdate.userId}`);
                previousStream.getTracks().forEach((t) => {
                    t.stop();
                    previousStream.removeTrack(t);
                });
            }
        };
        this.negotiate = async (subscriberOffer) => {
            await this.pc.setRemoteDescription({
                type: 'offer',
                sdp: subscriberOffer.sdp,
            });
            this.addTrickledIceCandidates();
            const answer = await this.pc.createAnswer();
            await this.pc.setLocalDescription(answer);
            await this.sfuClient.sendAnswer({
                peerType: PeerType.SUBSCRIBER,
                sdp: answer.sdp || '',
            });
            this.isIceRestarting = false;
        };
        this.pc.addEventListener('track', this.handleOnTrack);
        this.on('subscriberOffer', async (subscriberOffer) => {
            return this.negotiate(subscriberOffer).catch((err) => {
                this.logger('error', `Negotiation failed.`, err);
            });
        });
    }
    /**
     * Detaches the event handlers from the `RTCPeerConnection`.
     * This is useful when we want to replace the `RTCPeerConnection`
     * instance with a new one (in case of migration).
     */
    detachEventHandlers() {
        super.detachEventHandlers();
        this.pc.removeEventListener('track', this.handleOnTrack);
    }
}

const createWebSocketSignalChannel = (opts) => {
    const { endpoint, onMessage, logTag } = opts;
    const logger = getLogger(['SfuClientWS', logTag]);
    logger('debug', 'Creating signaling WS channel:', endpoint);
    const ws = new WebSocket(endpoint);
    ws.binaryType = 'arraybuffer'; // do we need this?
    ws.addEventListener('error', (e) => {
        logger('error', 'Signaling WS channel error', e);
    });
    ws.addEventListener('close', (e) => {
        logger('info', 'Signaling WS channel is closed', e);
    });
    ws.addEventListener('open', (e) => {
        logger('info', 'Signaling WS channel is open', e);
    });
    ws.addEventListener('message', (e) => {
        try {
            const message = e.data instanceof ArrayBuffer
                ? SfuEvent.fromBinary(new Uint8Array(e.data))
                : SfuEvent.fromJsonString(e.data.toString());
            onMessage(message);
        }
        catch (err) {
            logger('error', 'Failed to decode a message. Check whether the Proto models match.', { event: e, error: err });
        }
    });
    return ws;
};

const toRtcConfiguration = (config) => {
    return {
        bundlePolicy: 'max-bundle',
        iceServers: config.map((ice) => ({
            urls: ice.urls,
            username: ice.username,
            credential: ice.password,
        })),
    };
};

/**
 * Saving a long-lived reference to a promise that can reject can be unsafe,
 * since rejecting the promise causes an unhandled rejection error (even if the
 * rejection is handled everywhere promise result is expected).
 *
 * To avoid that, we add both resolution and rejection handlers to the promise.
 * That way, the saved promise never rejects. A callback is provided as return
 * value to build a *new* promise, that resolves and rejects along with
 * the original promise.
 * @param promise Promise to wrap, which possibly rejects
 * @returns Callback to build a new promise, which resolves and rejects along
 * with the original promise
 */
function makeSafePromise(promise) {
    let isPending = true;
    const safePromise = promise
        .then((result) => ({ status: 'resolved', result }), (error) => ({ status: 'rejected', error }))
        .finally(() => (isPending = false));
    const unwrapPromise = () => safePromise.then((fulfillment) => {
        if (fulfillment.status === 'rejected')
            throw fulfillment.error;
        return fulfillment.result;
    });
    unwrapPromise.checkPending = () => isPending;
    return unwrapPromise;
}
/**
 * Creates a new promise with resolvers.
 *
 * Based on:
 * - https://github.com/tc39/proposal-promise-with-resolvers/blob/main/polyfills.js
 */
const promiseWithResolvers = () => {
    let resolve;
    let reject;
    const promise = new Promise((_resolve, _reject) => {
        resolve = _resolve;
        reject = _reject;
    });
    let isResolved = false;
    let isRejected = false;
    const resolver = (value) => {
        isResolved = true;
        resolve(value);
    };
    const rejecter = (reason) => {
        isRejected = true;
        reject(reason);
    };
    return {
        promise,
        resolve: resolver,
        reject: rejecter,
        isResolved: () => isResolved,
        isRejected: () => isRejected,
    };
};

const uninitialized = Symbol('uninitialized');
/**
 * Lazily creates a value using a provided factory
 */
function lazy(factory) {
    let value = uninitialized;
    return () => {
        if (value === uninitialized) {
            value = factory();
        }
        return value;
    };
}

// Do not modify this file manually. Instead, edit worker.ts
// and the run ./generate-timer-worker.sh
const timerWorker = {
    src: `const timerIdMapping = new Map();
self.addEventListener('message', (event) => {
    const request = event.data;
    switch (request.type) {
        case 'setTimeout':
        case 'setInterval':
            timerIdMapping.set(request.id, (request.type === 'setTimeout' ? setTimeout : setInterval)(() => {
                tick(request.id);
                if (request.type === 'setTimeout') {
                    timerIdMapping.delete(request.id);
                }
            }, request.timeout));
            break;
        case 'clearTimeout':
        case 'clearInterval':
            (request.type === 'clearTimeout' ? clearTimeout : clearInterval)(timerIdMapping.get(request.id));
            timerIdMapping.delete(request.id);
            break;
    }
});
function tick(id) {
    const message = { type: 'tick', id };
    self.postMessage(message);
}`,
};

class TimerWorker {
    constructor() {
        this.currentTimerId = 1;
        this.callbacks = new Map();
        this.fallback = false;
    }
    setup({ useTimerWorker = true } = {}) {
        if (!useTimerWorker) {
            this.fallback = true;
            return;
        }
        try {
            const source = timerWorker.src;
            const blob = new Blob([source], {
                type: 'application/javascript; charset=utf-8',
            });
            const script = URL.createObjectURL(blob);
            this.worker = new Worker(script, { name: 'str-timer-worker' });
            this.worker.addEventListener('message', (event) => {
                const { type, id } = event.data;
                if (type === 'tick') {
                    this.callbacks.get(id)?.();
                }
            });
        }
        catch (err) {
            getLogger(['timer-worker'])('error', err);
            this.fallback = true;
        }
    }
    destroy() {
        this.callbacks.clear();
        this.worker?.terminate();
        this.worker = undefined;
        this.fallback = false;
    }
    get ready() {
        return this.fallback || Boolean(this.worker);
    }
    setInterval(callback, timeout) {
        return this.setTimer('setInterval', callback, timeout);
    }
    clearInterval(id) {
        this.clearTimer('clearInterval', id);
    }
    setTimeout(callback, timeout) {
        return this.setTimer('setTimeout', callback, timeout);
    }
    clearTimeout(id) {
        this.clearTimer('clearTimeout', id);
    }
    setTimer(type, callback, timeout) {
        if (!this.ready) {
            this.setup();
        }
        if (this.fallback) {
            return (type === 'setTimeout' ? setTimeout : setInterval)(callback, timeout);
        }
        const id = this.getTimerId();
        this.callbacks.set(id, () => {
            callback();
            // Timeouts are one-off operations, so no need to keep callback reference
            // after timer has fired
            if (type === 'setTimeout') {
                this.callbacks.delete(id);
            }
        });
        this.sendMessage({ type, id, timeout });
        return id;
    }
    clearTimer(type, id) {
        if (!id) {
            return;
        }
        if (!this.ready) {
            this.setup();
        }
        if (this.fallback) {
            (type === 'clearTimeout' ? clearTimeout : clearInterval)(id);
            return;
        }
        this.callbacks.delete(id);
        this.sendMessage({ type, id });
    }
    getTimerId() {
        return this.currentTimerId++;
    }
    sendMessage(message) {
        if (!this.worker) {
            throw new Error("Cannot use timer worker before it's set up");
        }
        this.worker.postMessage(message);
    }
}
let timerWorkerEnabled = false;
const enableTimerWorker = () => {
    timerWorkerEnabled = true;
};
const getTimers = lazy(() => {
    const instance = new TimerWorker();
    instance.setup({ useTimerWorker: timerWorkerEnabled });
    return instance;
});

/**
 * The client used for exchanging information with the SFU.
 */
class StreamSfuClient {
    /**
     * Constructs a new SFU client.
     */
    constructor({ dispatcher, credentials, sessionId, logTag, joinResponseTimeout = 5000, onSignalClose, streamClient, enableTracing, }) {
        /**
         * A buffer for ICE Candidates that are received before
         * the Publisher and Subscriber Peer Connections are ready to handle them.
         */
        this.iceTrickleBuffer = new IceTrickleBuffer();
        /**
         * Flag to indicate if the client is in the process of leaving the call.
         * This is set to `true` when the user initiates the leave process.
         */
        this.isLeaving = false;
        /**
         * Flag to indicate if the client is in the process of closing the connection.
         */
        this.isClosing = false;
        this.pingIntervalInMs = 10 * 1000;
        this.unhealthyTimeoutInMs = this.pingIntervalInMs + 5 * 1000;
        /**
         * Promise that resolves when the JoinResponse is received.
         * Rejects after a certain threshold if the response is not received.
         */
        this.joinResponseTask = promiseWithResolvers();
        /**
         * A controller to abort the current requests.
         */
        this.abortController = new AbortController();
        this.createWebSocket = () => {
            this.signalWs = createWebSocketSignalChannel({
                logTag: this.logTag,
                endpoint: `${this.credentials.server.ws_endpoint}?tag=${this.logTag}`,
                onMessage: (message) => {
                    this.lastMessageTimestamp = new Date();
                    this.scheduleConnectionCheck();
                    this.dispatcher.dispatch(message, this.logTag);
                },
            });
            this.signalReady = makeSafePromise(Promise.race([
                new Promise((resolve, reject) => {
                    const onOpen = () => {
                        this.signalWs.removeEventListener('open', onOpen);
                        resolve(this.signalWs);
                    };
                    this.signalWs.addEventListener('open', onOpen);
                    this.signalWs.addEventListener('close', (e) => {
                        this.handleWebSocketClose(e);
                        // Normally, this shouldn't have any effect, because WS should never emit 'close'
                        // before emitting 'open'. However, strager things have happened, and we don't
                        // want to leave signalReady in pending state.
                        reject(new Error('SFU WS closed unexpectedly'));
                    });
                }),
                new Promise((resolve, reject) => {
                    setTimeout(() => reject(new Error('SFU WS connection timed out')), this.joinResponseTimeout);
                }),
            ]));
        };
        this.cleanUpWebSocket = () => {
            this.signalWs.removeEventListener('close', this.handleWebSocketClose);
        };
        this.handleWebSocketClose = (e) => {
            this.signalWs.removeEventListener('close', this.handleWebSocketClose);
            getTimers().clearInterval(this.keepAliveInterval);
            clearTimeout(this.connectionCheckTimeout);
            this.onSignalClose?.(`${e.code} ${e.reason}`);
        };
        this.close = (code = StreamSfuClient.NORMAL_CLOSURE, reason) => {
            this.isClosing = true;
            if (this.signalWs.readyState === WebSocket.OPEN) {
                this.logger('debug', `Closing SFU WS connection: ${code} - ${reason}`);
                this.signalWs.close(code, `js-client: ${reason}`);
                this.cleanUpWebSocket();
            }
            this.dispose();
        };
        this.dispose = () => {
            this.logger('debug', 'Disposing SFU client');
            this.unsubscribeIceTrickle();
            this.unsubscribeNetworkChanged();
            clearInterval(this.keepAliveInterval);
            clearTimeout(this.connectionCheckTimeout);
            clearTimeout(this.migrateAwayTimeout);
            this.abortController.abort();
            this.migrationTask?.resolve();
            this.iceTrickleBuffer.dispose();
        };
        this.getTrace = () => {
            return this.tracer?.take();
        };
        this.leaveAndClose = async (reason) => {
            await this.joinTask;
            try {
                this.isLeaving = true;
                await this.notifyLeave(reason);
            }
            catch (err) {
                this.logger('debug', 'Error notifying SFU about leaving call', err);
            }
            this.close(StreamSfuClient.NORMAL_CLOSURE, reason.substring(0, 115));
        };
        this.updateSubscriptions = async (tracks) => {
            await this.joinTask;
            return retryable(() => this.rpc.updateSubscriptions({ sessionId: this.sessionId, tracks }), this.abortController.signal);
        };
        this.setPublisher = async (data) => {
            await this.joinTask;
            return retryable(() => this.rpc.setPublisher({ ...data, sessionId: this.sessionId }), this.abortController.signal);
        };
        this.sendAnswer = async (data) => {
            await this.joinTask;
            return retryable(() => this.rpc.sendAnswer({ ...data, sessionId: this.sessionId }), this.abortController.signal);
        };
        this.iceTrickle = async (data) => {
            await this.joinTask;
            return retryable(() => this.rpc.iceTrickle({ ...data, sessionId: this.sessionId }), this.abortController.signal);
        };
        this.iceRestart = async (data) => {
            await this.joinTask;
            return retryable(() => this.rpc.iceRestart({ ...data, sessionId: this.sessionId }), this.abortController.signal);
        };
        this.updateMuteStates = async (muteStates) => {
            await this.joinTask;
            return retryable(() => this.rpc.updateMuteStates({ muteStates, sessionId: this.sessionId }), this.abortController.signal);
        };
        this.sendStats = async (stats) => {
            await this.joinTask;
            return retryable(() => this.rpc.sendStats({ ...stats, sessionId: this.sessionId }), this.abortController.signal);
        };
        this.startNoiseCancellation = async () => {
            await this.joinTask;
            return retryable(() => this.rpc.startNoiseCancellation({ sessionId: this.sessionId }), this.abortController.signal);
        };
        this.stopNoiseCancellation = async () => {
            await this.joinTask;
            return retryable(() => this.rpc.stopNoiseCancellation({ sessionId: this.sessionId }), this.abortController.signal);
        };
        this.enterMigration = async (opts = {}) => {
            this.isLeaving = true;
            const { timeout = 7 * 1000 } = opts;
            this.migrationTask?.reject(new Error('Cancelled previous migration'));
            const task = (this.migrationTask = promiseWithResolvers());
            const unsubscribe = this.dispatcher.on('participantMigrationComplete', () => {
                unsubscribe();
                clearTimeout(this.migrateAwayTimeout);
                task.resolve();
            });
            this.migrateAwayTimeout = setTimeout(() => {
                unsubscribe();
                task.reject(new Error(`Migration (${this.logTag}) failed to complete in ${timeout}ms`));
            }, timeout);
            return task.promise;
        };
        this.join = async (data) => {
            // wait for the signal web socket to be ready before sending "joinRequest"
            await this.signalReady();
            if (this.joinResponseTask.isResolved() ||
                this.joinResponseTask.isRejected()) {
                // we need to lock the RPC requests until we receive a JoinResponse.
                // that's why we have this primitive lock mechanism.
                // the client starts with already initialized joinResponseTask,
                // and this code creates a new one for the next join request.
                this.joinResponseTask = promiseWithResolvers();
            }
            // capture a reference to the current joinResponseTask as it might
            // be replaced with a new one in case a second join request is made
            const current = this.joinResponseTask;
            let timeoutId = undefined;
            const unsubscribe = this.dispatcher.on('joinResponse', (joinResponse) => {
                this.logger('debug', 'Received joinResponse', joinResponse);
                clearTimeout(timeoutId);
                unsubscribe();
                this.keepAlive();
                current.resolve(joinResponse);
            });
            timeoutId = setTimeout(() => {
                unsubscribe();
                current.reject(new Error('Waiting for "joinResponse" has timed out'));
            }, this.joinResponseTimeout);
            await this.send(SfuRequest.create({
                requestPayload: {
                    oneofKind: 'joinRequest',
                    joinRequest: JoinRequest.create({
                        ...data,
                        sessionId: this.sessionId,
                        token: this.credentials.token,
                    }),
                },
            }));
            return current.promise;
        };
        this.ping = async () => {
            return this.send(SfuRequest.create({
                requestPayload: {
                    oneofKind: 'healthCheckRequest',
                    healthCheckRequest: {},
                },
            }));
        };
        this.notifyLeave = async (reason) => {
            return this.send(SfuRequest.create({
                requestPayload: {
                    oneofKind: 'leaveCallRequest',
                    leaveCallRequest: {
                        sessionId: this.sessionId,
                        reason,
                    },
                },
            }));
        };
        this.send = async (message) => {
            await this.signalReady(); // wait for the signal ws to be open
            const msgJson = SfuRequest.toJson(message);
            if (this.signalWs.readyState !== WebSocket.OPEN) {
                this.logger('debug', 'Signal WS is not open. Skipping message', msgJson);
                return;
            }
            this.logger('debug', `Sending message to: ${this.edgeName}`, msgJson);
            this.signalWs.send(SfuRequest.toBinary(message));
        };
        this.keepAlive = () => {
            const timers = getTimers();
            timers.clearInterval(this.keepAliveInterval);
            this.keepAliveInterval = timers.setInterval(() => {
                this.ping().catch((e) => {
                    this.logger('error', 'Error sending healthCheckRequest to SFU', e);
                });
            }, this.pingIntervalInMs);
        };
        this.scheduleConnectionCheck = () => {
            clearTimeout(this.connectionCheckTimeout);
            this.connectionCheckTimeout = setTimeout(() => {
                if (this.lastMessageTimestamp) {
                    const timeSinceLastMessage = new Date().getTime() - this.lastMessageTimestamp.getTime();
                    if (timeSinceLastMessage > this.unhealthyTimeoutInMs) {
                        this.close(StreamSfuClient.ERROR_CONNECTION_UNHEALTHY, `SFU connection unhealthy. Didn't receive any message for ${this.unhealthyTimeoutInMs}ms`);
                    }
                }
            }, this.unhealthyTimeoutInMs);
        };
        this.dispatcher = dispatcher;
        this.sessionId = sessionId || generateUUIDv4();
        this.onSignalClose = onSignalClose;
        this.credentials = credentials;
        const { server, token } = credentials;
        this.edgeName = server.edge_name;
        this.joinResponseTimeout = joinResponseTimeout;
        this.logTag = logTag;
        this.logger = getLogger(['SfuClient', logTag]);
        this.tracer = enableTracing ? new Tracer(logTag) : undefined;
        this.rpc = createSignalClient({
            baseUrl: server.url,
            interceptors: [
                withHeaders({ Authorization: `Bearer ${token}` }),
                this.tracer && withRequestTracer(this.tracer.trace),
                getLogLevel() === 'trace' && withRequestLogger(this.logger, 'trace'),
            ].filter((v) => !!v),
        });
        // Special handling for the ICETrickle kind of events.
        // The SFU might trigger these events before the initial RTC
        // connection is established or "JoinResponse" received.
        // In that case, those events (ICE candidates) need to be buffered
        // and later added to the appropriate PeerConnection
        // once the remoteDescription is known and set.
        this.unsubscribeIceTrickle = dispatcher.on('iceTrickle', (iceTrickle) => {
            this.iceTrickleBuffer.push(iceTrickle);
        });
        // listen to network changes to handle offline state
        // we shouldn't attempt to recover websocket connection when offline
        this.unsubscribeNetworkChanged = streamClient.on('network.changed', (e) => {
            if (!e.online) {
                this.networkAvailableTask = promiseWithResolvers();
            }
            else {
                this.networkAvailableTask?.resolve();
            }
        });
        this.createWebSocket();
    }
    get isHealthy() {
        return (this.signalWs.readyState === WebSocket.OPEN &&
            this.joinResponseTask.isResolved());
    }
    get joinTask() {
        return this.joinResponseTask.promise;
    }
}
/**
 * The normal closure code. Used for controlled shutdowns.
 */
StreamSfuClient.NORMAL_CLOSURE = 1000;
/**
 * The error code used when the SFU connection is unhealthy.
 * Usually, this means that no message has been received from the SFU for
 * a certain amount of time (`connectionCheckTimeout`).
 */
StreamSfuClient.ERROR_CONNECTION_UNHEALTHY = 4001;
/**
 * The error code used when the SFU connection is disposed because a new
 * connection is established or is about to be established.
 * Here, we don't use 1000 (normal closure) because we don't want the
 * SFU to clean up the resources associated with the current participant.
 */
StreamSfuClient.DISPOSE_OLD_SOCKET = 4002;

/**
 * Event handler that watched the delivery of `call.accepted`.
 * Once the event is received, the call is joined.
 */
const watchCallAccepted = (call) => {
    return async function onCallAccepted(event) {
        // We want to discard the event if it's from the current user
        if (event.user.id === call.currentUserId)
            return;
        const { state } = call;
        if (event.call.created_by.id === call.currentUserId &&
            state.callingState === exports.CallingState.RINGING) {
            await call.join();
        }
    };
};
/**
 * Event handler that watches delivery of `call.rejected` Websocket event.
 * Once the event is received, the call is left.
 */
const watchCallRejected = (call) => {
    return async function onCallRejected(event) {
        // We want to discard the event if it's from the current user
        if (event.user.id === call.currentUserId)
            return;
        const { call: eventCall } = event;
        const { session: callSession } = eventCall;
        if (!callSession) {
            call.logger('warn', 'No call session provided. Ignoring call.rejected event.', event);
            return;
        }
        const rejectedBy = callSession.rejected_by;
        const { members, callingState } = call.state;
        if (callingState !== exports.CallingState.RINGING) {
            call.logger('info', 'Call is not in ringing mode (it is either accepted or rejected already). Ignoring call.rejected event.', event);
            return;
        }
        if (call.isCreatedByMe) {
            const everyoneElseRejected = members
                .filter((m) => m.user_id !== call.currentUserId)
                .every((m) => rejectedBy[m.user_id]);
            if (everyoneElseRejected) {
                call.logger('info', 'everyone rejected, leaving the call');
                await call.leave({ reason: 'ring: everyone rejected' });
            }
        }
        else {
            if (rejectedBy[eventCall.created_by.id]) {
                call.logger('info', 'call creator rejected, leaving call');
                await call.leave({ reason: 'ring: creator rejected' });
            }
        }
    };
};
/**
 * Event handler that watches the delivery of `call.ended` Websocket event.
 */
const watchCallEnded = (call) => {
    return function onCallEnded() {
        const { callingState } = call.state;
        if (callingState !== exports.CallingState.IDLE &&
            callingState !== exports.CallingState.LEFT) {
            call
                .leave({ reason: 'call.ended event received', reject: false })
                .catch((err) => {
                call.logger('error', 'Failed to leave call after call.ended ', err);
            });
        }
    };
};
/**
 * Watches for `callEnded` events.
 */
const watchSfuCallEnded = (call) => {
    return call.on('callEnded', async (e) => {
        if (call.state.callingState === exports.CallingState.LEFT)
            return;
        try {
            // `call.ended` event arrived after the call is already left
            // and all event handlers are detached. We need to manually
            // update the call state to reflect the call has ended.
            call.state.setEndedAt(new Date());
            const reason = CallEndedReason[e.reason];
            await call.leave({ reason: `callEnded received: ${reason}` });
        }
        catch (err) {
            call.logger('error', 'Failed to leave call after being ended by the SFU', err);
        }
    });
};

/**
 * Event handler that watches for `callGrantsUpdated` events.
 *
 * @param state the call state to update.
 */
const watchCallGrantsUpdated = (state) => {
    return function onCallGrantsUpdated(event) {
        const { currentGrants } = event;
        if (currentGrants) {
            const { canPublishAudio, canPublishVideo, canScreenshare } = currentGrants;
            const update = {
                [OwnCapability.SEND_AUDIO]: canPublishAudio,
                [OwnCapability.SEND_VIDEO]: canPublishVideo,
                [OwnCapability.SCREENSHARE]: canScreenshare,
            };
            const nextCapabilities = state.ownCapabilities.filter((capability) => update[capability] !== false);
            Object.entries(update).forEach(([capability, value]) => {
                if (value && !nextCapabilities.includes(capability)) {
                    nextCapabilities.push(capability);
                }
            });
            state.setOwnCapabilities(nextCapabilities);
        }
    };
};

const watchConnectionQualityChanged = (dispatcher, state) => {
    return dispatcher.on('connectionQualityChanged', (e) => {
        const { connectionQualityUpdates } = e;
        if (!connectionQualityUpdates)
            return;
        state.updateParticipants(connectionQualityUpdates.reduce((patches, update) => {
            const { sessionId, connectionQuality } = update;
            patches[sessionId] = {
                connectionQuality,
            };
            return patches;
        }, {}));
    });
};
/**
 * Updates the approximate number of participants in the call by peeking at the
 * health check events that our SFU sends.
 */
const watchParticipantCountChanged = (dispatcher, state) => {
    return dispatcher.on('healthCheckResponse', (e) => {
        const { participantCount } = e;
        if (participantCount) {
            state.setParticipantCount(participantCount.total);
            state.setAnonymousParticipantCount(participantCount.anonymous);
        }
    });
};
const watchLiveEnded = (dispatcher, call) => {
    return dispatcher.on('error', (e) => {
        if (e.error && e.error.code !== ErrorCode.LIVE_ENDED)
            return;
        call.state.setBackstage(true);
        if (!call.permissionsContext.hasPermission(OwnCapability.JOIN_BACKSTAGE)) {
            call.leave({ reason: 'live ended' }).catch((err) => {
                call.logger('error', 'Failed to leave call after live ended', err);
            });
        }
    });
};
/**
 * Watches and logs the errors reported by the currently connected SFU.
 */
const watchSfuErrorReports = (dispatcher) => {
    return dispatcher.on('error', (e) => {
        if (!e.error)
            return;
        const logger = getLogger(['SfuClient']);
        const { error, reconnectStrategy } = e;
        logger('error', 'SFU reported error', {
            code: ErrorCode[error.code],
            reconnectStrategy: WebsocketReconnectStrategy[reconnectStrategy],
            message: error.message,
            shouldRetry: error.shouldRetry,
        });
    });
};
/**
 * Watches for `pinsUpdated` events and updates the pinned state of participants
 * in the call.
 */
const watchPinsUpdated = (state) => {
    return function onPinsUpdated(e) {
        const { pins } = e;
        state.setServerSidePins(pins);
    };
};

/**
 * An event handler that handles soft mutes.
 *
 * @param call the call.
 */
const handleRemoteSoftMute = (call) => {
    return call.on('trackUnpublished', async (event) => {
        const { cause, type, sessionId } = event;
        const { localParticipant } = call.state;
        if (cause === TrackUnpublishReason.MODERATION &&
            sessionId === localParticipant?.sessionId) {
            const logger = call.logger;
            logger('info', `Local participant's ${TrackType[type]} track is muted remotely`);
            try {
                if (type === TrackType.VIDEO) {
                    await call.camera.disable();
                }
                else if (type === TrackType.AUDIO) {
                    await call.microphone.disable();
                }
                else if (type === TrackType.SCREEN_SHARE ||
                    type === TrackType.SCREEN_SHARE_AUDIO) {
                    await call.screenShare.disable();
                }
                else {
                    logger('warn', 'Unsupported track type to soft mute', TrackType[type]);
                }
            }
            catch (error) {
                logger('error', 'Failed to stop publishing', error);
            }
        }
    });
};

/**
 * Adds unique values to an array.
 *
 * @param arr the array to add to.
 * @param values the values to add.
 */
const pushToIfMissing = (arr, ...values) => {
    for (const v of values) {
        if (!arr.includes(v)) {
            arr.push(v);
        }
    }
    return arr;
};

/**
 * An event responder which handles the `participantJoined` event.
 */
const watchParticipantJoined = (state) => {
    return function onParticipantJoined(e) {
        const { participant } = e;
        if (!participant)
            return;
        // `state.updateOrAddParticipant` acts as a safeguard against
        // potential duplicate events from the SFU.
        //
        // Although the SFU should not send duplicate events, we have seen
        // some race conditions in the past during the `join-flow`.
        // The SFU would send participant info as part of the `join`
        // response and then follow up with a `participantJoined` event for
        // already announced participants.
        const orphanedTracks = reconcileOrphanedTracks(state, participant);
        state.updateOrAddParticipant(participant.sessionId, Object.assign(participant, orphanedTracks, {
            viewportVisibilityState: {
                videoTrack: exports.VisibilityState.UNKNOWN,
                screenShareTrack: exports.VisibilityState.UNKNOWN,
            },
        }));
    };
};
/**
 * An event responder which handles the `participantLeft` event.
 */
const watchParticipantLeft = (state) => {
    return function onParticipantLeft(e) {
        const { participant } = e;
        if (!participant)
            return;
        state.setParticipants((participants) => participants.filter((p) => p.sessionId !== participant.sessionId));
    };
};
/**
 * An event responder which handles the `participantUpdated` event.
 */
const watchParticipantUpdated = (state) => {
    return function onParticipantUpdated(e) {
        const { participant } = e;
        if (!participant)
            return;
        state.updateParticipant(participant.sessionId, participant);
    };
};
/**
 * An event responder which handles the `trackPublished` event.
 * The SFU will send this event when a participant publishes a track.
 */
const watchTrackPublished = (state) => {
    return function onTrackPublished(e) {
        const { type, sessionId } = e;
        // An optimization for large calls.
        // After a certain threshold, the SFU would stop emitting `participantJoined`
        // events, and instead, it would only provide the participant's information
        // once they start publishing a track.
        if (e.participant) {
            const orphanedTracks = reconcileOrphanedTracks(state, e.participant);
            const participant = Object.assign(e.participant, orphanedTracks);
            state.updateOrAddParticipant(sessionId, participant);
        }
        else {
            state.updateParticipant(sessionId, (p) => ({
                publishedTracks: pushToIfMissing([...p.publishedTracks], type),
            }));
        }
    };
};
/**
 * An event responder which handles the `trackUnpublished` event.
 * The SFU will send this event when a participant unpublishes a track.
 */
const watchTrackUnpublished = (state) => {
    return function onTrackUnpublished(e) {
        const { type, sessionId } = e;
        // An optimization for large calls. See `watchTrackPublished`.
        if (e.participant) {
            const orphanedTracks = reconcileOrphanedTracks(state, e.participant);
            const participant = Object.assign(e.participant, orphanedTracks);
            state.updateOrAddParticipant(sessionId, participant);
        }
        else {
            state.updateParticipant(sessionId, (p) => ({
                publishedTracks: p.publishedTracks.filter((t) => t !== type),
            }));
        }
    };
};
/**
 * Reconciles orphaned tracks (if any) for the given participant.
 *
 * @param state the call state.
 * @param participant the participant.
 */
const reconcileOrphanedTracks = (state, participant) => {
    const orphanTracks = state.takeOrphanedTracks(participant.trackLookupPrefix);
    if (!orphanTracks.length)
        return;
    const reconciledTracks = {};
    for (const orphan of orphanTracks) {
        const key = trackTypeToParticipantStreamKey(orphan.trackType);
        if (!key)
            continue;
        reconciledTracks[key] = orphan.track;
    }
    return reconciledTracks;
};

/**
 * Watches for `dominantSpeakerChanged` events.
 */
const watchDominantSpeakerChanged = (dispatcher, state) => {
    return dispatcher.on('dominantSpeakerChanged', (e) => {
        const { sessionId } = e;
        if (sessionId === state.dominantSpeaker?.sessionId)
            return;
        state.setParticipants((participants) => participants.map((participant) => {
            // mark the new dominant speaker
            if (participant.sessionId === sessionId) {
                return {
                    ...participant,
                    isDominantSpeaker: true,
                };
            }
            // unmark the old dominant speaker
            if (participant.isDominantSpeaker) {
                return {
                    ...participant,
                    isDominantSpeaker: false,
                };
            }
            return participant; // no change
        }));
    });
};
/**
 * Watches for `audioLevelChanged` events.
 */
const watchAudioLevelChanged = (dispatcher, state) => {
    return dispatcher.on('audioLevelChanged', (e) => {
        const { audioLevels } = e;
        state.updateParticipants(audioLevels.reduce((patches, current) => {
            patches[current.sessionId] = {
                audioLevel: current.level,
                isSpeaking: current.isSpeaking,
            };
            return patches;
        }, {}));
    });
};

/**
 * Registers the default event handlers for a call during its lifecycle.
 *
 * @param call the call to register event handlers for.
 * @param dispatcher the dispatcher.
 */
const registerEventHandlers = (call, dispatcher) => {
    const state = call.state;
    const eventHandlers = [
        call.on('call.ended', watchCallEnded(call)),
        watchSfuCallEnded(call),
        watchLiveEnded(dispatcher, call),
        watchSfuErrorReports(dispatcher),
        watchConnectionQualityChanged(dispatcher, state),
        watchParticipantCountChanged(dispatcher, state),
        call.on('participantJoined', watchParticipantJoined(state)),
        call.on('participantLeft', watchParticipantLeft(state)),
        call.on('participantUpdated', watchParticipantUpdated(state)),
        call.on('trackPublished', watchTrackPublished(state)),
        call.on('trackUnpublished', watchTrackUnpublished(state)),
        watchAudioLevelChanged(dispatcher, state),
        watchDominantSpeakerChanged(dispatcher, state),
        call.on('callGrantsUpdated', watchCallGrantsUpdated(state)),
        call.on('pinsUpdated', watchPinsUpdated(state)),
        handleRemoteSoftMute(call),
    ];
    if (call.ringing) {
        // these events are only relevant when the call is ringing
        eventHandlers.push(registerRingingCallEventHandlers(call));
    }
    return () => {
        eventHandlers.forEach((unsubscribe) => unsubscribe());
    };
};
/**
 * Registers event handlers for a call that is of ringing type.
 *
 * @param call the call to register event handlers for.
 */
const registerRingingCallEventHandlers = (call) => {
    const coordinatorRingEvents = {
        'call.accepted': watchCallAccepted(call),
        'call.rejected': watchCallRejected(call),
    };
    const eventHandlers = Object.keys(coordinatorRingEvents).map((event) => {
        const eventName = event;
        return call.on(eventName, coordinatorRingEvents[eventName]);
    });
    return () => {
        eventHandlers.forEach((unsubscribe) => unsubscribe());
    };
};

const DEFAULT_THRESHOLD = 0.35;
class ViewportTracker {
    constructor() {
        /**
         * @private
         */
        this.elementHandlerMap = new Map();
        /**
         * @private
         */
        this.observer = null;
        // in React children render before viewport is set, add
        // them to the queue and observe them once the observer is ready
        /**
         * @private
         */
        this.queueSet = new Set();
        /**
         * Method to set scrollable viewport as root for the IntersectionObserver, returns
         * cleanup function to be invoked upon disposing of the DOM element to prevent memory leaks
         *
         * @param viewportElement
         * @param options
         * @returns Unobserve
         */
        this.setViewport = (viewportElement, options) => {
            const cleanup = () => {
                this.observer?.disconnect();
                this.observer = null;
                this.elementHandlerMap.clear();
            };
            this.observer = new IntersectionObserver((entries) => {
                entries.forEach((entry) => {
                    const handler = this.elementHandlerMap.get(entry.target);
                    handler?.(entry);
                });
            }, {
                root: viewportElement,
                ...options,
                threshold: options?.threshold ?? DEFAULT_THRESHOLD,
            });
            if (this.queueSet.size) {
                this.queueSet.forEach(([queueElement, queueHandler]) => {
                    // check if element which requested observation is
                    // a child of a viewport element, skip if isn't
                    if (!viewportElement.contains(queueElement))
                        return;
                    this.observer.observe(queueElement);
                    this.elementHandlerMap.set(queueElement, queueHandler);
                });
                this.queueSet.clear();
            }
            return cleanup;
        };
        /**
         * Method to set element to observe and handler to be triggered whenever IntersectionObserver
         * detects a possible change in element's visibility within specified viewport, returns
         * cleanup function to be invoked upon disposing of the DOM element to prevent memory leaks
         *
         * @param element
         * @param handler
         * @returns Unobserve
         */
        this.observe = (element, handler) => {
            const queueItem = [element, handler];
            const cleanup = () => {
                this.elementHandlerMap.delete(element);
                this.observer?.unobserve(element);
                this.queueSet.delete(queueItem);
            };
            if (this.elementHandlerMap.has(element))
                return cleanup;
            if (!this.observer) {
                this.queueSet.add(queueItem);
                return cleanup;
            }
            if (this.observer.root.contains(element)) {
                this.elementHandlerMap.set(element, handler);
                this.observer.observe(element);
            }
            return cleanup;
        };
    }
}

const DEFAULT_VIEWPORT_VISIBILITY_STATE = {
    videoTrack: exports.VisibilityState.UNKNOWN,
    screenShareTrack: exports.VisibilityState.UNKNOWN,
};
const globalOverrideKey = Symbol('globalOverrideKey');
/**
 * A manager class that handles dynascale related tasks like:
 *
 * - binding video elements to session ids
 * - binding audio elements to session ids
 * - tracking element visibility
 * - updating subscriptions based on viewport visibility
 * - updating subscriptions based on video element dimensions
 * - updating subscriptions based on published tracks
 */
class DynascaleManager {
    /**
     * Creates a new DynascaleManager instance.
     */
    constructor(callState, speaker) {
        /**
         * The viewport tracker instance.
         */
        this.viewportTracker = new ViewportTracker();
        this.logger = getLogger(['DynascaleManager']);
        this.pendingSubscriptionsUpdate = null;
        this.videoTrackSubscriptionOverridesSubject = new rxjs.BehaviorSubject({});
        this.videoTrackSubscriptionOverrides$ = this.videoTrackSubscriptionOverridesSubject.asObservable();
        this.incomingVideoSettings$ = this.videoTrackSubscriptionOverrides$.pipe(rxjs.map((overrides) => {
            const { [globalOverrideKey]: globalSettings, ...participants } = overrides;
            return {
                enabled: globalSettings?.enabled !== false,
                preferredResolution: globalSettings?.enabled
                    ? globalSettings.dimension
                    : undefined,
                participants: Object.fromEntries(Object.entries(participants).map(([sessionId, participantOverride]) => [
                    sessionId,
                    {
                        enabled: participantOverride?.enabled !== false,
                        preferredResolution: participantOverride?.enabled
                            ? participantOverride.dimension
                            : undefined,
                    },
                ])),
                isParticipantVideoEnabled: (sessionId) => overrides[sessionId]?.enabled ??
                    overrides[globalOverrideKey]?.enabled ??
                    true,
            };
        }), rxjs.shareReplay(1));
        this.setVideoTrackSubscriptionOverrides = (override, sessionIds) => {
            if (!sessionIds) {
                return setCurrentValue(this.videoTrackSubscriptionOverridesSubject, override ? { [globalOverrideKey]: override } : {});
            }
            return setCurrentValue(this.videoTrackSubscriptionOverridesSubject, (overrides) => ({
                ...overrides,
                ...Object.fromEntries(sessionIds.map((id) => [id, override])),
            }));
        };
        this.applyTrackSubscriptions = (debounceType = exports.DebounceType.SLOW) => {
            if (this.pendingSubscriptionsUpdate) {
                clearTimeout(this.pendingSubscriptionsUpdate);
            }
            const updateSubscriptions = () => {
                this.pendingSubscriptionsUpdate = null;
                this.sfuClient
                    ?.updateSubscriptions(this.trackSubscriptions)
                    .catch((err) => {
                    this.logger('debug', `Failed to update track subscriptions`, err);
                });
            };
            if (debounceType) {
                this.pendingSubscriptionsUpdate = setTimeout(updateSubscriptions, debounceType);
            }
            else {
                updateSubscriptions();
            }
        };
        /**
         * Will begin tracking the given element for visibility changes within the
         * configured viewport element (`call.setViewport`).
         *
         * @param element the element to track.
         * @param sessionId the session id.
         * @param trackType the kind of video.
         * @returns Untrack.
         */
        this.trackElementVisibility = (element, sessionId, trackType) => {
            const cleanup = this.viewportTracker.observe(element, (entry) => {
                this.callState.updateParticipant(sessionId, (participant) => {
                    const previousVisibilityState = participant.viewportVisibilityState ??
                        DEFAULT_VIEWPORT_VISIBILITY_STATE;
                    // observer triggers when the element is "moved" to be a fullscreen element
                    // keep it VISIBLE if that happens to prevent fullscreen with placeholder
                    const isVisible = entry.isIntersecting || document.fullscreenElement === element
                        ? exports.VisibilityState.VISIBLE
                        : exports.VisibilityState.INVISIBLE;
                    return {
                        ...participant,
                        viewportVisibilityState: {
                            ...previousVisibilityState,
                            [trackType]: isVisible,
                        },
                    };
                });
            });
            return () => {
                cleanup();
                // reset visibility state to UNKNOWN upon cleanup
                // so that the layouts that are not actively observed
                // can still function normally (runtime layout switching)
                this.callState.updateParticipant(sessionId, (participant) => {
                    const previousVisibilityState = participant.viewportVisibilityState ??
                        DEFAULT_VIEWPORT_VISIBILITY_STATE;
                    return {
                        ...participant,
                        viewportVisibilityState: {
                            ...previousVisibilityState,
                            [trackType]: exports.VisibilityState.UNKNOWN,
                        },
                    };
                });
            };
        };
        /**
         * Sets the viewport element to track bound video elements for visibility.
         *
         * @param element the viewport element.
         */
        this.setViewport = (element) => {
            return this.viewportTracker.setViewport(element);
        };
        /**
         * Binds a DOM <video> element to the given session id.
         * This method will make sure that the video element will play
         * the correct video stream for the given session id.
         *
         * Under the hood, it would also keep track of the video element dimensions
         * and update the subscription accordingly in order to optimize the bandwidth.
         *
         * If a "viewport" is configured, the video element will be automatically
         * tracked for visibility and the subscription will be updated accordingly.
         *
         * @param videoElement the video element to bind to.
         * @param sessionId the session id.
         * @param trackType the kind of video.
         */
        this.bindVideoElement = (videoElement, sessionId, trackType) => {
            const boundParticipant = this.callState.findParticipantBySessionId(sessionId);
            if (!boundParticipant)
                return;
            const requestTrackWithDimensions = (debounceType, dimension) => {
                if (dimension && (dimension.width === 0 || dimension.height === 0)) {
                    // ignore 0x0 dimensions. this can happen when the video element
                    // is not visible (e.g., has display: none).
                    // we treat this as "unsubscription" as we don't want to keep
                    // consuming bandwidth for a video that is not visible on the screen.
                    this.logger('debug', `Ignoring 0x0 dimension`, boundParticipant);
                    dimension = undefined;
                }
                this.callState.updateParticipantTracks(trackType, {
                    [sessionId]: { dimension },
                });
                this.applyTrackSubscriptions(debounceType);
            };
            const participant$ = this.callState.participants$.pipe(rxjs.map((participants) => participants.find((participant) => participant.sessionId === sessionId)), rxjs.takeWhile((participant) => !!participant), rxjs.distinctUntilChanged(), rxjs.shareReplay({ bufferSize: 1, refCount: true }));
            /**
             * Since the video elements are now being removed from the DOM (React SDK) upon
             * visibility change, this subscription is not in use an stays here only for the
             * plain JS integrations where integrators might choose not to remove the video
             * elements from the DOM.
             */
            // keep copy for resize observer handler
            let viewportVisibilityState;
            const viewportVisibilityStateSubscription = boundParticipant.isLocalParticipant
                ? null
                : participant$
                    .pipe(rxjs.map((p) => p.viewportVisibilityState?.[trackType]), rxjs.distinctUntilChanged())
                    .subscribe((nextViewportVisibilityState) => {
                    // skip initial trigger
                    if (!viewportVisibilityState) {
                        viewportVisibilityState =
                            nextViewportVisibilityState ?? exports.VisibilityState.UNKNOWN;
                        return;
                    }
                    viewportVisibilityState =
                        nextViewportVisibilityState ?? exports.VisibilityState.UNKNOWN;
                    if (nextViewportVisibilityState === exports.VisibilityState.INVISIBLE) {
                        return requestTrackWithDimensions(exports.DebounceType.MEDIUM, undefined);
                    }
                    requestTrackWithDimensions(exports.DebounceType.MEDIUM, {
                        width: videoElement.clientWidth,
                        height: videoElement.clientHeight,
                    });
                });
            let lastDimensions;
            const resizeObserver = boundParticipant.isLocalParticipant
                ? null
                : new ResizeObserver(() => {
                    const currentDimensions = {
                        width: videoElement.clientWidth,
                        height: videoElement.clientHeight,
                    };
                    // skip initial trigger
                    if (!lastDimensions) {
                        lastDimensions = currentDimensions;
                        return;
                    }
                    if ((lastDimensions.width === currentDimensions.width &&
                        lastDimensions.height === currentDimensions.height) ||
                        viewportVisibilityState === exports.VisibilityState.INVISIBLE) {
                        return;
                    }
                    const relativeDelta = Math.max(currentDimensions.width / lastDimensions.width, currentDimensions.height / lastDimensions.height);
                    // Low quality video in an upscaled video element is very noticable.
                    // We try to upscale faster, and downscale slower. We also update debounce
                    // more if the size change is not significant, gurading against fast-firing
                    // resize events.
                    const debounceType = relativeDelta > 1.2 ? exports.DebounceType.IMMEDIATE : exports.DebounceType.MEDIUM;
                    requestTrackWithDimensions(debounceType, {
                        width: videoElement.clientWidth,
                        height: videoElement.clientHeight,
                    });
                    lastDimensions = currentDimensions;
                });
            resizeObserver?.observe(videoElement);
            // element renders and gets bound - track subscription gets
            // triggered first other ones get skipped on initial subscriptions
            const publishedTracksSubscription = boundParticipant.isLocalParticipant
                ? null
                : participant$
                    .pipe(rxjs.distinctUntilKeyChanged('publishedTracks'), rxjs.map((p) => trackType === 'videoTrack' ? hasVideo(p) : hasScreenShare(p)), rxjs.distinctUntilChanged())
                    .subscribe((isPublishing) => {
                    if (isPublishing) {
                        // the participant just started to publish a track
                        requestTrackWithDimensions(exports.DebounceType.IMMEDIATE, {
                            width: videoElement.clientWidth,
                            height: videoElement.clientHeight,
                        });
                    }
                    else {
                        // the participant just stopped publishing a track
                        requestTrackWithDimensions(exports.DebounceType.FAST, undefined);
                    }
                });
            videoElement.autoplay = true;
            videoElement.playsInline = true;
            // explicitly marking the element as muted will allow autoplay to work
            // without prior user interaction:
            // https://developer.mozilla.org/en-US/docs/Web/Media/Autoplay_guide
            videoElement.muted = true;
            const streamSubscription = participant$
                .pipe(rxjs.distinctUntilKeyChanged(trackType === 'videoTrack' ? 'videoStream' : 'screenShareStream'))
                .subscribe((p) => {
                const source = trackType === 'videoTrack' ? p.videoStream : p.screenShareStream;
                if (videoElement.srcObject === source)
                    return;
                videoElement.srcObject = source ?? null;
                if (isSafari() || isFirefox()) {
                    setTimeout(() => {
                        videoElement.srcObject = source ?? null;
                        videoElement.play().catch((e) => {
                            this.logger('warn', `Failed to play stream`, e);
                        });
                        // we add extra delay until we attempt to force-play
                        // the participant's media stream in Firefox and Safari,
                        // as they seem to have some timing issues
                    }, 25);
                }
            });
            return () => {
                requestTrackWithDimensions(exports.DebounceType.FAST, undefined);
                viewportVisibilityStateSubscription?.unsubscribe();
                publishedTracksSubscription?.unsubscribe();
                streamSubscription.unsubscribe();
                resizeObserver?.disconnect();
            };
        };
        /**
         * Binds a DOM <audio> element to the given session id.
         *
         * This method will make sure that the audio element will
         * play the correct audio stream for the given session id.
         *
         * @param audioElement the audio element to bind to.
         * @param sessionId the session id.
         * @param trackType the kind of audio.
         * @returns a cleanup function that will unbind the audio element.
         */
        this.bindAudioElement = (audioElement, sessionId, trackType) => {
            const participant = this.callState.findParticipantBySessionId(sessionId);
            if (!participant || participant.isLocalParticipant)
                return;
            const participant$ = this.callState.participants$.pipe(rxjs.map((participants) => participants.find((p) => p.sessionId === sessionId)), rxjs.takeWhile((p) => !!p), rxjs.distinctUntilChanged(), rxjs.shareReplay({ bufferSize: 1, refCount: true }));
            const updateMediaStreamSubscription = participant$
                .pipe(rxjs.distinctUntilKeyChanged(trackType === 'screenShareAudioTrack'
                ? 'screenShareAudioStream'
                : 'audioStream'))
                .subscribe((p) => {
                const source = trackType === 'screenShareAudioTrack'
                    ? p.screenShareAudioStream
                    : p.audioStream;
                if (audioElement.srcObject === source)
                    return;
                setTimeout(() => {
                    audioElement.srcObject = source ?? null;
                    if (audioElement.srcObject) {
                        audioElement.play().catch((e) => {
                            this.logger('warn', `Failed to play stream`, e);
                        });
                        // audio output device shall be set after the audio element is played
                        // otherwise, the browser will not pick it up, and will always
                        // play audio through the system's default device
                        const { selectedDevice } = this.speaker.state;
                        if (selectedDevice && 'setSinkId' in audioElement) {
                            audioElement.setSinkId(selectedDevice);
                            tracer.trace('navigator.mediaDevices.setSinkId', selectedDevice);
                        }
                    }
                });
            });
            const sinkIdSubscription = !('setSinkId' in audioElement)
                ? null
                : this.speaker.state.selectedDevice$.subscribe((deviceId) => {
                    if (deviceId) {
                        audioElement.setSinkId(deviceId);
                        tracer.trace('navigator.mediaDevices.setSinkId', deviceId);
                    }
                });
            const volumeSubscription = rxjs.combineLatest([
                this.speaker.state.volume$,
                participant$.pipe(rxjs.distinctUntilKeyChanged('audioVolume')),
            ]).subscribe(([volume, p]) => {
                audioElement.volume = p.audioVolume ?? volume;
            });
            audioElement.autoplay = true;
            return () => {
                sinkIdSubscription?.unsubscribe();
                volumeSubscription.unsubscribe();
                updateMediaStreamSubscription.unsubscribe();
            };
        };
        this.callState = callState;
        this.speaker = speaker;
    }
    setSfuClient(sfuClient) {
        this.sfuClient = sfuClient;
    }
    get trackSubscriptions() {
        const subscriptions = [];
        for (const p of this.callState.remoteParticipants) {
            // NOTE: audio tracks don't have to be requested explicitly
            // as the SFU will implicitly subscribe us to all of them,
            // once they become available.
            if (p.videoDimension && hasVideo(p)) {
                const override = this.videoTrackSubscriptionOverrides[p.sessionId] ??
                    this.videoTrackSubscriptionOverrides[globalOverrideKey];
                if (override?.enabled !== false) {
                    subscriptions.push({
                        userId: p.userId,
                        sessionId: p.sessionId,
                        trackType: TrackType.VIDEO,
                        dimension: override?.dimension ?? p.videoDimension,
                    });
                }
            }
            if (p.screenShareDimension && hasScreenShare(p)) {
                subscriptions.push({
                    userId: p.userId,
                    sessionId: p.sessionId,
                    trackType: TrackType.SCREEN_SHARE,
                    dimension: p.screenShareDimension,
                });
            }
            if (hasScreenShareAudio(p)) {
                subscriptions.push({
                    userId: p.userId,
                    sessionId: p.sessionId,
                    trackType: TrackType.SCREEN_SHARE_AUDIO,
                });
            }
        }
        return subscriptions;
    }
    get videoTrackSubscriptionOverrides() {
        return getCurrentValue(this.videoTrackSubscriptionOverrides$);
    }
}

/**
 * Stores the permissions for the current user and exposes
 * a few helper methods which make it easier to work with permissions.
 *
 * This is an internal class meant to be used in combination with
 * a {@link Call} instance.
 *
 * @internal
 */
class PermissionsContext {
    constructor() {
        this.permissions = [];
        /**
         * Sets the permissions for the current user.
         *
         * @param permissions the permissions to set.
         */
        this.setPermissions = (permissions) => {
            this.permissions = permissions || [];
        };
        /**
         * Sets the settings for the bound call.
         * @param settings
         */
        this.setCallSettings = (settings) => {
            this.settings = settings;
        };
        /**
         * Checks if the current user has a specific permission.
         *
         * @param permission the permission to check for.
         */
        this.hasPermission = (permission) => {
            return this.permissions.includes(permission);
        };
        /**
         * Helper method that checks whether the current user has the permission
         * to publish the given track type.
         */
        this.canPublish = (trackType) => {
            switch (trackType) {
                case TrackType.AUDIO:
                    return this.hasPermission(OwnCapability.SEND_AUDIO);
                case TrackType.VIDEO:
                    return this.hasPermission(OwnCapability.SEND_VIDEO);
                case TrackType.SCREEN_SHARE:
                case TrackType.SCREEN_SHARE_AUDIO:
                    return this.hasPermission(OwnCapability.SCREENSHARE);
                case TrackType.UNSPECIFIED:
                    return false;
                default:
                    ensureExhausted(trackType, 'Unknown track type');
            }
        };
        /**
         * Checks if the current user can request a specific permission
         * within the call.
         *
         * @param permission the permission to check for.
         * @param settings the call settings to check against (optional).
         */
        this.canRequest = (permission, settings = this.settings) => {
            if (!settings)
                return false;
            const { audio, video, screensharing } = settings;
            switch (permission) {
                case OwnCapability.SEND_AUDIO:
                    return audio.access_request_enabled;
                case OwnCapability.SEND_VIDEO:
                    return video.access_request_enabled;
                case OwnCapability.SCREENSHARE:
                    return screensharing.access_request_enabled;
                default:
                    return false;
            }
        };
    }
}

/**
 * Represents a call type.
 */
class CallType {
    /**
     * Constructs a new CallType.
     *
     * @param name the name of the call type.
     * @param options the options for the call type.
     */
    constructor(name, options = {
        sortParticipantsBy: defaultSortPreset,
    }) {
        this.name = name;
        this.options = options;
    }
}
/**
 * A registry of {@link CallType}s.
 * You can register and unregister call types.
 */
class CallTypesRegistry {
    /**
     * Constructs a new CallTypesRegistry.
     *
     * @param callTypes the initial call types to register.
     */
    constructor(callTypes) {
        /**
         * Registers a new call type.
         *
         * @param callType the call type to register.
         */
        this.register = (callType) => {
            this.callTypes[callType.name] = callType;
        };
        /**
         * Unregisters a call type.
         *
         * @param name the name of the call type to unregister.
         */
        this.unregister = (name) => {
            delete this.callTypes[name];
        };
        /**
         * Gets a call type by name.
         *
         * @param name the name of the call type to get.
         */
        this.get = (name) => {
            if (!this.callTypes[name]) {
                this.register(new CallType(name));
            }
            return this.callTypes[name];
        };
        this.callTypes = callTypes.reduce((acc, callType) => {
            acc[callType.name] = callType;
            return acc;
        }, {});
    }
}
/**
 * The default call types registry.
 * You can use this instance to dynamically register and unregister call types.
 */
const CallTypes = new CallTypesRegistry([
    new CallType('default', {
        sortParticipantsBy: defaultSortPreset,
    }),
    new CallType('development', {
        sortParticipantsBy: defaultSortPreset,
    }),
    new CallType('livestream', {
        sortParticipantsBy: livestreamOrAudioRoomSortPreset,
    }),
    new CallType('audio_room', {
        sortParticipantsBy: livestreamOrAudioRoomSortPreset,
    }),
]);

class BrowserPermission {
    constructor(permission) {
        this.permission = permission;
        this.disposeController = new AbortController();
        this.wasPrompted = false;
        this.listeners = new Set();
        this.logger = getLogger(['permissions']);
        const signal = this.disposeController.signal;
        this.ready = (async () => {
            const assumeGranted = () => {
                this.setState('prompt');
            };
            if (!canQueryPermissions()) {
                return assumeGranted();
            }
            try {
                const status = await navigator.permissions.query({
                    name: permission.queryName,
                });
                if (!signal.aborted) {
                    this.setState(status.state);
                    status.addEventListener('change', () => this.setState(status.state), {
                        signal,
                    });
                }
            }
            catch (err) {
                this.logger('debug', 'Failed to query permission status', err);
                assumeGranted();
            }
        })();
    }
    dispose() {
        this.state = undefined;
        this.disposeController.abort();
    }
    async getState() {
        await this.ready;
        if (!this.state) {
            throw new Error('BrowserPermission instance possibly disposed');
        }
        return this.state;
    }
    async prompt({ forcePrompt = false, throwOnNotAllowed = false, } = {}) {
        return await withoutConcurrency(`permission-prompt-${this.permission.queryName}`, async () => {
            if ((await this.getState()) !== 'prompt' ||
                (this.wasPrompted && !forcePrompt)) {
                const isGranted = this.state === 'granted';
                if (!isGranted && throwOnNotAllowed) {
                    throw new Error('Permission was not granted previously, and prompting again is not allowed');
                }
                return isGranted;
            }
            try {
                this.wasPrompted = true;
                this.setState('prompting');
                const stream = await navigator.mediaDevices.getUserMedia(this.permission.constraints);
                disposeOfMediaStream(stream);
                this.setState('granted');
                return true;
            }
            catch (e) {
                if (e &&
                    typeof e === 'object' &&
                    'name' in e &&
                    (e.name === 'NotAllowedError' || e.name === 'SecurityError')) {
                    this.logger('info', 'Browser permission was not granted', {
                        permission: this.permission,
                    });
                    this.setState('denied');
                    if (throwOnNotAllowed) {
                        throw e;
                    }
                    return false;
                }
                this.logger('error', `Failed to getUserMedia`, {
                    error: e,
                    permission: this.permission,
                });
                this.setState('prompt');
                throw e;
            }
        });
    }
    listen(cb) {
        this.listeners.add(cb);
        if (this.state)
            cb(this.state);
        return () => this.listeners.delete(cb);
    }
    asObservable() {
        return this.getStateObservable().pipe(
        // In some browsers, the 'change' event doesn't reliably emit and hence,
        // permissionState stays in 'prompt' state forever.
        // Typically, this happens when a user grants one-time permission.
        // Instead of checking if a permission is granted, we check if it isn't denied
        rxjs.map((state) => state !== 'denied'));
    }
    getIsPromptingObservable() {
        return this.getStateObservable().pipe(rxjs.map((state) => state === 'prompting'));
    }
    getStateObservable() {
        return rxjs.fromEventPattern((handler) => this.listen(handler), (handler, unlisten) => unlisten());
    }
    setState(state) {
        if (this.state !== state) {
            this.state = state;
            this.listeners.forEach((listener) => listener(state));
        }
    }
}
function canQueryPermissions() {
    return (!isReactNative() &&
        typeof navigator !== 'undefined' &&
        !!navigator.permissions?.query);
}

/**
 * Returns an Observable that emits the list of available devices
 * that meet the given constraints.
 *
 * @param permission a BrowserPermission instance.
 * @param kind the kind of devices to enumerate.
 */
const getDevices = (permission, kind) => {
    return rxjs.from((async () => {
        let devices = await navigator.mediaDevices.enumerateDevices();
        // for privacy reasons, most browsers don't give you device labels
        // unless you have a corresponding camera or microphone permission
        const shouldPromptForBrowserPermission = devices.some((device) => device.kind === kind && device.label === '');
        if (shouldPromptForBrowserPermission && (await permission.prompt())) {
            devices = await navigator.mediaDevices.enumerateDevices();
        }
        return devices.filter((device) => device.kind === kind &&
            device.label !== '' &&
            device.deviceId !== 'default');
    })());
};
/**
 * Tells if the browser supports audio output change on 'audio' elements,
 * see https://developer.mozilla.org/en-US/docs/Web/API/HTMLMediaElement/setSinkId.
 */
const checkIfAudioOutputChangeSupported = () => {
    if (typeof document === 'undefined')
        return false;
    const element = document.createElement('audio');
    return 'setSinkId' in element;
};
/**
 * The default constraints used to request audio devices.
 */
const audioDeviceConstraints = {
    audio: {
        autoGainControl: true,
        noiseSuppression: true,
        echoCancellation: true,
    },
};
/**
 * The default constraints used to request video devices.
 */
const videoDeviceConstraints = {
    video: {
        width: 1280,
        height: 720,
    },
};
/**
 * Keeps track of the browser permission to use microphone. This permission also
 * affects an ability to enumerate audio devices.
 */
const getAudioBrowserPermission = lazy(() => new BrowserPermission({
    constraints: audioDeviceConstraints,
    queryName: 'microphone',
}));
/**
 * Keeps track of the browser permission to use camera. This permission also
 * affects an ability to enumerate video devices.
 */
const getVideoBrowserPermission = lazy(() => new BrowserPermission({
    constraints: videoDeviceConstraints,
    queryName: 'camera',
}));
const getDeviceChangeObserver = lazy(() => {
    // 'addEventListener' is not available in React Native, returning
    // an observable that will never fire
    if (!navigator.mediaDevices.addEventListener)
        return rxjs.from([]);
    return rxjs.fromEvent(navigator.mediaDevices, 'devicechange').pipe(rxjs.map(() => undefined), rxjs.debounceTime(500));
});
/**
 * Prompts the user for a permission to use audio devices (if not already granted
 * and was not prompted before) and lists the available 'audioinput' devices,
 * if devices are added/removed the list is updated, and if the permission is revoked,
 * the observable errors.
 */
const getAudioDevices = lazy(() => {
    return rxjs.merge(getDeviceChangeObserver(), getAudioBrowserPermission().asObservable()).pipe(rxjs.startWith(undefined), rxjs.concatMap(() => getDevices(getAudioBrowserPermission(), 'audioinput')), rxjs.shareReplay(1));
});
/**
 * Prompts the user for a permission to use video devices (if not already granted
 * and was not prompted before) and lists the available 'videoinput' devices,
 * if devices are added/removed the list is updated, and if the permission is revoked,
 * the observable errors.
 */
const getVideoDevices = lazy(() => {
    return rxjs.merge(getDeviceChangeObserver(), getVideoBrowserPermission().asObservable()).pipe(rxjs.startWith(undefined), rxjs.concatMap(() => getDevices(getVideoBrowserPermission(), 'videoinput')), rxjs.shareReplay(1));
});
/**
 * Prompts the user for a permission to use video devices (if not already granted
 * and was not prompted before) and lists the available 'audiooutput' devices,
 * if devices are added/removed the list is updated, and if the permission is revoked,
 * the observable errors.
 */
const getAudioOutputDevices = lazy(() => {
    return rxjs.merge(getDeviceChangeObserver(), getAudioBrowserPermission().asObservable()).pipe(rxjs.startWith(undefined), rxjs.concatMap(() => getDevices(getAudioBrowserPermission(), 'audiooutput')), rxjs.shareReplay(1));
});
const getStream = async (constraints) => {
    const stream = await navigator.mediaDevices.getUserMedia(constraints);
    if (isFirefox()) {
        // When enumerating devices, Firefox will hide device labels unless there's been
        // an active user media stream on the page. So we force device list updates after
        // every successful getUserMedia call.
        navigator.mediaDevices.dispatchEvent(new Event('devicechange'));
    }
    return stream;
};
function isNotFoundOrOverconstrainedError(error) {
    if (!error || typeof error !== 'object') {
        return false;
    }
    if ('name' in error && typeof error.name === 'string') {
        const name = error.name;
        if (['OverconstrainedError', 'NotFoundError'].includes(name)) {
            return true;
        }
    }
    if ('message' in error && typeof error.message === 'string') {
        const message = error.message;
        if (message.startsWith('OverconstrainedError')) {
            return true;
        }
    }
    return false;
}
/**
 * Returns an audio media stream that fulfills the given constraints.
 * If no constraints are provided, it uses the browser's default ones.
 *
 * @angular It's recommended to use the [`DeviceManagerService`](./DeviceManagerService.md) for a higher level API, use this low-level method only if the `DeviceManagerService` doesn't suit your requirements.
 * @param trackConstraints the constraints to use when requesting the stream.
 * @returns the new `MediaStream` fulfilling the given constraints.
 */
const getAudioStream = async (trackConstraints) => {
    const constraints = {
        audio: {
            ...audioDeviceConstraints.audio,
            ...trackConstraints,
        },
    };
    try {
        await getAudioBrowserPermission().prompt({
            throwOnNotAllowed: true,
            forcePrompt: true,
        });
        return await getStream(constraints);
    }
    catch (error) {
        if (isNotFoundOrOverconstrainedError(error) && trackConstraints?.deviceId) {
            // eslint-disable-next-line @typescript-eslint/no-unused-vars
            const { deviceId, ...relaxedConstraints } = trackConstraints;
            getLogger(['devices'])('warn', 'Failed to get audio stream, will try again with relaxed constraints', { error, constraints, relaxedConstraints });
            return getAudioStream(relaxedConstraints);
        }
        getLogger(['devices'])('error', 'Failed to get audio stream', {
            error,
            constraints,
        });
        throw error;
    }
};
/**
 * Returns a video media stream that fulfills the given constraints.
 * If no constraints are provided, it uses the browser's default ones.
 *
 * @angular It's recommended to use the [`DeviceManagerService`](./DeviceManagerService.md) for a higher level API, use this low-level method only if the `DeviceManagerService` doesn't suit your requirements.
 * @param trackConstraints the constraints to use when requesting the stream.
 * @returns a new `MediaStream` fulfilling the given constraints.
 */
const getVideoStream = async (trackConstraints) => {
    const constraints = {
        video: {
            ...videoDeviceConstraints.video,
            ...trackConstraints,
        },
    };
    try {
        await getVideoBrowserPermission().prompt({
            throwOnNotAllowed: true,
            forcePrompt: true,
        });
        return await getStream(constraints);
    }
    catch (error) {
        if (isNotFoundOrOverconstrainedError(error) && trackConstraints?.deviceId) {
            // eslint-disable-next-line @typescript-eslint/no-unused-vars
            const { deviceId, ...relaxedConstraints } = trackConstraints;
            getLogger(['devices'])('warn', 'Failed to get video stream, will try again with relaxed constraints', { error, constraints, relaxedConstraints });
            return getVideoStream(relaxedConstraints);
        }
        getLogger(['devices'])('error', 'Failed to get video stream', {
            error,
            constraints,
        });
        throw error;
    }
};
/**
 * Prompts the user for a permission to share a screen.
 * If the user grants the permission, a screen sharing stream is returned. Throws otherwise.
 *
 * The callers of this API are responsible to handle the possible errors.
 *
 * @angular It's recommended to use the [`DeviceManagerService`](./DeviceManagerService.md) for a higher level API, use this low-level method only if the `DeviceManagerService` doesn't suit your requirements.
 *
 * @param options any additional options to pass to the [`getDisplayMedia`](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getDisplayMedia) API.
 */
const getScreenShareStream = async (options) => {
    try {
        return await navigator.mediaDevices.getDisplayMedia({
            video: true,
            audio: {
                channelCount: {
                    ideal: 2,
                },
                echoCancellation: false,
                autoGainControl: false,
                noiseSuppression: false,
            },
            // @ts-expect-error - not present in types yet
            systemAudio: 'include',
            ...options,
        });
    }
    catch (e) {
        getLogger(['devices'])('error', 'Failed to get screen share stream', e);
        throw e;
    }
};
const deviceIds$ = typeof navigator !== 'undefined' &&
    typeof navigator.mediaDevices !== 'undefined'
    ? getDeviceChangeObserver().pipe(rxjs.startWith(undefined), rxjs.concatMap(() => navigator.mediaDevices.enumerateDevices()), rxjs.shareReplay(1))
    : undefined;
/**
 * Deactivates MediaStream (stops and removes tracks) to be later garbage collected
 *
 * @param stream MediaStream
 * @returns void
 */
const disposeOfMediaStream = (stream) => {
    if (!stream.active)
        return;
    stream.getTracks().forEach((track) => {
        track.stop();
    });
    // @ts-expect-error release() is present in react-native-webrtc and must be called to dispose the stream
    if (typeof stream.release === 'function') {
        // @ts-expect-error - release() is present in react-native-webrtc
        stream.release();
    }
};

/**
 * Checks if the current platform is a mobile device.
 *
 * See:
 * https://developer.mozilla.org/en-US/docs/Web/HTTP/Browser_detection_using_the_user_agent
 */
const isMobile = () => /Mobi/i.test(navigator.userAgent);

class InputMediaDeviceManager {
    constructor(call, state, trackType) {
        this.call = call;
        this.state = state;
        this.trackType = trackType;
        /**
         * if true, stops the media stream when call is left
         */
        this.stopOnLeave = true;
        this.subscriptions = [];
        this.isTrackStoppedDueToTrackEnd = false;
        this.filters = [];
        this.statusChangeConcurrencyTag = Symbol('statusChangeConcurrencyTag');
        this.filterRegistrationConcurrencyTag = Symbol('filterRegistrationConcurrencyTag');
        /**
         * Disposes the manager.
         *
         * @internal
         */
        this.dispose = () => {
            this.subscriptions.forEach((s) => s());
        };
        this.logger = getLogger([`${TrackType[trackType].toLowerCase()} manager`]);
        if (deviceIds$ &&
            !isReactNative() &&
            (this.trackType === TrackType.AUDIO || this.trackType === TrackType.VIDEO)) {
            this.handleDisconnectedOrReplacedDevices();
        }
    }
    /**
     * Lists the available audio/video devices
     *
     * Note: It prompts the user for a permission to use devices (if not already granted)
     *
     * @returns an Observable that will be updated if a device is connected or disconnected
     */
    listDevices() {
        return this.getDevices();
    }
    /**
     * Returns `true` when this device is in enabled state.
     */
    get enabled() {
        return this.state.status === 'enabled';
    }
    /**
     * Starts stream.
     */
    async enable() {
        this.state.prevStatus = this.state.optimisticStatus;
        if (this.state.optimisticStatus === 'enabled') {
            return;
        }
        this.state.setPendingStatus('enabled');
        await withCancellation(this.statusChangeConcurrencyTag, async (signal) => {
            try {
                await this.unmuteStream();
                this.state.setStatus('enabled');
            }
            finally {
                if (!signal.aborted) {
                    this.state.setPendingStatus(this.state.status);
                }
            }
        });
    }
    /**
     * Stops or pauses the stream based on state.disableMode
     * @param {boolean} [forceStop=false] when true, stops the tracks regardless of the state.disableMode
     */
    async disable(forceStop = false) {
        this.state.prevStatus = this.state.optimisticStatus;
        if (!forceStop && this.state.optimisticStatus === 'disabled') {
            return;
        }
        this.state.setPendingStatus('disabled');
        await withCancellation(this.statusChangeConcurrencyTag, async (signal) => {
            try {
                const stopTracks = forceStop || this.state.disableMode === 'stop-tracks';
                await this.muteStream(stopTracks);
                this.state.setStatus('disabled');
            }
            finally {
                if (!signal.aborted) {
                    this.state.setPendingStatus(this.state.status);
                }
            }
        });
    }
    /**
     * Returns a promise that resolves when all pe
     */
    async statusChangeSettled() {
        await settled(this.statusChangeConcurrencyTag);
    }
    /**
     * If status was previously enabled, it will re-enable the device.
     */
    async resume() {
        if (this.state.prevStatus === 'enabled' &&
            this.state.status !== 'enabled') {
            await this.enable();
        }
    }
    /**
     * If the current device status is disabled, it will enable the device,
     * else it will disable it.
     */
    async toggle() {
        if (this.state.optimisticStatus === 'enabled') {
            return await this.disable();
        }
        else {
            return await this.enable();
        }
    }
    /**
     * Registers a filter that will be applied to the stream.
     *
     * The registered filter will get the existing stream, and it should return
     * a new stream with the applied filter.
     *
     * @param filter the filter to register.
     * @returns MediaStreamFilterRegistrationResult
     */
    registerFilter(filter) {
        const entry = {
            start: filter,
            stop: undefined,
        };
        const registered = withoutConcurrency(this.filterRegistrationConcurrencyTag, async () => {
            this.filters.push(entry);
            await this.applySettingsToStream();
        });
        return {
            registered,
            unregister: () => withoutConcurrency(this.filterRegistrationConcurrencyTag, async () => {
                entry.stop?.();
                this.filters = this.filters.filter((f) => f !== entry);
                await this.applySettingsToStream();
            }),
        };
    }
    /**
     * Will set the default constraints for the device.
     *
     * @param constraints the constraints to set.
     */
    setDefaultConstraints(constraints) {
        this.state.setDefaultConstraints(constraints);
    }
    /**
     * Selects a device.
     *
     * Note: This method is not supported in React Native
     * @param deviceId the device id to select.
     */
    async select(deviceId) {
        if (isReactNative()) {
            throw new Error('This method is not supported in React Native. Please visit https://getstream.io/video/docs/reactnative/core/camera-and-microphone/#speaker-management for reference.');
        }
        const prevDeviceId = this.state.selectedDevice;
        if (deviceId === prevDeviceId) {
            return;
        }
        try {
            this.state.setDevice(deviceId);
            await this.applySettingsToStream();
        }
        catch (error) {
            this.state.setDevice(prevDeviceId);
            throw error;
        }
    }
    async applySettingsToStream() {
        await withCancellation(this.statusChangeConcurrencyTag, async () => {
            if (this.enabled) {
                await this.muteStream();
                await this.unmuteStream();
            }
        });
    }
    publishStream(stream) {
        return this.call.publish(stream, this.trackType);
    }
    stopPublishStream() {
        return this.call.stopPublish(this.trackType);
    }
    getTracks() {
        return this.state.mediaStream?.getTracks() ?? [];
    }
    async muteStream(stopTracks = true) {
        const mediaStream = this.state.mediaStream;
        if (!mediaStream)
            return;
        this.logger('debug', `${stopTracks ? 'Stopping' : 'Disabling'} stream`);
        if (this.call.state.callingState === exports.CallingState.JOINED) {
            await this.stopPublishStream();
        }
        this.muteLocalStream(stopTracks);
        const allEnded = this.getTracks().every((t) => t.readyState === 'ended');
        if (allEnded) {
            // @ts-expect-error release() is present in react-native-webrtc
            if (typeof mediaStream.release === 'function') {
                // @ts-expect-error called to dispose the stream in RN
                mediaStream.release();
            }
            this.state.setMediaStream(undefined, undefined);
            this.filters.forEach((entry) => entry.stop?.());
        }
    }
    disableTracks() {
        this.getTracks().forEach((track) => {
            if (track.enabled)
                track.enabled = false;
        });
    }
    enableTracks() {
        this.getTracks().forEach((track) => {
            if (!track.enabled)
                track.enabled = true;
        });
    }
    stopTracks() {
        this.getTracks().forEach((track) => {
            if (track.readyState === 'live')
                track.stop();
        });
    }
    muteLocalStream(stopTracks) {
        if (!this.state.mediaStream) {
            return;
        }
        if (stopTracks) {
            this.stopTracks();
        }
        else {
            this.disableTracks();
        }
    }
    async unmuteStream() {
        this.logger('debug', 'Starting stream');
        let stream;
        let rootStream;
        if (this.state.mediaStream &&
            this.getTracks().every((t) => t.readyState === 'live')) {
            stream = this.state.mediaStream;
            this.enableTracks();
        }
        else {
            const defaultConstraints = this.state.defaultConstraints;
            const constraints = {
                ...defaultConstraints,
                deviceId: this.state.selectedDevice
                    ? { exact: this.state.selectedDevice }
                    : undefined,
            };
            /**
             * Chains two media streams together.
             *
             * In our case, filters MediaStreams are derived from their parent MediaStream.
             * However, once a child filter's track is stopped,
             * the tracks of the parent MediaStream aren't automatically stopped.
             * This leads to a situation where the camera indicator light is still on
             * even though the user stopped publishing video.
             *
             * This function works around this issue by stopping the parent MediaStream's tracks
             * as well once the child filter's tracks are stopped.
             *
             * It works by patching the stop() method of the child filter's tracks to also stop
             * the parent MediaStream's tracks of the same type. Here we assume that
             * the parent MediaStream has only one track of each type.
             *
             * @param parentStream the parent MediaStream. Omit for the root stream.
             */
            const chainWith = (parentStream) => async (filterStream) => {
                if (!parentStream)
                    return filterStream;
                // TODO OL: take care of track.enabled property as well
                const parent = await parentStream;
                filterStream.getTracks().forEach((track) => {
                    const originalStop = track.stop;
                    track.stop = function stop() {
                        originalStop.call(track);
                        parent.getTracks().forEach((parentTrack) => {
                            if (parentTrack.kind === track.kind) {
                                parentTrack.stop();
                            }
                        });
                    };
                });
                parent.getTracks().forEach((parentTrack) => {
                    // When the parent stream abruptly ends, we propagate the event
                    // to the filter stream.
                    // This usually happens when the camera/microphone permissions
                    // are revoked or when the device is disconnected.
                    const handleParentTrackEnded = () => {
                        filterStream.getTracks().forEach((track) => {
                            if (parentTrack.kind !== track.kind)
                                return;
                            track.stop();
                            track.dispatchEvent(new Event('ended')); // propagate the event
                        });
                    };
                    parentTrack.addEventListener('ended', handleParentTrackEnded);
                    this.subscriptions.push(() => {
                        parentTrack.removeEventListener('ended', handleParentTrackEnded);
                    });
                });
                return filterStream;
            };
            // the rootStream represents the stream coming from the actual device
            // e.g. camera or microphone stream
            rootStream = this.getStream(constraints);
            // we publish the last MediaStream of the chain
            stream = await this.filters.reduce((parent, entry) => parent
                .then((inputStream) => {
                const { stop, output } = entry.start(inputStream);
                entry.stop = stop;
                return output;
            })
                .then(chainWith(parent), (error) => {
                this.logger('warn', 'Filter failed to start and will be ignored', error);
                return parent;
            }), rootStream);
        }
        if (this.call.state.callingState === exports.CallingState.JOINED) {
            await this.publishStream(stream);
        }
        if (this.state.mediaStream !== stream) {
            this.state.setMediaStream(stream, await rootStream);
            const handleTrackEnded = async () => {
                await this.statusChangeSettled();
                if (this.enabled) {
                    this.isTrackStoppedDueToTrackEnd = true;
                    setTimeout(() => {
                        this.isTrackStoppedDueToTrackEnd = false;
                    }, 2000);
                    await this.disable();
                }
            };
            const createTrackMuteHandler = (muted) => () => {
                if (!isMobile() || this.trackType !== TrackType.VIDEO)
                    return;
                this.call.notifyTrackMuteState(muted, this.trackType).catch((err) => {
                    this.logger('warn', 'Error while notifying track mute state', err);
                });
            };
            stream.getTracks().forEach((track) => {
                const muteHandler = createTrackMuteHandler(true);
                const unmuteHandler = createTrackMuteHandler(false);
                track.addEventListener('mute', muteHandler);
                track.addEventListener('unmute', unmuteHandler);
                track.addEventListener('ended', handleTrackEnded);
                this.subscriptions.push(() => {
                    track.removeEventListener('mute', muteHandler);
                    track.removeEventListener('unmute', unmuteHandler);
                    track.removeEventListener('ended', handleTrackEnded);
                });
            });
        }
    }
    get mediaDeviceKind() {
        if (this.trackType === TrackType.AUDIO) {
            return 'audioinput';
        }
        if (this.trackType === TrackType.VIDEO) {
            return 'videoinput';
        }
        return '';
    }
    handleDisconnectedOrReplacedDevices() {
        this.subscriptions.push(createSubscription(rxjs.combineLatest([
            deviceIds$.pipe(rxjs.pairwise()),
            this.state.selectedDevice$,
        ]), async ([[prevDevices, currentDevices], deviceId]) => {
            try {
                if (!deviceId)
                    return;
                await this.statusChangeSettled();
                let isDeviceDisconnected = false;
                let isDeviceReplaced = false;
                const currentDevice = this.findDevice(currentDevices, deviceId);
                const prevDevice = this.findDevice(prevDevices, deviceId);
                if (!currentDevice && prevDevice) {
                    isDeviceDisconnected = true;
                }
                else if (currentDevice &&
                    prevDevice &&
                    currentDevice.deviceId === prevDevice.deviceId &&
                    currentDevice.groupId !== prevDevice.groupId) {
                    isDeviceReplaced = true;
                }
                if (isDeviceDisconnected) {
                    await this.disable();
                    await this.select(undefined);
                }
                if (isDeviceReplaced) {
                    if (this.isTrackStoppedDueToTrackEnd &&
                        this.state.status === 'disabled') {
                        await this.enable();
                        this.isTrackStoppedDueToTrackEnd = false;
                    }
                    else {
                        await this.applySettingsToStream();
                    }
                }
            }
            catch (err) {
                this.logger('warn', 'Unexpected error while handling disconnected or replaced device', err);
            }
        }));
    }
    findDevice(devices, deviceId) {
        const kind = this.mediaDeviceKind;
        return devices.find((d) => d.deviceId === deviceId && d.kind === kind);
    }
}

class InputMediaDeviceManagerState {
    /**
     * Constructs new InputMediaDeviceManagerState instance.
     *
     * @param disableMode the disable mode to use.
     * @param permission the BrowserPermission to use for querying.
     * `undefined` means no permission is required.
     */
    constructor(disableMode = 'stop-tracks', permission) {
        this.disableMode = disableMode;
        this.statusSubject = new rxjs.BehaviorSubject(undefined);
        this.optimisticStatusSubject = new rxjs.BehaviorSubject(undefined);
        this.mediaStreamSubject = new rxjs.BehaviorSubject(undefined);
        this.selectedDeviceSubject = new rxjs.BehaviorSubject(undefined);
        this.defaultConstraintsSubject = new rxjs.BehaviorSubject(undefined);
        /**
         * An Observable that emits the current media stream, or `undefined` if the device is currently disabled.
         *
         */
        this.mediaStream$ = this.mediaStreamSubject.asObservable();
        /**
         * An Observable that emits the currently selected device
         */
        this.selectedDevice$ = this.selectedDeviceSubject
            .asObservable()
            .pipe(rxjs.distinctUntilChanged());
        /**
         * An Observable that emits the device status
         */
        this.status$ = this.statusSubject.asObservable().pipe(rxjs.distinctUntilChanged());
        /**
         * An Observable the reflects the requested device status. Useful for optimistic UIs
         */
        this.optimisticStatus$ = this.optimisticStatusSubject
            .asObservable()
            .pipe(rxjs.distinctUntilChanged());
        /**
         * The default constraints for the device.
         */
        this.defaultConstraints$ = this.defaultConstraintsSubject.asObservable();
        /**
         * Gets the current value of an observable, or undefined if the observable has
         * not emitted a value yet.
         *
         * @param observable$ the observable to get the value from.
         */
        this.getCurrentValue = getCurrentValue;
        /**
         * Updates the value of the provided Subject.
         * An `update` can either be a new value or a function which takes
         * the current value and returns a new value.
         *
         * @internal
         *
         * @param subject the subject to update.
         * @param update the update to apply to the subject.
         * @return the updated value.
         */
        this.setCurrentValue = setCurrentValue;
        this.hasBrowserPermission$ = permission
            ? permission.asObservable().pipe(rxjs.shareReplay(1))
            : rxjs.of(true);
        this.isPromptingPermission$ = permission
            ? permission.getIsPromptingObservable().pipe(rxjs.shareReplay(1))
            : rxjs.of(false);
    }
    /**
     * The device status
     */
    get status() {
        return this.getCurrentValue(this.status$);
    }
    /**
     * The requested device status. Useful for optimistic UIs
     */
    get optimisticStatus() {
        return this.getCurrentValue(this.optimisticStatus$);
    }
    /**
     * The currently selected device
     */
    get selectedDevice() {
        return this.getCurrentValue(this.selectedDevice$);
    }
    /**
     * The current media stream, or `undefined` if the device is currently disabled.
     */
    get mediaStream() {
        return this.getCurrentValue(this.mediaStream$);
    }
    /**
     * @internal
     * @param status
     */
    setStatus(status) {
        this.setCurrentValue(this.statusSubject, status);
    }
    /**
     * @internal
     * @param pendingStatus
     */
    setPendingStatus(pendingStatus) {
        this.setCurrentValue(this.optimisticStatusSubject, pendingStatus);
    }
    /**
     * Updates the `mediaStream` state variable.
     *
     * @internal
     * @param stream the stream to set.
     * @param rootStream the root stream, applicable when filters are used
     * as this is the stream that holds the actual deviceId information.
     */
    setMediaStream(stream, rootStream) {
        this.setCurrentValue(this.mediaStreamSubject, stream);
        if (rootStream) {
            this.setDevice(this.getDeviceIdFromStream(rootStream));
        }
    }
    /**
     * @internal
     * @param deviceId the device id to set.
     */
    setDevice(deviceId) {
        this.setCurrentValue(this.selectedDeviceSubject, deviceId);
    }
    /**
     * Gets the default constraints for the device.
     */
    get defaultConstraints() {
        return this.getCurrentValue(this.defaultConstraints$);
    }
    /**
     * Sets the default constraints for the device.
     *
     * @internal
     * @param constraints the constraints to set.
     */
    setDefaultConstraints(constraints) {
        this.setCurrentValue(this.defaultConstraintsSubject, constraints);
    }
}

class CameraManagerState extends InputMediaDeviceManagerState {
    constructor() {
        super('stop-tracks', getVideoBrowserPermission());
        this.directionSubject = new rxjs.BehaviorSubject(undefined);
        this.direction$ = this.directionSubject
            .asObservable()
            .pipe(rxjs.distinctUntilChanged());
    }
    /**
     * The preferred camera direction
     * front - means the camera facing the user
     * back - means the camera facing the environment
     */
    get direction() {
        return this.getCurrentValue(this.direction$);
    }
    /**
     * @internal
     */
    setDirection(direction) {
        this.setCurrentValue(this.directionSubject, direction);
    }
    /**
     * @internal
     */
    setMediaStream(stream, rootStream) {
        super.setMediaStream(stream, rootStream);
        if (stream) {
            // RN getSettings() doesn't return facingMode, so we don't verify camera direction
            const direction = isReactNative()
                ? this.direction
                : stream.getVideoTracks()[0]?.getSettings().facingMode === 'environment'
                    ? 'back'
                    : 'front';
            this.setDirection(direction);
        }
    }
    getDeviceIdFromStream(stream) {
        const [track] = stream.getVideoTracks();
        return track?.getSettings().deviceId;
    }
}

class CameraManager extends InputMediaDeviceManager {
    /**
     * Constructs a new CameraManager.
     *
     * @param call the call instance.
     */
    constructor(call) {
        super(call, new CameraManagerState(), TrackType.VIDEO);
        this.targetResolution = {
            width: 1280,
            height: 720,
        };
    }
    isDirectionSupportedByDevice() {
        return isReactNative() || isMobile();
    }
    /**
     * Select the camera direction.
     *
     * @param direction the direction of the camera to select.
     */
    async selectDirection(direction) {
        if (this.isDirectionSupportedByDevice()) {
            if (isReactNative()) {
                const videoTrack = this.getTracks()[0];
                if (!videoTrack) {
                    this.logger('warn', 'No video track found to do direction selection');
                    return;
                }
                await videoTrack.applyConstraints({
                    facingMode: direction === 'front' ? 'user' : 'environment',
                });
                this.state.setDirection(direction);
                this.state.setDevice(undefined);
            }
            else {
                // web mobile
                this.state.setDirection(direction);
                // Providing both device id and direction doesn't work, so we deselect the device
                this.state.setDevice(undefined);
                this.getTracks().forEach((track) => {
                    track.stop();
                });
                await this.unmuteStream();
            }
        }
        else {
            this.logger('warn', 'Camera direction ignored for desktop devices');
        }
    }
    /**
     * Flips the camera direction: if it's front it will change to back, if it's back, it will change to front.
     *
     * Note: if there is no available camera with the desired direction, this method will do nothing.
     * @returns
     */
    async flip() {
        const newDirection = this.state.direction === 'front' ? 'back' : 'front';
        await this.selectDirection(newDirection);
    }
    /**
     * @internal
     */
    async selectTargetResolution(resolution) {
        this.targetResolution.height = resolution.height;
        this.targetResolution.width = resolution.width;
        if (this.state.optimisticStatus === 'enabled') {
            try {
                await this.statusChangeSettled();
            }
            catch (error) {
                // couldn't enable device, target resolution will be applied the next time user attempts to start the device
                this.logger('warn', 'could not apply target resolution', error);
            }
        }
        if (this.enabled && this.state.mediaStream) {
            const [videoTrack] = this.state.mediaStream.getVideoTracks();
            if (!videoTrack)
                return;
            const { width, height } = videoTrack.getSettings();
            if (width !== this.targetResolution.width ||
                height !== this.targetResolution.height) {
                await this.applySettingsToStream();
                this.logger('debug', `${width}x${height} target resolution applied to media stream`);
            }
        }
    }
    /**
     * Applies the video settings to the camera.
     *
     * @param settings the video settings to apply.
     * @param publish whether to publish the stream after applying the settings.
     */
    async apply(settings, publish) {
        const hasPublishedVideo = !!this.call.state.localParticipant?.videoStream;
        const hasPermission = this.call.permissionsContext.hasPermission(OwnCapability.SEND_AUDIO);
        if (hasPublishedVideo || !hasPermission)
            return;
        // Wait for any in progress camera operation
        await this.statusChangeSettled();
        const { target_resolution, camera_facing, camera_default_on } = settings;
        await this.selectTargetResolution(target_resolution);
        // Set camera direction if it's not yet set
        if (!this.state.direction && !this.state.selectedDevice) {
            this.state.setDirection(camera_facing === 'front' ? 'front' : 'back');
        }
        if (!publish)
            return;
        const { mediaStream } = this.state;
        if (this.enabled && mediaStream) {
            // The camera is already enabled (e.g. lobby screen). Publish the stream
            await this.publishStream(mediaStream);
        }
        else if (this.state.status === undefined && camera_default_on) {
            // Start camera if backend config specifies, and there is no local setting
            await this.enable();
        }
    }
    getDevices() {
        return getVideoDevices();
    }
    getStream(constraints) {
        constraints.width = this.targetResolution.width;
        constraints.height = this.targetResolution.height;
        // We can't set both device id and facing mode
        // Device id has higher priority
        if (!constraints.deviceId &&
            this.state.direction &&
            this.isDirectionSupportedByDevice()) {
            constraints.facingMode =
                this.state.direction === 'front' ? 'user' : 'environment';
        }
        return getVideoStream(constraints);
    }
}

class MicrophoneManagerState extends InputMediaDeviceManagerState {
    constructor(disableMode) {
        super(disableMode, getAudioBrowserPermission());
        this.speakingWhileMutedSubject = new rxjs.BehaviorSubject(false);
        this.speakingWhileMuted$ = this.speakingWhileMutedSubject
            .asObservable()
            .pipe(rxjs.distinctUntilChanged());
    }
    /**
     * `true` if the user's microphone is muted but they'are speaking.
     *
     * This feature is not available in the React Native SDK.
     */
    get speakingWhileMuted() {
        return this.getCurrentValue(this.speakingWhileMuted$);
    }
    /**
     * @internal
     */
    setSpeakingWhileMuted(isSpeaking) {
        this.setCurrentValue(this.speakingWhileMutedSubject, isSpeaking);
    }
    getDeviceIdFromStream(stream) {
        const [track] = stream.getAudioTracks();
        return track?.getSettings().deviceId;
    }
}

const DETECTION_FREQUENCY_IN_MS = 500;
const AUDIO_LEVEL_THRESHOLD = 150;
const FFT_SIZE = 128;
/**
 * Creates a new sound detector.
 *
 * @param audioStream the audio stream to observe. Depending on the provided configuration, this stream might be destroyed when the sound detector is stopped.
 * @param onSoundDetectedStateChanged a callback which is called when the sound state changes.
 * @param options custom options for the sound detector.
 * @returns a clean-up function which once invoked stops the sound detector.
 */
const createSoundDetector = (audioStream, onSoundDetectedStateChanged, options = {}) => {
    const { detectionFrequencyInMs = DETECTION_FREQUENCY_IN_MS, audioLevelThreshold = AUDIO_LEVEL_THRESHOLD, fftSize = FFT_SIZE, destroyStreamOnStop = true, } = options;
    const audioContext = new AudioContext();
    const analyser = audioContext.createAnalyser();
    analyser.fftSize = fftSize;
    const microphone = audioContext.createMediaStreamSource(audioStream);
    microphone.connect(analyser);
    const intervalId = setInterval(() => {
        const data = new Uint8Array(analyser.frequencyBinCount);
        analyser.getByteFrequencyData(data);
        const isSoundDetected = data.some((value) => value >= audioLevelThreshold);
        const averagedDataValue = data.reduce((pv, cv) => pv + cv, 0) / data.length;
        const percentage = averagedDataValue > audioLevelThreshold
            ? 100
            : Math.round((averagedDataValue / audioLevelThreshold) * 100);
        // When the track is disabled, it takes time for the buffer to empty
        // This check will ensure that we don't send anything if the track is disabled
        if (audioStream.getAudioTracks()[0]?.enabled) {
            onSoundDetectedStateChanged({ isSoundDetected, audioLevel: percentage });
        }
        else {
            onSoundDetectedStateChanged({ isSoundDetected: false, audioLevel: 0 });
        }
    }, detectionFrequencyInMs);
    return async function stop() {
        clearInterval(intervalId);
        // clean-up the AudioContext elements
        microphone.disconnect();
        analyser.disconnect();
        if (audioContext.state !== 'closed') {
            await audioContext.close();
        }
        // stop the stream
        if (destroyStreamOnStop) {
            audioStream.getTracks().forEach((track) => {
                track.stop();
                audioStream.removeTrack(track);
            });
        }
    };
};

class RNSpeechDetector {
    constructor() {
        this.pc1 = new RTCPeerConnection({});
        this.pc2 = new RTCPeerConnection({});
    }
    /**
     * Starts the speech detection.
     */
    async start(onSoundDetectedStateChanged) {
        try {
            this.cleanupAudioStream();
            const audioStream = await navigator.mediaDevices.getUserMedia({
                audio: true,
            });
            this.audioStream = audioStream;
            this.pc1.addEventListener('icecandidate', async (e) => {
                await this.pc2.addIceCandidate(e.candidate);
            });
            this.pc2.addEventListener('icecandidate', async (e) => {
                await this.pc1.addIceCandidate(e.candidate);
            });
            this.pc2.addEventListener('track', (e) => {
                e.streams[0].getTracks().forEach((track) => {
                    // In RN, the remote track is automatically added to the audio output device
                    // so we need to mute it to avoid hearing the audio back
                    // @ts-expect-error _setVolume is a private method in react-native-webrtc
                    track._setVolume(0);
                });
            });
            audioStream
                .getTracks()
                .forEach((track) => this.pc1.addTrack(track, audioStream));
            const offer = await this.pc1.createOffer({});
            await this.pc2.setRemoteDescription(offer);
            await this.pc1.setLocalDescription(offer);
            const answer = await this.pc2.createAnswer();
            await this.pc1.setRemoteDescription(answer);
            await this.pc2.setLocalDescription(answer);
            const unsub = this.onSpeakingDetectedStateChange(onSoundDetectedStateChanged);
            return () => {
                unsub();
                this.stop();
            };
        }
        catch (error) {
            const logger = getLogger(['RNSpeechDetector']);
            logger('error', 'error handling permissions: ', error);
            return () => { };
        }
    }
    /**
     * Stops the speech detection and releases all allocated resources.
     */
    stop() {
        this.pc1.close();
        this.pc2.close();
        this.cleanupAudioStream();
    }
    /**
     * Public method that detects the audio levels and returns the status.
     */
    onSpeakingDetectedStateChange(onSoundDetectedStateChanged) {
        const initialBaselineNoiseLevel = 0.13;
        let baselineNoiseLevel = initialBaselineNoiseLevel;
        let speechDetected = false;
        let speechTimer;
        let silenceTimer;
        const audioLevelHistory = []; // Store recent audio levels for smoother detection
        const historyLength = 10;
        const silenceThreshold = 1.1;
        const resetThreshold = 0.9;
        const speechTimeout = 500; // Speech is set to true after 500ms of audio detection
        const silenceTimeout = 5000; // Reset baseline after 5 seconds of silence
        const checkAudioLevel = async () => {
            try {
                const stats = (await this.pc1.getStats());
                const report = flatten(stats);
                // Audio levels are present inside stats of type `media-source` and of kind `audio`
                const audioMediaSourceStats = report.find((stat) => stat.type === 'media-source' &&
                    stat.kind === 'audio');
                if (audioMediaSourceStats) {
                    const { audioLevel } = audioMediaSourceStats;
                    if (audioLevel) {
                        // Update audio level history (with max historyLength sized array)
                        audioLevelHistory.push(audioLevel);
                        if (audioLevelHistory.length > historyLength) {
                            audioLevelHistory.shift();
                        }
                        // Calculate average audio level
                        const avgAudioLevel = audioLevelHistory.reduce((a, b) => a + b, 0) /
                            audioLevelHistory.length;
                        // Update baseline (if necessary) based on silence detection
                        if (avgAudioLevel < baselineNoiseLevel * silenceThreshold) {
                            if (!silenceTimer) {
                                silenceTimer = setTimeout(() => {
                                    baselineNoiseLevel = Math.min(avgAudioLevel * resetThreshold, initialBaselineNoiseLevel);
                                }, silenceTimeout);
                            }
                        }
                        else {
                            clearTimeout(silenceTimer);
                            silenceTimer = undefined;
                        }
                        // Speech detection with hysteresis
                        if (avgAudioLevel > baselineNoiseLevel * 1.5) {
                            if (!speechDetected) {
                                speechDetected = true;
                                onSoundDetectedStateChanged({
                                    isSoundDetected: true,
                                    audioLevel,
                                });
                            }
                            clearTimeout(speechTimer);
                            speechTimer = setTimeout(() => {
                                speechDetected = false;
                                onSoundDetectedStateChanged({
                                    isSoundDetected: false,
                                    audioLevel: 0,
                                });
                            }, speechTimeout);
                        }
                    }
                }
            }
            catch (error) {
                const logger = getLogger(['RNSpeechDetector']);
                logger('error', 'error checking audio level from stats', error);
            }
        };
        // Call checkAudioLevel periodically (every 100ms)
        const intervalId = setInterval(checkAudioLevel, 100);
        return () => {
            clearInterval(intervalId);
            clearTimeout(speechTimer);
            clearTimeout(silenceTimer);
        };
    }
    cleanupAudioStream() {
        if (!this.audioStream) {
            return;
        }
        this.audioStream.getTracks().forEach((track) => track.stop());
        if (
        // @ts-expect-error release() is present in react-native-webrtc
        typeof this.audioStream.release === 'function') {
            // @ts-expect-error called to dispose the stream in RN
            this.audioStream.release();
        }
    }
}

class MicrophoneManager extends InputMediaDeviceManager {
    constructor(call, disableMode = 'stop-tracks') {
        super(call, new MicrophoneManagerState(disableMode), TrackType.AUDIO);
        this.speakingWhileMutedNotificationEnabled = true;
        this.soundDetectorConcurrencyTag = Symbol('soundDetectorConcurrencyTag');
        this.subscriptions.push(createSafeAsyncSubscription(rxjs.combineLatest([
            this.call.state.callingState$,
            this.call.state.ownCapabilities$,
            this.state.selectedDevice$,
            this.state.status$,
        ]), async ([callingState, ownCapabilities, deviceId, status]) => {
            try {
                if (callingState === exports.CallingState.LEFT) {
                    await this.stopSpeakingWhileMutedDetection();
                }
                if (callingState !== exports.CallingState.JOINED)
                    return;
                if (!this.speakingWhileMutedNotificationEnabled)
                    return;
                if (ownCapabilities.includes(OwnCapability.SEND_AUDIO)) {
                    if (status === 'disabled') {
                        await this.startSpeakingWhileMutedDetection(deviceId);
                    }
                    else {
                        await this.stopSpeakingWhileMutedDetection();
                    }
                }
                else {
                    await this.stopSpeakingWhileMutedDetection();
                }
            }
            catch (err) {
                this.logger('warn', 'Could not enable speaking while muted', err);
            }
        }));
        this.subscriptions.push(createSubscription(this.call.state.callingState$, (callingState) => {
            // do nothing when noise filtering isn't turned on
            if (!this.noiseCancellationRegistration || !this.noiseCancellation)
                return;
            const autoOn = this.call.state.settings?.audio.noise_cancellation?.mode ===
                NoiseCancellationSettingsModeEnum.AUTO_ON;
            if (autoOn && callingState === exports.CallingState.JOINED) {
                this.noiseCancellationRegistration
                    .then(() => this.noiseCancellation?.enable())
                    .catch((err) => {
                    this.logger('warn', `Failed to enable noise cancellation`, err);
                    return this.call.notifyNoiseCancellationStopped();
                });
            }
            else if (callingState === exports.CallingState.LEFT) {
                this.noiseCancellationRegistration
                    .then(() => this.noiseCancellation?.disable())
                    .catch((err) => {
                    this.logger('warn', `Failed to disable noise cancellation`, err);
                });
            }
        }));
    }
    /**
     * Enables noise cancellation for the microphone.
     *
     * Note: not supported in React Native.
     * @param noiseCancellation - a noise cancellation instance to use.
     */
    async enableNoiseCancellation(noiseCancellation) {
        if (isReactNative()) {
            throw new Error('Noise cancellation is not supported in React Native');
        }
        const { ownCapabilities, settings } = this.call.state;
        const hasNoiseCancellationCapability = ownCapabilities.includes(OwnCapability.ENABLE_NOISE_CANCELLATION);
        if (!hasNoiseCancellationCapability) {
            throw new Error('Noise cancellation is not available.');
        }
        const noiseCancellationSettings = settings?.audio.noise_cancellation;
        if (!noiseCancellationSettings ||
            noiseCancellationSettings.mode ===
                NoiseCancellationSettingsModeEnum.DISABLED) {
            throw new Error('Noise cancellation is disabled for this call type.');
        }
        try {
            this.noiseCancellation = noiseCancellation;
            // listen for change events and notify the SFU
            this.noiseCancellationChangeUnsubscribe = this.noiseCancellation.on('change', (enabled) => {
                if (enabled) {
                    this.call.notifyNoiseCancellationStarting().catch((err) => {
                        this.logger('warn', `notifyNoiseCancellationStart failed`, err);
                    });
                }
                else {
                    this.call.notifyNoiseCancellationStopped().catch((err) => {
                        this.logger('warn', `notifyNoiseCancellationStop failed`, err);
                    });
                }
            });
            const registrationResult = this.registerFilter(noiseCancellation.toFilter());
            this.noiseCancellationRegistration = registrationResult.registered;
            this.unregisterNoiseCancellation = registrationResult.unregister;
            await this.noiseCancellationRegistration;
            // handles an edge case where a noise cancellation is enabled after
            // the participant as joined the call -> we immediately enable NC
            if (noiseCancellationSettings.mode ===
                NoiseCancellationSettingsModeEnum.AUTO_ON &&
                this.call.state.callingState === exports.CallingState.JOINED) {
                noiseCancellation.enable();
            }
        }
        catch (e) {
            this.logger('warn', 'Failed to enable noise cancellation', e);
            await this.disableNoiseCancellation().catch((err) => {
                this.logger('warn', 'Failed to disable noise cancellation', err);
            });
        }
    }
    /**
     * Disables noise cancellation for the microphone.
     *
     * Note: not supported in React Native.
     */
    async disableNoiseCancellation() {
        if (isReactNative()) {
            throw new Error('Noise cancellation is not supported in React Native');
        }
        await (this.unregisterNoiseCancellation?.() ?? Promise.resolve())
            .then(() => this.noiseCancellation?.disable())
            .then(() => this.noiseCancellationChangeUnsubscribe?.())
            .catch((err) => {
            this.logger('warn', 'Failed to unregister noise cancellation', err);
        });
        await this.call.notifyNoiseCancellationStopped();
    }
    /**
     * Enables speaking while muted notification.
     */
    async enableSpeakingWhileMutedNotification() {
        this.speakingWhileMutedNotificationEnabled = true;
        if (this.state.status === 'disabled') {
            await this.startSpeakingWhileMutedDetection(this.state.selectedDevice);
        }
    }
    /**
     * Disables speaking while muted notification.
     */
    async disableSpeakingWhileMutedNotification() {
        this.speakingWhileMutedNotificationEnabled = false;
        await this.stopSpeakingWhileMutedDetection();
    }
    /**
     * Applies the audio settings to the microphone.
     * @param settings the audio settings to apply.
     * @param publish whether to publish the stream after applying the settings.
     */
    async apply(settings, publish) {
        if (!publish)
            return;
        const hasPublishedAudio = !!this.call.state.localParticipant?.audioStream;
        const hasPermission = this.call.permissionsContext.hasPermission(OwnCapability.SEND_AUDIO);
        if (hasPublishedAudio || !hasPermission)
            return;
        // Wait for any in progress mic operation
        await this.statusChangeSettled();
        // Publish media stream that was set before we joined
        const { mediaStream } = this.state;
        if (this.enabled && mediaStream) {
            // The mic is already enabled (e.g. lobby screen). Publish the stream
            await this.publishStream(mediaStream);
        }
        else if (this.state.status === undefined && settings.mic_default_on) {
            // Start mic if backend config specifies, and there is no local setting
            await this.enable();
        }
    }
    getDevices() {
        return getAudioDevices();
    }
    getStream(constraints) {
        return getAudioStream(constraints);
    }
    async startSpeakingWhileMutedDetection(deviceId) {
        await withoutConcurrency(this.soundDetectorConcurrencyTag, async () => {
            await this.stopSpeakingWhileMutedDetection();
            if (isReactNative()) {
                this.rnSpeechDetector = new RNSpeechDetector();
                const unsubscribe = await this.rnSpeechDetector.start((event) => {
                    this.state.setSpeakingWhileMuted(event.isSoundDetected);
                });
                this.soundDetectorCleanup = () => {
                    unsubscribe();
                    this.rnSpeechDetector = undefined;
                };
            }
            else {
                // Need to start a new stream that's not connected to publisher
                const stream = await this.getStream({
                    deviceId: { exact: deviceId },
                });
                this.soundDetectorCleanup = createSoundDetector(stream, (event) => {
                    this.state.setSpeakingWhileMuted(event.isSoundDetected);
                });
            }
        });
    }
    async stopSpeakingWhileMutedDetection() {
        await withoutConcurrency(this.soundDetectorConcurrencyTag, async () => {
            if (!this.soundDetectorCleanup)
                return;
            const soundDetectorCleanup = this.soundDetectorCleanup;
            this.soundDetectorCleanup = undefined;
            this.state.setSpeakingWhileMuted(false);
            await soundDetectorCleanup();
        });
    }
}

class ScreenShareState extends InputMediaDeviceManagerState {
    constructor() {
        super(...arguments);
        this.audioEnabledSubject = new rxjs.BehaviorSubject(true);
        this.settingsSubject = new rxjs.BehaviorSubject(undefined);
        /**
         * An Observable that emits the current screen share audio status.
         */
        this.audioEnabled$ = this.audioEnabledSubject
            .asObservable()
            .pipe(rxjs.distinctUntilChanged());
        /**
         * An Observable that emits the current screen share settings.
         */
        this.settings$ = this.settingsSubject.asObservable();
        /**
         * @internal
         */
        this.getDeviceIdFromStream = (stream) => {
            const [track] = stream.getTracks();
            return track?.getSettings().deviceId;
        };
    }
    /**
     * The current screen share audio status.
     */
    get audioEnabled() {
        return this.getCurrentValue(this.audioEnabled$);
    }
    /**
     * Set the current screen share audio status.
     */
    setAudioEnabled(isEnabled) {
        this.setCurrentValue(this.audioEnabledSubject, isEnabled);
    }
    /**
     * The current screen share settings.
     */
    get settings() {
        return this.getCurrentValue(this.settings$);
    }
    /**
     * Set the current screen share settings.
     *
     * @param settings the screen share settings to set.
     */
    setSettings(settings) {
        this.setCurrentValue(this.settingsSubject, settings);
    }
}

class ScreenShareManager extends InputMediaDeviceManager {
    constructor(call) {
        super(call, new ScreenShareState(), TrackType.SCREEN_SHARE);
        this.subscriptions.push(createSubscription(call.state.settings$, (settings) => {
            const maybeTargetResolution = settings?.screensharing.target_resolution;
            if (maybeTargetResolution) {
                this.setDefaultConstraints({
                    video: {
                        width: maybeTargetResolution.width,
                        height: maybeTargetResolution.height,
                    },
                });
            }
        }));
    }
    /**
     * Will enable screen share audio options on supported platforms.
     *
     * Note: for ongoing screen share, audio won't be enabled until you
     * re-publish the screen share stream.
     */
    enableScreenShareAudio() {
        this.state.setAudioEnabled(true);
    }
    /**
     * Will disable screen share audio options on supported platforms.
     */
    async disableScreenShareAudio() {
        this.state.setAudioEnabled(false);
        if (this.call.publisher?.isPublishing(TrackType.SCREEN_SHARE_AUDIO)) {
            await this.call.stopPublish(TrackType.SCREEN_SHARE_AUDIO);
        }
    }
    /**
     * Returns the current screen share settings.
     */
    getSettings() {
        return this.state.settings;
    }
    /**
     * Sets the current screen share settings.
     *
     * @param settings the settings to set.
     */
    setSettings(settings) {
        this.state.setSettings(settings);
    }
    getDevices() {
        return rxjs.of([]); // there are no devices to be listed for Screen Share
    }
    getStream(constraints) {
        if (!this.state.audioEnabled) {
            constraints.audio = false;
        }
        return getScreenShareStream(constraints);
    }
    async stopPublishStream() {
        return this.call.stopPublish(TrackType.SCREEN_SHARE, TrackType.SCREEN_SHARE_AUDIO);
    }
    /**
     * Overrides the default `select` method to throw an error.
     */
    async select() {
        throw new Error('This method is not supported in for Screen Share');
    }
}

class SpeakerState {
    constructor() {
        this.selectedDeviceSubject = new rxjs.BehaviorSubject('');
        this.volumeSubject = new rxjs.BehaviorSubject(1);
        /**
         * [Tells if the browser supports audio output change on 'audio' elements](https://developer.mozilla.org/en-US/docs/Web/API/HTMLMediaElement/setSinkId).
         */
        this.isDeviceSelectionSupported = checkIfAudioOutputChangeSupported();
        /**
         * Gets the current value of an observable, or undefined if the observable has
         * not emitted a value yet.
         *
         * @param observable$ the observable to get the value from.
         */
        this.getCurrentValue = getCurrentValue;
        /**
         * Updates the value of the provided Subject.
         * An `update` can either be a new value or a function which takes
         * the current value and returns a new value.
         *
         * @internal
         *
         * @param subject the subject to update.
         * @param update the update to apply to the subject.
         * @return the updated value.
         */
        this.setCurrentValue = setCurrentValue;
        this.selectedDevice$ = this.selectedDeviceSubject
            .asObservable()
            .pipe(rxjs.distinctUntilChanged());
        this.volume$ = this.volumeSubject
            .asObservable()
            .pipe(rxjs.distinctUntilChanged());
    }
    /**
     * The currently selected device
     *
     * Note: this feature is not supported in React Native
     */
    get selectedDevice() {
        return this.getCurrentValue(this.selectedDevice$);
    }
    /**
     * The currently selected volume
     *
     * Note: this feature is not supported in React Native
     */
    get volume() {
        return this.getCurrentValue(this.volume$);
    }
    /**
     * @internal
     * @param deviceId
     */
    setDevice(deviceId) {
        this.setCurrentValue(this.selectedDeviceSubject, deviceId);
    }
    /**
     * @internal
     * @param volume
     */
    setVolume(volume) {
        this.setCurrentValue(this.volumeSubject, volume);
    }
}

class SpeakerManager {
    constructor(call) {
        this.state = new SpeakerState();
        this.subscriptions = [];
        /**
         * Disposes the manager.
         *
         * @internal
         */
        this.dispose = () => {
            this.subscriptions.forEach((s) => s.unsubscribe());
        };
        this.call = call;
        if (deviceIds$ && !isReactNative()) {
            this.subscriptions.push(rxjs.combineLatest([deviceIds$, this.state.selectedDevice$]).subscribe(([devices, deviceId]) => {
                if (!deviceId) {
                    return;
                }
                const device = devices.find((d) => d.deviceId === deviceId && d.kind === 'audiooutput');
                if (!device) {
                    this.select('');
                }
            }));
        }
    }
    /**
     * Lists the available audio output devices
     *
     * Note: It prompts the user for a permission to use devices (if not already granted)
     * Note: This method is not supported in React Native
     *
     * @returns an Observable that will be updated if a device is connected or disconnected
     */
    listDevices() {
        if (isReactNative()) {
            throw new Error('This feature is not supported in React Native. Please visit https://getstream.io/video/docs/reactnative/core/camera-and-microphone/#speaker-management for more details');
        }
        return getAudioOutputDevices();
    }
    /**
     * Select a device.
     *
     * Note: This method is not supported in React Native
     *
     * @param deviceId empty string means the system default
     */
    select(deviceId) {
        if (isReactNative()) {
            throw new Error('This feature is not supported in React Native. Please visit https://getstream.io/video/docs/reactnative/core/camera-and-microphone/#speaker-management for more details');
        }
        this.state.setDevice(deviceId);
    }
    /**
     * Set the volume of the audio elements
     * @param volume a number between 0 and 1.
     *
     * Note: This method is not supported in React Native
     */
    setVolume(volume) {
        if (isReactNative()) {
            throw new Error('This feature is not supported in React Native. Please visit https://getstream.io/video/docs/reactnative/core/camera-and-microphone/#speaker-management for more details');
        }
        if (volume && (volume < 0 || volume > 1)) {
            throw new Error('Volume must be between 0 and 1');
        }
        this.state.setVolume(volume);
    }
    /**
     * Set the volume of a participant.
     *
     * Note: This method is not supported in React Native.
     *
     * @param sessionId the participant's session id.
     * @param volume a number between 0 and 1. Set it to `undefined` to use the default volume.
     */
    setParticipantVolume(sessionId, volume) {
        if (isReactNative()) {
            throw new Error('This feature is not supported in React Native. Please visit https://getstream.io/video/docs/reactnative/core/camera-and-microphone/#speaker-management for more details');
        }
        if (volume && (volume < 0 || volume > 1)) {
            throw new Error('Volume must be between 0 and 1, or undefined');
        }
        this.call.state.updateParticipant(sessionId, { audioVolume: volume });
    }
}

/**
 * An object representation of a `Call`.
 */
class Call {
    /**
     * Constructs a new `Call` instance.
     *
     * NOTE: Don't call the constructor directly, instead
     * Use the [`StreamVideoClient.call`](./StreamVideoClient.md/#call)
     * method to construct a `Call` instance.
     */
    constructor({ type, id, streamClient, members, ownCapabilities, sortParticipantsBy, clientStore, ringing = false, watching = false, }) {
        /**
         * The state of this call.
         */
        this.state = new CallState();
        /**
         * The permissions context of this call.
         */
        this.permissionsContext = new PermissionsContext();
        /**
         * The event dispatcher instance dedicated to this Call instance.
         * @private
         */
        this.dispatcher = new Dispatcher();
        this.sfuClientTag = 0;
        this.reconnectConcurrencyTag = Symbol('reconnectConcurrencyTag');
        this.reconnectAttempts = 0;
        this.reconnectStrategy = WebsocketReconnectStrategy.UNSPECIFIED;
        this.reconnectReason = '';
        this.fastReconnectDeadlineSeconds = 0;
        this.disconnectionTimeoutSeconds = 0;
        this.lastOfflineTimestamp = 0;
        // maintain the order of publishing tracks to restore them after a reconnection
        // it shouldn't contain duplicates
        this.trackPublishOrder = [];
        this.hasJoinedOnce = false;
        this.deviceSettingsAppliedOnce = false;
        this.initialized = false;
        this.joinLeaveConcurrencyTag = Symbol('joinLeaveConcurrencyTag');
        /**
         * A list hooks/functions to invoke when the call is left.
         * A typical use case is to clean up some global event handlers.
         * @private
         */
        this.leaveCallHooks = new Set();
        this.streamClientEventHandlers = new Map();
        /**
         * Sets up the call instance.
         *
         * @internal an internal method and should not be used outside the SDK.
         */
        this.setup = async () => {
            await withoutConcurrency(this.joinLeaveConcurrencyTag, async () => {
                if (this.initialized)
                    return;
                this.leaveCallHooks.add(this.on('all', (event) => {
                    // update state with the latest event data
                    this.state.updateFromEvent(event);
                }));
                this.leaveCallHooks.add(this.on('changePublishOptions', (event) => {
                    this.currentPublishOptions = event.publishOptions;
                }));
                this.leaveCallHooks.add(registerEventHandlers(this, this.dispatcher));
                this.registerEffects();
                this.registerReconnectHandlers();
                if (this.state.callingState === exports.CallingState.LEFT) {
                    this.state.setCallingState(exports.CallingState.IDLE);
                }
                this.initialized = true;
            });
        };
        this.registerEffects = () => {
            this.leaveCallHooks.add(
            // handles updating the permissions context when the settings change.
            createSubscription(this.state.settings$, (settings) => {
                if (!settings)
                    return;
                this.permissionsContext.setCallSettings(settings);
            }));
            this.leaveCallHooks.add(
            // handle the case when the user permissions are modified.
            createSafeAsyncSubscription(this.state.ownCapabilities$, this.handleOwnCapabilitiesUpdated));
            this.leaveCallHooks.add(
            // handles the case when the user is blocked by the call owner.
            createSubscription(this.state.blockedUserIds$, async (blockedUserIds) => {
                if (!blockedUserIds || blockedUserIds.length === 0)
                    return;
                const currentUserId = this.currentUserId;
                if (currentUserId && blockedUserIds.includes(currentUserId)) {
                    this.logger('info', 'Leaving call because of being blocked');
                    await this.leave({ reason: 'user blocked' }).catch((err) => {
                        this.logger('error', 'Error leaving call after being blocked', err);
                    });
                }
            }));
            this.leaveCallHooks.add(
            // cancel auto-drop when call is accepted or rejected
            createSubscription(this.state.session$, (session) => {
                if (!this.ringing)
                    return;
                const receiverId = this.clientStore.connectedUser?.id;
                if (!receiverId)
                    return;
                const isAcceptedByMe = Boolean(session?.accepted_by[receiverId]);
                const isRejectedByMe = Boolean(session?.rejected_by[receiverId]);
                if (isAcceptedByMe || isRejectedByMe) {
                    this.cancelAutoDrop();
                }
                const isAcceptedElsewhere = isAcceptedByMe && this.state.callingState === exports.CallingState.RINGING;
                if ((isAcceptedElsewhere || isRejectedByMe) &&
                    !hasPending(this.joinLeaveConcurrencyTag)) {
                    this.leave().catch(() => {
                        this.logger('error', 'Could not leave a call that was accepted or rejected elsewhere');
                    });
                }
            }));
            this.leaveCallHooks.add(
            // "ringing" mode effects and event handlers
            createSubscription(this.ringingSubject, (isRinging) => {
                if (!isRinging)
                    return;
                const callSession = this.state.session;
                const receiver_id = this.clientStore.connectedUser?.id;
                const ended_at = callSession?.ended_at;
                const created_by_id = this.state.createdBy?.id;
                const rejected_by = callSession?.rejected_by;
                const accepted_by = callSession?.accepted_by;
                let leaveCallIdle = false;
                if (ended_at) {
                    // call was ended before it was accepted or rejected so we should leave it to idle
                    leaveCallIdle = true;
                }
                else if (created_by_id && rejected_by) {
                    if (rejected_by[created_by_id]) {
                        // call was cancelled by the caller
                        leaveCallIdle = true;
                    }
                }
                else if (receiver_id && rejected_by) {
                    if (rejected_by[receiver_id]) {
                        // call was rejected by the receiver in some other device
                        leaveCallIdle = true;
                    }
                }
                else if (receiver_id && accepted_by) {
                    if (accepted_by[receiver_id]) {
                        // call was accepted by the receiver in some other device
                        leaveCallIdle = true;
                    }
                }
                if (leaveCallIdle) {
                    if (this.state.callingState !== exports.CallingState.IDLE) {
                        this.state.setCallingState(exports.CallingState.IDLE);
                    }
                }
                else {
                    if (this.state.callingState === exports.CallingState.IDLE) {
                        this.state.setCallingState(exports.CallingState.RINGING);
                    }
                    this.scheduleAutoDrop();
                    this.leaveCallHooks.add(registerRingingCallEventHandlers(this));
                }
            }));
        };
        this.handleOwnCapabilitiesUpdated = async (ownCapabilities) => {
            // update the permission context.
            this.permissionsContext.setPermissions(ownCapabilities);
            if (!this.publisher)
                return;
            // check if the user still has publishing permissions and stop publishing if not.
            const permissionToTrackType = {
                [OwnCapability.SEND_AUDIO]: TrackType.AUDIO,
                [OwnCapability.SEND_VIDEO]: TrackType.VIDEO,
                [OwnCapability.SCREENSHARE]: TrackType.SCREEN_SHARE,
            };
            for (const [permission, trackType] of Object.entries(permissionToTrackType)) {
                const hasPermission = this.permissionsContext.hasPermission(permission);
                if (hasPermission)
                    continue;
                try {
                    switch (trackType) {
                        case TrackType.AUDIO:
                            if (this.microphone.enabled)
                                await this.microphone.disable();
                            break;
                        case TrackType.VIDEO:
                            if (this.camera.enabled)
                                await this.camera.disable();
                            break;
                        case TrackType.SCREEN_SHARE:
                            if (this.screenShare.enabled)
                                await this.screenShare.disable();
                            break;
                    }
                }
                catch (err) {
                    this.logger('error', `Can't disable mic/camera/screenshare after revoked permissions`, err);
                }
            }
        };
        /**
         * You can subscribe to WebSocket events provided by the API. To remove a subscription, call the `off` method.
         * Please note that subscribing to WebSocket events is an advanced use-case.
         * For most use-cases, it should be enough to watch for state changes.
         *
         * @param eventName the event name.
         * @param fn the event handler.
         */
        this.on = (eventName, fn) => {
            if (isSfuEvent(eventName)) {
                return this.dispatcher.on(eventName, fn);
            }
            const offHandler = this.streamClient.on(eventName, (e) => {
                const event = e;
                if (event.call_cid && event.call_cid === this.cid) {
                    fn(event);
                }
            });
            // keep the 'off' reference returned by the stream client
            this.streamClientEventHandlers.set(fn, offHandler);
            return () => {
                this.off(eventName, fn);
            };
        };
        /**
         * Remove subscription for WebSocket events that were created by the `on` method.
         *
         * @param eventName the event name.
         * @param fn the event handler.
         */
        this.off = (eventName, fn) => {
            if (isSfuEvent(eventName)) {
                return this.dispatcher.off(eventName, fn);
            }
            // unsubscribe from the stream client event by using the 'off' reference
            const registeredOffHandler = this.streamClientEventHandlers.get(fn);
            if (registeredOffHandler) {
                registeredOffHandler();
            }
        };
        /**
         * Leave the call and stop the media streams that were published by the call.
         */
        this.leave = async ({ reject, reason = 'user is leaving the call', } = {}) => {
            await withoutConcurrency(this.joinLeaveConcurrencyTag, async () => {
                const callingState = this.state.callingState;
                if (callingState === exports.CallingState.LEFT) {
                    throw new Error('Cannot leave call that has already been left.');
                }
                if (callingState === exports.CallingState.JOINING) {
                    const waitUntilCallJoined = () => {
                        return new Promise((resolve) => {
                            this.state.callingState$
                                .pipe(rxjs.takeWhile((state) => state !== exports.CallingState.JOINED, true))
                                .subscribe(() => resolve());
                        });
                    };
                    await waitUntilCallJoined();
                }
                if (callingState === exports.CallingState.RINGING && reject !== false) {
                    if (reject) {
                        await this.reject('decline');
                    }
                    else {
                        // if reject was undefined, we still have to cancel the call automatically
                        // when I am the creator and everyone else left the call
                        const hasOtherParticipants = this.state.remoteParticipants.length > 0;
                        if (this.isCreatedByMe && !hasOtherParticipants) {
                            await this.reject('cancel');
                        }
                    }
                }
                this.statsReporter?.stop();
                this.statsReporter = undefined;
                this.sfuStatsReporter?.stop();
                this.sfuStatsReporter = undefined;
                this.subscriber?.dispose();
                this.subscriber = undefined;
                this.publisher?.dispose();
                this.publisher = undefined;
                await this.sfuClient?.leaveAndClose(reason);
                this.sfuClient = undefined;
                this.dynascaleManager.setSfuClient(undefined);
                this.state.setCallingState(exports.CallingState.LEFT);
                this.state.setParticipants([]);
                this.state.dispose();
                // Call all leave call hooks, e.g. to clean up global event handlers
                this.leaveCallHooks.forEach((hook) => hook());
                this.initialized = false;
                this.hasJoinedOnce = false;
                this.ringingSubject.next(false);
                this.cancelAutoDrop();
                this.clientStore.unregisterCall(this);
                this.camera.dispose();
                this.microphone.dispose();
                this.screenShare.dispose();
                this.speaker.dispose();
                const stopOnLeavePromises = [];
                if (this.camera.stopOnLeave) {
                    stopOnLeavePromises.push(this.camera.disable(true));
                }
                if (this.microphone.stopOnLeave) {
                    stopOnLeavePromises.push(this.microphone.disable(true));
                }
                if (this.screenShare.stopOnLeave) {
                    stopOnLeavePromises.push(this.screenShare.disable(true));
                }
                await Promise.all(stopOnLeavePromises);
            });
        };
        /**
         * Update from the call response from the "call.ring" event
         * @internal
         */
        this.updateFromRingingEvent = async (event) => {
            await this.setup();
            // call.ring event excludes the call creator in the members list
            // as the creator does not get the ring event
            // so update the member list accordingly
            const { created_by, settings } = event.call;
            const creator = this.state.members.find((m) => m.user.id === created_by.id);
            if (!creator) {
                this.state.setMembers(event.members);
            }
            else {
                this.state.setMembers([creator, ...event.members]);
            }
            // update the call state with the latest event data
            this.state.updateFromCallResponse(event.call);
            this.watching = true;
            this.ringingSubject.next(true);
            // we remove the instance from the calls list to enable the following filter in useCalls hook
            // const calls = useCalls().filter((c) => c.ringing);
            const calls = this.clientStore.calls.filter((c) => c.cid !== this.cid);
            this.clientStore.setCalls([this, ...calls]);
            await this.applyDeviceConfig(settings, false);
        };
        /**
         * Loads the information about the call.
         *
         * @param params.ring if set to true, a `call.ring` event will be sent to the call members.
         * @param params.notify if set to true, a `call.notification` event will be sent to the call members.
         * @param params.members_limit the total number of members to return as part of the response.
         */
        this.get = async (params) => {
            await this.setup();
            const response = await this.streamClient.get(this.streamClientBasePath, params);
            this.state.updateFromCallResponse(response.call);
            this.state.setMembers(response.members);
            this.state.setOwnCapabilities(response.own_capabilities);
            if (params?.ring) {
                // the call response can indicate where the call is still ringing or not
                this.ringingSubject.next(true);
            }
            if (this.streamClient._hasConnectionID()) {
                this.watching = true;
                this.clientStore.registerCall(this);
            }
            await this.applyDeviceConfig(response.call.settings, false);
            return response;
        };
        /**
         * Loads the information about the call and creates it if it doesn't exist.
         *
         * @param data the data to create the call with.
         */
        this.getOrCreate = async (data) => {
            await this.setup();
            const response = await this.streamClient.post(this.streamClientBasePath, data);
            this.state.updateFromCallResponse(response.call);
            this.state.setMembers(response.members);
            this.state.setOwnCapabilities(response.own_capabilities);
            if (data?.ring) {
                // the call response can indicate where the call is still ringing or not
                this.ringingSubject.next(true);
            }
            if (this.streamClient._hasConnectionID()) {
                this.watching = true;
                this.clientStore.registerCall(this);
            }
            await this.applyDeviceConfig(response.call.settings, false);
            return response;
        };
        /**
         * Creates a call
         *
         * @param data the data to create the call with.
         */
        this.create = async (data) => {
            return this.getOrCreate(data);
        };
        /**
         * Deletes the call.
         */
        this.delete = async (data = {}) => {
            return this.streamClient.post(`${this.streamClientBasePath}/delete`, data);
        };
        /**
         * A shortcut for {@link Call.get} with `ring` parameter set to `true`.
         * Will send a `call.ring` event to the call members.
         */
        this.ring = async () => {
            return await this.get({ ring: true });
        };
        /**
         * A shortcut for {@link Call.get} with `notify` parameter set to `true`.
         * Will send a `call.notification` event to the call members.
         */
        this.notify = async () => {
            return await this.get({ notify: true });
        };
        /**
         * Marks the incoming call as accepted.
         *
         * This method should be used only for "ringing" call flows.
         * {@link Call.join} invokes this method automatically for you when joining a call.
         * Unless you are implementing a custom "ringing" flow, you should not use this method.
         */
        this.accept = async () => {
            return this.streamClient.post(`${this.streamClientBasePath}/accept`);
        };
        /**
         * Marks the incoming call as rejected.
         *
         * This method should be used only for "ringing" call flows.
         * {@link Call.leave} invokes this method automatically for you when you leave or reject this call.
         * Unless you are implementing a custom "ringing" flow, you should not use this method.
         *
         * @param reason the reason for rejecting the call.
         */
        this.reject = async (reason = 'decline') => {
            return this.streamClient.post(`${this.streamClientBasePath}/reject`, { reason: reason });
        };
        /**
         * Will start to watch for call related WebSocket events and initiate a call session with the server.
         *
         * @returns a promise which resolves once the call join-flow has finished.
         */
        this.join = async ({ maxJoinRetries = 3, ...data } = {}) => {
            await this.setup();
            const callingState = this.state.callingState;
            if ([exports.CallingState.JOINED, exports.CallingState.JOINING].includes(callingState)) {
                throw new Error(`Illegal State: call.join() shall be called only once`);
            }
            this.state.setCallingState(exports.CallingState.JOINING);
            maxJoinRetries = Math.max(maxJoinRetries, 1);
            for (let attempt = 0; attempt < maxJoinRetries; attempt++) {
                try {
                    this.logger('trace', `Joining call (${attempt})`, this.cid);
                    return await this.doJoin(data);
                }
                catch (err) {
                    this.logger('warn', `Failed to join call (${attempt})`, this.cid);
                    if (attempt === maxJoinRetries - 1) {
                        // restore the previous call state if the join-flow fails
                        this.state.setCallingState(callingState);
                        throw err;
                    }
                }
                await sleep(retryInterval(attempt));
            }
        };
        /**
         * Will make a single attempt to watch for call related WebSocket events
         * and initiate a call session with the server.
         *
         * @returns a promise which resolves once the call join-flow has finished.
         */
        this.doJoin = async (data) => {
            const connectStartTime = Date.now();
            const callingState = this.state.callingState;
            this.joinCallData = data;
            this.logger('debug', 'Starting join flow');
            this.state.setCallingState(exports.CallingState.JOINING);
            const performingMigration = this.reconnectStrategy === WebsocketReconnectStrategy.MIGRATE;
            const performingRejoin = this.reconnectStrategy === WebsocketReconnectStrategy.REJOIN;
            const performingFastReconnect = this.reconnectStrategy === WebsocketReconnectStrategy.FAST;
            let statsOptions = this.sfuStatsReporter?.options;
            if (!this.credentials ||
                !statsOptions ||
                performingRejoin ||
                performingMigration) {
                try {
                    const joinResponse = await this.doJoinRequest(data);
                    this.credentials = joinResponse.credentials;
                    statsOptions = joinResponse.stats_options;
                }
                catch (error) {
                    // prevent triggering reconnect flow if the state is OFFLINE
                    const avoidRestoreState = this.state.callingState === exports.CallingState.OFFLINE;
                    if (!avoidRestoreState) {
                        // restore the previous call state if the join-flow fails
                        this.state.setCallingState(callingState);
                    }
                    throw error;
                }
            }
            const previousSfuClient = this.sfuClient;
            const previousSessionId = previousSfuClient?.sessionId;
            const isWsHealthy = !!previousSfuClient?.isHealthy;
            const sfuClient = performingRejoin || performingMigration || !isWsHealthy
                ? new StreamSfuClient({
                    logTag: String(++this.sfuClientTag),
                    dispatcher: this.dispatcher,
                    credentials: this.credentials,
                    streamClient: this.streamClient,
                    enableTracing: statsOptions.enable_rtc_stats,
                    // a new session_id is necessary for the REJOIN strategy.
                    // we use the previous session_id if available
                    sessionId: performingRejoin ? undefined : previousSessionId,
                    onSignalClose: (reason) => this.handleSfuSignalClose(sfuClient, reason),
                })
                : previousSfuClient;
            this.sfuClient = sfuClient;
            this.dynascaleManager.setSfuClient(sfuClient);
            const clientDetails = await getClientDetails();
            // we don't need to send JoinRequest if we are re-using an existing healthy SFU client
            if (previousSfuClient !== sfuClient) {
                // prepare a generic SDP and send it to the SFU.
                // these are throw-away SDPs that the SFU will use to determine
                // the capabilities of the client (codec support, etc.)
                const [subscriberSdp, publisherSdp] = await Promise.all([
                    getGenericSdp('recvonly'),
                    getGenericSdp('sendonly'),
                ]);
                const isReconnecting = this.reconnectStrategy !== WebsocketReconnectStrategy.UNSPECIFIED;
                const reconnectDetails = isReconnecting
                    ? this.getReconnectDetails(data?.migrating_from, previousSessionId)
                    : undefined;
                const preferredPublishOptions = !isReconnecting
                    ? this.getPreferredPublishOptions()
                    : this.currentPublishOptions || [];
                const preferredSubscribeOptions = !isReconnecting
                    ? this.getPreferredSubscribeOptions()
                    : [];
                try {
                    const { callState, fastReconnectDeadlineSeconds, publishOptions } = await sfuClient.join({
                        subscriberSdp,
                        publisherSdp,
                        clientDetails,
                        fastReconnect: performingFastReconnect,
                        reconnectDetails,
                        preferredPublishOptions,
                        preferredSubscribeOptions,
                    });
                    this.currentPublishOptions = publishOptions;
                    this.fastReconnectDeadlineSeconds = fastReconnectDeadlineSeconds;
                    if (callState) {
                        this.state.updateFromSfuCallState(callState, sfuClient.sessionId, reconnectDetails);
                    }
                }
                catch (error) {
                    this.logger('warn', 'Join SFU request failed', error);
                    sfuClient.close(StreamSfuClient.ERROR_CONNECTION_UNHEALTHY, 'Join request failed, connection considered unhealthy');
                    // restore the previous call state if the join-flow fails
                    this.state.setCallingState(callingState);
                    throw error;
                }
            }
            if (!performingMigration) {
                // in MIGRATION, `JOINED` state is set in `this.reconnectMigrate()`
                this.state.setCallingState(exports.CallingState.JOINED);
            }
            this.hasJoinedOnce = true;
            // when performing fast reconnect, or when we reuse the same SFU client,
            // (ws remained healthy), we just need to restore the ICE connection
            if (performingFastReconnect) {
                // the SFU automatically issues an ICE restart on the subscriber
                // we don't have to do it ourselves
                await this.restoreICE(sfuClient, { includeSubscriber: false });
            }
            else {
                const connectionConfig = toRtcConfiguration(this.credentials.ice_servers);
                this.initPublisherAndSubscriber({
                    sfuClient,
                    connectionConfig,
                    clientDetails,
                    statsOptions,
                    publishOptions: this.currentPublishOptions || [],
                    closePreviousInstances: !performingMigration,
                });
            }
            // make sure we only track connection timing if we are not calling this method as part of a reconnection flow
            if (!performingRejoin && !performingFastReconnect && !performingMigration) {
                this.sfuStatsReporter?.sendConnectionTime((Date.now() - connectStartTime) / 1000);
            }
            if (performingRejoin) {
                const strategy = WebsocketReconnectStrategy[this.reconnectStrategy];
                await previousSfuClient?.leaveAndClose(`Closing previous WS after reconnect with strategy: ${strategy}`);
            }
            else if (!isWsHealthy) {
                previousSfuClient?.close(StreamSfuClient.DISPOSE_OLD_SOCKET, 'Closing unhealthy WS after reconnect');
            }
            // device settings should be applied only once, we don't have to
            // re-apply them on later reconnections or server-side data fetches
            if (!this.deviceSettingsAppliedOnce && this.state.settings) {
                await this.applyDeviceConfig(this.state.settings, true);
                this.deviceSettingsAppliedOnce = true;
            }
            // We shouldn't persist the `ring` and `notify` state after joining the call
            // as it's a one-time event and clashes with the potential reconnection attempts.
            // When reconnecting, if provided with `ring: true` or `notify: true`,
            // we will spam the other participants with push notifications and `call.ring` events.
            delete this.joinCallData?.ring;
            delete this.joinCallData?.notify;
            // reset the reconnect strategy to unspecified after a successful reconnection
            this.reconnectStrategy = WebsocketReconnectStrategy.UNSPECIFIED;
            this.reconnectReason = '';
            this.logger('info', `Joined call ${this.cid}`);
        };
        /**
         * Prepares Reconnect Details object.
         * @internal
         */
        this.getReconnectDetails = (migratingFromSfuId, previousSessionId) => {
            const strategy = this.reconnectStrategy;
            const performingRejoin = strategy === WebsocketReconnectStrategy.REJOIN;
            const announcedTracks = this.publisher?.getAnnouncedTracksForReconnect() || [];
            return {
                strategy,
                announcedTracks,
                subscriptions: this.dynascaleManager.trackSubscriptions,
                reconnectAttempt: this.reconnectAttempts,
                fromSfuId: migratingFromSfuId || '',
                previousSessionId: performingRejoin ? previousSessionId || '' : '',
                reason: this.reconnectReason,
            };
        };
        /**
         * Prepares the preferred codec for the call.
         * This is an experimental client feature and subject to change.
         * @internal
         */
        this.getPreferredPublishOptions = () => {
            const { preferredCodec, fmtpLine, preferredBitrate, maxSimulcastLayers } = this.clientPublishOptions || {};
            if (!preferredCodec && !preferredBitrate && !maxSimulcastLayers)
                return [];
            const codec = preferredCodec
                ? Codec.create({ name: preferredCodec.split('/').pop(), fmtp: fmtpLine })
                : undefined;
            const preferredPublishOptions = [
                PublishOption.create({
                    trackType: TrackType.VIDEO,
                    codec,
                    bitrate: preferredBitrate,
                    maxSpatialLayers: maxSimulcastLayers,
                }),
            ];
            const screenShareSettings = this.screenShare.getSettings();
            if (screenShareSettings) {
                preferredPublishOptions.push(PublishOption.create({
                    trackType: TrackType.SCREEN_SHARE,
                    fps: screenShareSettings.maxFramerate,
                    bitrate: screenShareSettings.maxBitrate,
                }));
            }
            return preferredPublishOptions;
        };
        /**
         * Prepares the preferred options for subscribing to tracks.
         * This is an experimental client feature and subject to change.
         * @internal
         */
        this.getPreferredSubscribeOptions = () => {
            const { subscriberCodec, subscriberFmtpLine } = this.clientPublishOptions || {};
            if (!subscriberCodec || !subscriberFmtpLine)
                return [];
            return [
                SubscribeOption.create({
                    trackType: TrackType.VIDEO,
                    codecs: [
                        { name: subscriberCodec.split('/').pop(), fmtp: subscriberFmtpLine },
                    ],
                }),
            ];
        };
        /**
         * Performs an ICE restart on both the Publisher and Subscriber Peer Connections.
         * Uses the provided SFU client to restore the ICE connection.
         *
         * This method can throw an error if the ICE restart fails.
         * This error should be handled by the reconnect loop,
         * and a new reconnection shall be attempted.
         *
         * @internal
         */
        this.restoreICE = async (nextSfuClient, opts = {}) => {
            const { includeSubscriber = true, includePublisher = true } = opts;
            if (this.subscriber) {
                this.subscriber.setSfuClient(nextSfuClient);
                if (includeSubscriber) {
                    await this.subscriber.restartIce();
                }
            }
            if (this.publisher) {
                this.publisher.setSfuClient(nextSfuClient);
                if (includePublisher) {
                    await this.publisher.restartIce();
                }
            }
        };
        /**
         * Initializes the Publisher and Subscriber Peer Connections.
         * @internal
         */
        this.initPublisherAndSubscriber = (opts) => {
            const { sfuClient, connectionConfig, clientDetails, statsOptions, publishOptions, closePreviousInstances, } = opts;
            const { enable_rtc_stats: enableTracing } = statsOptions;
            if (closePreviousInstances && this.subscriber) {
                this.subscriber.dispose();
            }
            this.subscriber = new Subscriber({
                sfuClient,
                dispatcher: this.dispatcher,
                state: this.state,
                connectionConfig,
                logTag: String(this.sfuClientTag),
                clientDetails,
                enableTracing,
                onUnrecoverableError: (reason) => {
                    this.reconnect(WebsocketReconnectStrategy.REJOIN, reason).catch((err) => {
                        this.logger('warn', `[Reconnect] Error reconnecting after a subscriber error: ${reason}`, err);
                    });
                },
            });
            // anonymous users can't publish anything hence, there is no need
            // to create Publisher Peer Connection for them
            const isAnonymous = this.streamClient.user?.type === 'anonymous';
            if (!isAnonymous) {
                if (closePreviousInstances && this.publisher) {
                    this.publisher.dispose();
                }
                this.publisher = new Publisher({
                    sfuClient,
                    dispatcher: this.dispatcher,
                    state: this.state,
                    connectionConfig,
                    publishOptions,
                    logTag: String(this.sfuClientTag),
                    clientDetails,
                    enableTracing,
                    onUnrecoverableError: (reason) => {
                        this.reconnect(WebsocketReconnectStrategy.REJOIN, reason).catch((err) => {
                            this.logger('warn', `[Reconnect] Error reconnecting after a publisher error: ${reason}`, err);
                        });
                    },
                });
            }
            tracer.setEnabled(enableTracing);
            this.statsReporter?.stop();
            this.statsReporter = createStatsReporter({
                subscriber: this.subscriber,
                publisher: this.publisher,
                state: this.state,
                datacenter: sfuClient.edgeName,
            });
            this.sfuStatsReporter?.stop();
            if (statsOptions?.reporting_interval_ms > 0) {
                this.sfuStatsReporter = new SfuStatsReporter(sfuClient, {
                    clientDetails,
                    options: statsOptions,
                    subscriber: this.subscriber,
                    publisher: this.publisher,
                    microphone: this.microphone,
                    camera: this.camera,
                    state: this.state,
                });
                this.sfuStatsReporter.start();
            }
        };
        /**
         * Retrieves credentials for joining the call.
         *
         * @internal
         *
         * @param data the join call data.
         */
        this.doJoinRequest = async (data) => {
            const location = await this.streamClient.getLocationHint();
            const request = { ...data, location };
            const joinResponse = await this.streamClient.post(`${this.streamClientBasePath}/join`, request);
            this.state.updateFromCallResponse(joinResponse.call);
            this.state.setMembers(joinResponse.members);
            this.state.setOwnCapabilities(joinResponse.own_capabilities);
            if (data?.ring) {
                this.ringingSubject.next(true);
            }
            const isReconnecting = this.reconnectStrategy !== WebsocketReconnectStrategy.UNSPECIFIED;
            if (!isReconnecting && this.ringing && !this.isCreatedByMe) {
                // signals other users that I have accepted the incoming call.
                await this.accept();
            }
            if (this.streamClient._hasConnectionID()) {
                this.watching = true;
                this.clientStore.registerCall(this);
            }
            return joinResponse;
        };
        /**
         * Handles the closing of the SFU signal connection.
         *
         * @internal
         * @param sfuClient the SFU client instance that was closed.
         * @param reason the reason for the closure.
         */
        this.handleSfuSignalClose = (sfuClient, reason) => {
            this.logger('debug', '[Reconnect] SFU signal connection closed');
            const { callingState } = this.state;
            if (
            // SFU WS closed before we finished current join,
            // no need to schedule reconnecting
            callingState === exports.CallingState.JOINING ||
                // we are already in the process of reconnecting,
                // no need to schedule another one
                callingState === exports.CallingState.RECONNECTING ||
                // SFU WS closed as a result of unsuccessful join,
                // and no further retries need to be made
                callingState === exports.CallingState.IDLE ||
                callingState === exports.CallingState.LEFT)
                return;
            // normal close, no need to reconnect
            if (sfuClient.isLeaving || sfuClient.isClosing)
                return;
            this.reconnect(WebsocketReconnectStrategy.REJOIN, reason).catch((err) => {
                this.logger('warn', '[Reconnect] Error reconnecting', err);
            });
        };
        /**
         * Handles the reconnection flow.
         *
         * @internal
         *
         * @param strategy the reconnection strategy to use.
         * @param reason the reason for the reconnection.
         */
        this.reconnect = async (strategy, reason) => {
            if (this.state.callingState === exports.CallingState.RECONNECTING ||
                this.state.callingState === exports.CallingState.RECONNECTING_FAILED)
                return;
            return withoutConcurrency(this.reconnectConcurrencyTag, async () => {
                this.logger('info', `[Reconnect] Reconnecting with strategy ${WebsocketReconnectStrategy[strategy]}`);
                const reconnectStartTime = Date.now();
                this.reconnectStrategy = strategy;
                this.reconnectReason = reason;
                do {
                    if (this.disconnectionTimeoutSeconds > 0 &&
                        (Date.now() - reconnectStartTime) / 1000 >
                            this.disconnectionTimeoutSeconds) {
                        this.logger('warn', '[Reconnect] Stopping reconnection attempts after reaching disconnection timeout');
                        this.state.setCallingState(exports.CallingState.RECONNECTING_FAILED);
                        return;
                    }
                    // we don't increment reconnect attempts for the FAST strategy.
                    if (this.reconnectStrategy !== WebsocketReconnectStrategy.FAST) {
                        this.reconnectAttempts++;
                    }
                    const current = WebsocketReconnectStrategy[this.reconnectStrategy];
                    try {
                        // wait until the network is available
                        await this.networkAvailableTask?.promise;
                        switch (this.reconnectStrategy) {
                            case WebsocketReconnectStrategy.UNSPECIFIED:
                            case WebsocketReconnectStrategy.DISCONNECT:
                                this.logger('debug', `[Reconnect] No-op strategy ${current}`);
                                break;
                            case WebsocketReconnectStrategy.FAST:
                                await this.reconnectFast();
                                break;
                            case WebsocketReconnectStrategy.REJOIN:
                                await this.reconnectRejoin();
                                break;
                            case WebsocketReconnectStrategy.MIGRATE:
                                await this.reconnectMigrate();
                                break;
                            default:
                                ensureExhausted(this.reconnectStrategy, 'Unknown reconnection strategy');
                                break;
                        }
                        break; // do-while loop, reconnection worked, exit the loop
                    }
                    catch (error) {
                        if (this.state.callingState === exports.CallingState.OFFLINE) {
                            this.logger('trace', `[Reconnect] Can't reconnect while offline, stopping reconnection attempts`);
                            break;
                            // we don't need to handle the error if the call is offline
                            // network change event will trigger the reconnection
                        }
                        if (error instanceof ErrorFromResponse && error.unrecoverable) {
                            this.logger('warn', `[Reconnect] Can't reconnect due to coordinator unrecoverable error`, error);
                            this.state.setCallingState(exports.CallingState.RECONNECTING_FAILED);
                            return;
                        }
                        this.logger('warn', `[Reconnect] ${current} (${this.reconnectAttempts}) failed. Attempting with REJOIN`, error);
                        await sleep(500);
                        this.reconnectStrategy = WebsocketReconnectStrategy.REJOIN;
                    }
                } while (this.state.callingState !== exports.CallingState.JOINED &&
                    this.state.callingState !== exports.CallingState.RECONNECTING_FAILED &&
                    this.state.callingState !== exports.CallingState.LEFT);
            });
        };
        /**
         * Initiates the reconnection flow with the "fast" strategy.
         * @internal
         */
        this.reconnectFast = async () => {
            const reconnectStartTime = Date.now();
            this.reconnectStrategy = WebsocketReconnectStrategy.FAST;
            this.state.setCallingState(exports.CallingState.RECONNECTING);
            await this.doJoin(this.joinCallData);
            this.sfuStatsReporter?.sendReconnectionTime(WebsocketReconnectStrategy.FAST, (Date.now() - reconnectStartTime) / 1000);
        };
        /**
         * Initiates the reconnection flow with the "rejoin" strategy.
         * @internal
         */
        this.reconnectRejoin = async () => {
            const reconnectStartTime = Date.now();
            this.reconnectStrategy = WebsocketReconnectStrategy.REJOIN;
            this.state.setCallingState(exports.CallingState.RECONNECTING);
            await this.doJoin(this.joinCallData);
            await this.restorePublishedTracks();
            this.restoreSubscribedTracks();
            this.sfuStatsReporter?.sendReconnectionTime(WebsocketReconnectStrategy.REJOIN, (Date.now() - reconnectStartTime) / 1000);
        };
        /**
         * Initiates the reconnection flow with the "migrate" strategy.
         * @internal
         */
        this.reconnectMigrate = async () => {
            const reconnectStartTime = Date.now();
            const currentSfuClient = this.sfuClient;
            if (!currentSfuClient) {
                throw new Error('Cannot migrate without an active SFU client');
            }
            this.reconnectStrategy = WebsocketReconnectStrategy.MIGRATE;
            this.state.setCallingState(exports.CallingState.MIGRATING);
            const currentSubscriber = this.subscriber;
            const currentPublisher = this.publisher;
            currentSubscriber?.detachEventHandlers();
            currentPublisher?.detachEventHandlers();
            const migrationTask = makeSafePromise(currentSfuClient.enterMigration());
            try {
                const currentSfu = currentSfuClient.edgeName;
                await this.doJoin({ ...this.joinCallData, migrating_from: currentSfu });
            }
            finally {
                // cleanup the migration_from field after the migration is complete or failed
                // as we don't want to keep dirty data in the join call data
                delete this.joinCallData?.migrating_from;
            }
            await this.restorePublishedTracks();
            this.restoreSubscribedTracks();
            try {
                // Wait for the migration to complete, then close the previous SFU client
                // and the peer connection instances. In case of failure, the migration
                // task would throw an error and REJOIN would be attempted.
                await migrationTask();
                // in MIGRATE, we can consider the call as joined only after
                // `participantMigrationComplete` event is received, signaled by
                // the `migrationTask`
                this.state.setCallingState(exports.CallingState.JOINED);
            }
            finally {
                currentSubscriber?.dispose();
                currentPublisher?.dispose();
                // and close the previous SFU client, without specifying close code
                currentSfuClient.close(StreamSfuClient.NORMAL_CLOSURE, 'Migrating away');
            }
            this.sfuStatsReporter?.sendReconnectionTime(WebsocketReconnectStrategy.MIGRATE, (Date.now() - reconnectStartTime) / 1000);
        };
        /**
         * Registers the various event handlers for reconnection.
         *
         * @internal
         */
        this.registerReconnectHandlers = () => {
            // handles the legacy "goAway" event
            const unregisterGoAway = this.on('goAway', () => {
                this.reconnect(WebsocketReconnectStrategy.MIGRATE, 'goAway').catch((err) => this.logger('warn', '[Reconnect] Error reconnecting', err));
            });
            // handles the "error" event, through which the SFU can request a reconnect
            const unregisterOnError = this.on('error', (e) => {
                const { reconnectStrategy: strategy, error } = e;
                if (strategy === WebsocketReconnectStrategy.UNSPECIFIED)
                    return;
                if (strategy === WebsocketReconnectStrategy.DISCONNECT) {
                    this.leave({ reason: 'SFU instructed to disconnect' }).catch((err) => {
                        this.logger('warn', `Can't leave call after disconnect request`, err);
                    });
                }
                else {
                    this.reconnect(strategy, error?.message || 'SFU Error').catch((err) => {
                        this.logger('warn', '[Reconnect] Error reconnecting', err);
                    });
                }
            });
            const unregisterNetworkChanged = this.streamClient.on('network.changed', (e) => {
                if (!e.online) {
                    this.logger('debug', '[Reconnect] Going offline');
                    if (!this.hasJoinedOnce)
                        return;
                    this.lastOfflineTimestamp = Date.now();
                    // create a new task that would resolve when the network is available
                    const networkAvailableTask = promiseWithResolvers();
                    networkAvailableTask.promise.then(() => {
                        let strategy = WebsocketReconnectStrategy.FAST;
                        if (this.lastOfflineTimestamp) {
                            const offline = (Date.now() - this.lastOfflineTimestamp) / 1000;
                            if (offline > this.fastReconnectDeadlineSeconds) {
                                // We shouldn't attempt FAST if we have exceeded the deadline.
                                // The SFU would have already wiped out the session.
                                strategy = WebsocketReconnectStrategy.REJOIN;
                            }
                        }
                        this.reconnect(strategy, 'Going online').catch((err) => {
                            this.logger('warn', '[Reconnect] Error reconnecting after going online', err);
                        });
                    });
                    this.networkAvailableTask = networkAvailableTask;
                    this.sfuStatsReporter?.stop();
                    this.state.setCallingState(exports.CallingState.OFFLINE);
                }
                else {
                    this.logger('debug', '[Reconnect] Going online');
                    this.sfuClient?.close(StreamSfuClient.DISPOSE_OLD_SOCKET, 'Closing WS to reconnect after going online');
                    // we went online, release the previous waiters and reset the state
                    this.networkAvailableTask?.resolve();
                    this.networkAvailableTask = undefined;
                    this.sfuStatsReporter?.start();
                }
            });
            this.leaveCallHooks
                .add(unregisterGoAway)
                .add(unregisterOnError)
                .add(unregisterNetworkChanged);
        };
        /**
         * Restores the published tracks after a reconnection.
         * @internal
         */
        this.restorePublishedTracks = async () => {
            // the tracks need to be restored in their original order of publishing
            // otherwise, we might get `m-lines order mismatch` errors
            for (const trackType of this.trackPublishOrder) {
                let mediaStream;
                switch (trackType) {
                    case TrackType.AUDIO:
                        mediaStream = this.microphone.state.mediaStream;
                        break;
                    case TrackType.VIDEO:
                        mediaStream = this.camera.state.mediaStream;
                        break;
                    case TrackType.SCREEN_SHARE:
                        mediaStream = this.screenShare.state.mediaStream;
                        break;
                    // screen share audio can't exist without a screen share, so we handle it there
                    case TrackType.SCREEN_SHARE_AUDIO:
                    case TrackType.UNSPECIFIED:
                        break;
                    default:
                        ensureExhausted(trackType, 'Unknown track type');
                        break;
                }
                if (mediaStream)
                    await this.publish(mediaStream, trackType);
            }
        };
        /**
         * Restores the subscribed tracks after a reconnection.
         * @internal
         */
        this.restoreSubscribedTracks = () => {
            const { remoteParticipants } = this.state;
            if (remoteParticipants.length <= 0)
                return;
            this.dynascaleManager.applyTrackSubscriptions(undefined);
        };
        /**
         * Starts publishing the given video stream to the call.
         * @deprecated use `call.publish()`.
         */
        this.publishVideoStream = async (videoStream) => {
            await this.publish(videoStream, TrackType.VIDEO);
        };
        /**
         * Starts publishing the given audio stream to the call.
         * @deprecated use `call.publish()`
         */
        this.publishAudioStream = async (audioStream) => {
            await this.publish(audioStream, TrackType.AUDIO);
        };
        /**
         * Starts publishing the given screen-share stream to the call.
         * @deprecated use `call.publish()`
         */
        this.publishScreenShareStream = async (screenShareStream) => {
            await this.publish(screenShareStream, TrackType.SCREEN_SHARE);
        };
        /**
         * Publishes the given media stream.
         *
         * @param mediaStream the media stream to publish.
         * @param trackType the type of the track to announce.
         */
        this.publish = async (mediaStream, trackType) => {
            if (!this.sfuClient)
                throw new Error(`Call not joined yet.`);
            // joining is in progress, and we should wait until the client is ready
            await this.sfuClient.joinTask;
            if (!this.permissionsContext.canPublish(trackType)) {
                throw new Error(`No permission to publish ${TrackType[trackType]}`);
            }
            if (!this.publisher)
                throw new Error('Publisher is not initialized');
            const [track] = isAudioTrackType(trackType)
                ? mediaStream.getAudioTracks()
                : mediaStream.getVideoTracks();
            if (!track) {
                throw new Error(`There is no ${TrackType[trackType]} track in the stream`);
            }
            if (track.readyState === 'ended') {
                throw new Error(`Can't publish ended tracks.`);
            }
            pushToIfMissing(this.trackPublishOrder, trackType);
            await this.publisher.publish(track, trackType);
            const trackTypes = [trackType];
            if (trackType === TrackType.SCREEN_SHARE) {
                const [audioTrack] = mediaStream.getAudioTracks();
                if (audioTrack) {
                    pushToIfMissing(this.trackPublishOrder, TrackType.SCREEN_SHARE_AUDIO);
                    await this.publisher.publish(audioTrack, TrackType.SCREEN_SHARE_AUDIO);
                    trackTypes.push(TrackType.SCREEN_SHARE_AUDIO);
                }
            }
            await this.updateLocalStreamState(mediaStream, ...trackTypes);
        };
        /**
         * Stops publishing the given track type to the call, if it is currently being published.
         *
         * @param trackTypes the track types to stop publishing.
         */
        this.stopPublish = async (...trackTypes) => {
            if (!this.sfuClient || !this.publisher)
                return;
            this.publisher.stopTracks(...trackTypes);
            await this.updateLocalStreamState(undefined, ...trackTypes);
        };
        /**
         * Updates the call state with the new stream.
         *
         * @param mediaStream the new stream to update the call state with.
         * If undefined, the stream will be removed from the call state.
         * @param trackTypes the track types to update the call state with.
         */
        this.updateLocalStreamState = async (mediaStream, ...trackTypes) => {
            if (!this.sfuClient || !this.sfuClient.sessionId)
                return;
            await this.notifyTrackMuteState(!mediaStream, ...trackTypes);
            const { sessionId } = this.sfuClient;
            for (const trackType of trackTypes) {
                const streamStateProp = trackTypeToParticipantStreamKey(trackType);
                if (!streamStateProp)
                    continue;
                this.state.updateParticipant(sessionId, (p) => ({
                    publishedTracks: mediaStream
                        ? pushToIfMissing([...p.publishedTracks], trackType)
                        : p.publishedTracks.filter((t) => t !== trackType),
                    [streamStateProp]: mediaStream,
                }));
            }
        };
        /**
         * Updates the preferred publishing options
         *
         * @internal
         * @param options the options to use.
         */
        this.updatePublishOptions = (options) => {
            this.logger('warn', '[call.updatePublishOptions]: You are manually overriding the publish options for this call. ' +
                'This is not recommended, and it can cause call stability/compatibility issues. Use with caution.');
            if (this.state.callingState === exports.CallingState.JOINED) {
                this.logger('warn', 'Updating publish options after joining the call does not have an effect');
            }
            this.clientPublishOptions = { ...this.clientPublishOptions, ...options };
        };
        /**
         * Notifies the SFU that a noise cancellation process has started.
         *
         * @internal
         */
        this.notifyNoiseCancellationStarting = async () => {
            return this.sfuClient?.startNoiseCancellation().catch((err) => {
                this.logger('warn', 'Failed to notify start of noise cancellation', err);
            });
        };
        /**
         * Notifies the SFU that a noise cancellation process has stopped.
         *
         * @internal
         */
        this.notifyNoiseCancellationStopped = async () => {
            return this.sfuClient?.stopNoiseCancellation().catch((err) => {
                this.logger('warn', 'Failed to notify stop of noise cancellation', err);
            });
        };
        /**
         * Notifies the SFU about the mute state of the given track types.
         * @internal
         */
        this.notifyTrackMuteState = async (muted, ...trackTypes) => {
            if (!this.sfuClient)
                return;
            await this.sfuClient.updateMuteStates(trackTypes.map((trackType) => ({ trackType, muted })));
        };
        /**
         * Will enhance the reported stats with additional participant-specific information (`callStatsReport$` state [store variable](./StreamVideoClient.md/#readonlystatestore)).
         * This is usually helpful when detailed stats for a specific participant are needed.
         *
         * @param sessionId the sessionId to start reporting for.
         */
        this.startReportingStatsFor = (sessionId) => {
            return this.statsReporter?.startReportingStatsFor(sessionId);
        };
        /**
         * Opposite of `startReportingStatsFor`.
         * Will turn off stats reporting for a specific participant.
         *
         * @param sessionId the sessionId to stop reporting for.
         */
        this.stopReportingStatsFor = (sessionId) => {
            return this.statsReporter?.stopReportingStatsFor(sessionId);
        };
        /**
         * Resets the last sent reaction for the user holding the given `sessionId`. This is a local action, it won't reset the reaction on the backend.
         *
         * @param sessionId the session id.
         */
        this.resetReaction = (sessionId) => {
            this.state.updateParticipant(sessionId, {
                reaction: undefined,
            });
        };
        /**
         * Sets the list of criteria to sort the participants by.
         *
         * @param criteria the list of criteria to sort the participants by.
         */
        this.setSortParticipantsBy = (criteria) => {
            return this.state.setSortParticipantsBy(criteria);
        };
        /**
         * Sends a reaction to the other call participants.
         *
         * @param reaction the reaction to send.
         */
        this.sendReaction = async (reaction) => {
            return this.streamClient.post(`${this.streamClientBasePath}/reaction`, reaction);
        };
        /**
         * Blocks the user with the given `userId`.
         *
         * @param userId the id of the user to block.
         */
        this.blockUser = async (userId) => {
            return this.streamClient.post(`${this.streamClientBasePath}/block`, {
                user_id: userId,
            });
        };
        /**
         * Unblocks the user with the given `userId`.
         *
         * @param userId the id of the user to unblock.
         */
        this.unblockUser = async (userId) => {
            return this.streamClient.post(`${this.streamClientBasePath}/unblock`, {
                user_id: userId,
            });
        };
        /**
         * Mutes the current user.
         *
         * @param type the type of the mute operation.
         */
        this.muteSelf = (type) => {
            const myUserId = this.currentUserId;
            if (myUserId) {
                return this.muteUser(myUserId, type);
            }
        };
        /**
         * Mutes all the other participants.
         *
         * @param type the type of the mute operation.
         */
        this.muteOthers = (type) => {
            const trackType = muteTypeToTrackType(type);
            if (!trackType)
                return;
            const userIdsToMute = [];
            for (const participant of this.state.remoteParticipants) {
                if (participant.publishedTracks.includes(trackType)) {
                    userIdsToMute.push(participant.userId);
                }
            }
            if (userIdsToMute.length > 0) {
                return this.muteUser(userIdsToMute, type);
            }
        };
        /**
         * Mutes the user with the given `userId`.
         *
         * @param userId the id of the user to mute.
         * @param type the type of the mute operation.
         */
        this.muteUser = (userId, type) => {
            return this.streamClient.post(`${this.streamClientBasePath}/mute_users`, {
                user_ids: Array.isArray(userId) ? userId : [userId],
                [type]: true,
            });
        };
        /**
         * Will mute all users in the call.
         *
         * @param type the type of the mute operation.
         */
        this.muteAllUsers = (type) => {
            return this.streamClient.post(`${this.streamClientBasePath}/mute_users`, {
                mute_all_users: true,
                [type]: true,
            });
        };
        /**
         * Starts recording the call
         */
        this.startRecording = async (request) => {
            return this.streamClient.post(`${this.streamClientBasePath}/start_recording`, request ? request : {});
        };
        /**
         * Stops recording the call
         */
        this.stopRecording = async () => {
            return this.streamClient.post(`${this.streamClientBasePath}/stop_recording`, {});
        };
        /**
         * Starts the transcription of the call.
         *
         * @param request the request data.
         */
        this.startTranscription = async (request) => {
            return this.streamClient.post(`${this.streamClientBasePath}/start_transcription`, request);
        };
        /**
         * Stops the transcription of the call.
         */
        this.stopTranscription = async () => {
            return this.streamClient.post(`${this.streamClientBasePath}/stop_transcription`);
        };
        /**
         * Starts the closed captions of the call.
         */
        this.startClosedCaptions = async (options) => {
            const trx = this.state.setCaptioning(true); // optimistic update
            try {
                return await this.streamClient.post(`${this.streamClientBasePath}/start_closed_captions`, options);
            }
            catch (err) {
                trx.rollback(); // revert the optimistic update
                throw err;
            }
        };
        /**
         * Stops the closed captions of the call.
         */
        this.stopClosedCaptions = async (options) => {
            const trx = this.state.setCaptioning(false); // optimistic update
            try {
                return await this.streamClient.post(`${this.streamClientBasePath}/stop_closed_captions`, options);
            }
            catch (err) {
                trx.rollback(); // revert the optimistic update
                throw err;
            }
        };
        /**
         * Updates the closed caption settings.
         *
         * @param config the closed caption settings to apply
         */
        this.updateClosedCaptionSettings = (config) => {
            this.state.updateClosedCaptionSettings(config);
        };
        /**
         * Sends a `call.permission_request` event to all users connected to the call.
         * The call settings object contains information about which permissions can be requested during a call
         * (for example, a user might be allowed to request permission to publish audio, but not video).
         */
        this.requestPermissions = async (data) => {
            const { permissions } = data;
            const canRequestPermissions = permissions.every((permission) => this.permissionsContext.canRequest(permission));
            if (!canRequestPermissions) {
                throw new Error(`You are not allowed to request permissions: ${permissions.join(', ')}`);
            }
            return this.streamClient.post(`${this.streamClientBasePath}/request_permission`, data);
        };
        /**
         * Allows you to grant certain permissions to a user in a call.
         * The permissions are specific to the call experience and do not survive the call itself.
         *
         * Supported permissions that can be granted are:
         * - `send-audio`
         * - `send-video`
         * - `screenshare`
         *
         * @param userId the id of the user to grant permissions to.
         * @param permissions the permissions to grant.
         */
        this.grantPermissions = async (userId, permissions) => {
            return this.updateUserPermissions({
                user_id: userId,
                grant_permissions: permissions,
            });
        };
        /**
         * Allows you to revoke certain permissions from a user in a call.
         * The permissions are specific to the call experience and do not survive the call itself.
         *
         * Supported permissions that can be revoked are:
         * - `send-audio`
         * - `send-video`
         * - `screenshare`
         *
         * @param userId the id of the user to revoke permissions from.
         * @param permissions the permissions to revoke.
         */
        this.revokePermissions = async (userId, permissions) => {
            return this.updateUserPermissions({
                user_id: userId,
                revoke_permissions: permissions,
            });
        };
        /**
         * Allows you to grant or revoke a specific permission to a user in a call. The permissions are specific to the call experience and do not survive the call itself.
         *
         * When revoking a permission, this endpoint will also mute the relevant track from the user. This is similar to muting a user with the difference that the user will not be able to unmute afterwards.
         *
         * Supported permissions that can be granted or revoked: `send-audio`, `send-video` and `screenshare`.
         *
         * `call.permissions_updated` event is sent to all members of the call.
         *
         */
        this.updateUserPermissions = async (data) => {
            return this.streamClient.post(`${this.streamClientBasePath}/user_permissions`, data);
        };
        /**
         * Starts the livestreaming of the call.
         *
         * @param data the request data.
         * @param params the request params.
         */
        this.goLive = async (data = {}, params) => {
            return this.streamClient.post(`${this.streamClientBasePath}/go_live`, data, params);
        };
        /**
         * Stops the livestreaming of the call.
         */
        this.stopLive = async (data = {}) => {
            return this.streamClient.post(`${this.streamClientBasePath}/stop_live`, data);
        };
        /**
         * Starts the broadcasting of the call.
         */
        this.startHLS = async () => {
            return this.streamClient.post(`${this.streamClientBasePath}/start_broadcasting`, {});
        };
        /**
         * Stops the broadcasting of the call.
         */
        this.stopHLS = async () => {
            return this.streamClient.post(`${this.streamClientBasePath}/stop_broadcasting`, {});
        };
        /**
         * Starts the RTMP-out broadcasting of the call.
         */
        this.startRTMPBroadcasts = async (data) => {
            return this.streamClient.post(`${this.streamClientBasePath}/rtmp_broadcasts`, data);
        };
        /**
         * Stops all RTMP-out broadcasting of the call.
         */
        this.stopAllRTMPBroadcasts = async () => {
            return this.streamClient.post(`${this.streamClientBasePath}/rtmp_broadcasts/stop`);
        };
        /**
         * Stops the RTMP-out broadcasting of the call specified by it's name.
         */
        this.stopRTMPBroadcast = async (name) => {
            return this.streamClient.post(`${this.streamClientBasePath}/rtmp_broadcasts/${name}/stop`);
        };
        /**
         * Starts frame by frame recording.
         * Sends call.frame_recording_started events
         */
        this.startFrameRecording = async (data) => {
            return this.streamClient.post(`${this.streamClientBasePath}/start_frame_recording`, data);
        };
        /**
         * Stops frame recording.
         */
        this.stopFrameRecording = async () => {
            return this.streamClient.post(`${this.streamClientBasePath}/stop_frame_recording`);
        };
        /**
         * Updates the call settings or custom data.
         *
         * @param updates the updates to apply to the call.
         */
        this.update = async (updates) => {
            const response = await this.streamClient.patch(`${this.streamClientBasePath}`, updates);
            const { call, members, own_capabilities } = response;
            this.state.updateFromCallResponse(call);
            this.state.setMembers(members);
            this.state.setOwnCapabilities(own_capabilities);
            return response;
        };
        /**
         * Ends the call. Once the call is ended, it cannot be re-joined.
         */
        this.endCall = async () => {
            return this.streamClient.post(`${this.streamClientBasePath}/mark_ended`);
        };
        /**
         * Pins the given session to the top of the participants list.
         *
         * @param sessionId the sessionId to pin.
         */
        this.pin = (sessionId) => {
            this.state.updateParticipant(sessionId, {
                pin: {
                    isLocalPin: true,
                    pinnedAt: Date.now(),
                },
            });
        };
        /**
         * Unpins the given session from the top of the participants list.
         *
         * @param sessionId the sessionId to unpin.
         */
        this.unpin = (sessionId) => {
            this.state.updateParticipant(sessionId, {
                pin: undefined,
            });
        };
        /**
         * Pins the given session to the top of the participants list for everyone
         * in the call.
         * You can execute this method only if you have the `pin-for-everyone` capability.
         *
         * @param request the request object.
         */
        this.pinForEveryone = async (request) => {
            return this.streamClient.post(`${this.streamClientBasePath}/pin`, request);
        };
        /**
         * Unpins the given session from the top of the participants list for everyone
         * in the call.
         * You can execute this method only if you have the `pin-for-everyone` capability.
         *
         * @param request the request object.
         */
        this.unpinForEveryone = async (request) => {
            return this.streamClient.post(`${this.streamClientBasePath}/unpin`, request);
        };
        /**
         * Query call members with filter query. The result won't be stored in call state.
         * @param request
         * @returns
         */
        this.queryMembers = (request) => {
            return this.streamClient.post('/call/members', {
                ...(request || {}),
                id: this.id,
                type: this.type,
            });
        };
        /**
         * Will update the call members.
         *
         * @param data the request data.
         */
        this.updateCallMembers = async (data) => {
            return this.streamClient.post(`${this.streamClientBasePath}/members`, data);
        };
        /**
         * Schedules an auto-drop timeout based on the call settings.
         * Applicable only for ringing calls.
         */
        this.scheduleAutoDrop = () => {
            this.cancelAutoDrop();
            const settings = this.state.settings;
            if (!settings)
                return;
            // ignore if the call is not ringing
            if (this.state.callingState !== exports.CallingState.RINGING)
                return;
            const timeoutInMs = this.isCreatedByMe
                ? settings.ring.auto_cancel_timeout_ms
                : settings.ring.incoming_call_timeout_ms;
            // 0 means no auto-drop
            if (timeoutInMs <= 0)
                return;
            this.dropTimeout = setTimeout(() => {
                // the call might have stopped ringing by this point,
                // e.g. it was already accepted and joined
                if (this.state.callingState !== exports.CallingState.RINGING)
                    return;
                this.leave({ reject: true, reason: 'timeout' }).catch((err) => {
                    this.logger('error', 'Failed to drop call', err);
                });
            }, timeoutInMs);
        };
        /**
         * Cancels a scheduled auto-drop timeout.
         */
        this.cancelAutoDrop = () => {
            clearTimeout(this.dropTimeout);
            this.dropTimeout = undefined;
        };
        /**
         * Retrieves the list of recordings for the current call or call session.
         *
         * If `callSessionId` is provided, it will return the recordings for that call session.
         * Otherwise, all recordings for the current call will be returned.
         *
         * @param callSessionId the call session id to retrieve recordings for.
         */
        this.queryRecordings = async (callSessionId) => {
            let endpoint = this.streamClientBasePath;
            if (callSessionId) {
                endpoint = `${endpoint}/${callSessionId}`;
            }
            return this.streamClient.get(`${endpoint}/recordings`);
        };
        /**
         * Retrieves the list of transcriptions for the current call.
         *
         * @returns the list of transcriptions.
         */
        this.queryTranscriptions = async () => {
            return this.streamClient.get(`${this.streamClientBasePath}/transcriptions`);
        };
        /**
         * Retrieve call statistics for a particular call session (historical).
         * Here `callSessionID` is mandatory.
         *
         * @param callSessionID the call session ID to retrieve statistics for.
         * @returns The call stats.
         * @deprecated use `call.getCallReport` instead.
         * @internal
         */
        this.getCallStats = async (callSessionID) => {
            const endpoint = `${this.streamClientBasePath}/stats/${callSessionID}`;
            return this.streamClient.get(endpoint);
        };
        /**
         * Retrieve call report. If the `callSessionID` is not specified, then the
         * report for the latest call session is retrieved. If it is specified, then
         * the report for that particular session is retrieved if it exists.
         *
         * @param callSessionID the optional call session ID to retrieve statistics for
         * @returns the call report
         */
        this.getCallReport = async (callSessionID = '') => {
            const endpoint = `${this.streamClientBasePath}/report`;
            const params = callSessionID !== '' ? { session_id: callSessionID } : {};
            return this.streamClient.get(endpoint, params);
        };
        /**
         * Submit user feedback for the call
         *
         * @param rating Rating between 1 and 5 denoting the experience of the user in the call
         * @param reason The reason/description for the rating
         * @param custom Custom data
         */
        this.submitFeedback = async (rating, { reason, custom, } = {}) => {
            const { sdkName, sdkVersion, ...platform } = getSdkSignature(await getClientDetails());
            return this.streamClient.post(`${this.streamClientBasePath}/feedback`, {
                rating,
                reason,
                user_session_id: this.sfuClient?.sessionId,
                sdk: sdkName,
                sdk_version: sdkVersion,
                custom: {
                    ...custom,
                    'x-stream-platform-data': platform,
                },
            });
        };
        /**
         * Sends a custom event to all call participants.
         *
         * @param payload the payload to send.
         */
        this.sendCustomEvent = async (payload) => {
            return this.streamClient.post(`${this.streamClientBasePath}/event`, { custom: payload });
        };
        /**
         * Applies the device configuration from the backend.
         *
         * @internal
         */
        this.applyDeviceConfig = async (settings, publish) => {
            await this.camera.apply(settings.video, publish).catch((err) => {
                this.logger('warn', 'Camera init failed', err);
            });
            await this.microphone.apply(settings.audio, publish).catch((err) => {
                this.logger('warn', 'Mic init failed', err);
            });
        };
        /**
         * Will begin tracking the given element for visibility changes within the
         * configured viewport element (`call.setViewport`).
         *
         * @param element the element to track.
         * @param sessionId the session id.
         * @param trackType the video mode.
         */
        this.trackElementVisibility = (element, sessionId, trackType) => {
            return this.dynascaleManager.trackElementVisibility(element, sessionId, trackType);
        };
        /**
         * Sets the viewport element to track bound video elements for visibility.
         *
         * @param element the viewport element.
         */
        this.setViewport = (element) => {
            return this.dynascaleManager.setViewport(element);
        };
        /**
         * Binds a DOM <video> element to the given session id.
         * This method will make sure that the video element will play
         * the correct video stream for the given session id.
         *
         * Under the hood, it would also keep track of the video element dimensions
         * and update the subscription accordingly in order to optimize the bandwidth.
         *
         * If a "viewport" is configured, the video element will be automatically
         * tracked for visibility and the subscription will be updated accordingly.
         *
         * @param videoElement the video element to bind to.
         * @param sessionId the session id.
         * @param trackType the kind of video.
         */
        this.bindVideoElement = (videoElement, sessionId, trackType) => {
            const unbind = this.dynascaleManager.bindVideoElement(videoElement, sessionId, trackType);
            if (!unbind)
                return;
            this.leaveCallHooks.add(unbind);
            return () => {
                this.leaveCallHooks.delete(unbind);
                unbind();
            };
        };
        /**
         * Binds a DOM <audio> element to the given session id.
         *
         * This method will make sure that the audio element will
         * play the correct audio stream for the given session id.
         *
         * @param audioElement the audio element to bind to.
         * @param sessionId the session id.
         * @param trackType the kind of audio.
         */
        this.bindAudioElement = (audioElement, sessionId, trackType = 'audioTrack') => {
            const unbind = this.dynascaleManager.bindAudioElement(audioElement, sessionId, trackType);
            if (!unbind)
                return;
            this.leaveCallHooks.add(unbind);
            return () => {
                this.leaveCallHooks.delete(unbind);
                unbind();
            };
        };
        /**
         * Binds a DOM <img> element to this call's thumbnail (if enabled in settings).
         *
         * @param imageElement the image element to bind to.
         * @param opts options for the binding.
         */
        this.bindCallThumbnailElement = (imageElement, opts = {}) => {
            const handleError = () => {
                imageElement.src =
                    opts.fallbackImageSource ||
                        'https://getstream.io/random_svg/?name=x&id=x';
            };
            const unsubscribe = createSubscription(this.state.thumbnails$, (thumbnails) => {
                if (!thumbnails)
                    return;
                imageElement.addEventListener('error', handleError);
                const thumbnailUrl = new URL(thumbnails.image_url);
                thumbnailUrl.searchParams.set('w', String(imageElement.clientWidth));
                thumbnailUrl.searchParams.set('h', String(imageElement.clientHeight));
                imageElement.src = thumbnailUrl.toString();
            });
            return () => {
                unsubscribe();
                imageElement.removeEventListener('error', handleError);
            };
        };
        /**
         * Specify preference for incoming video resolution. The preference will
         * be matched as close as possible, but actual resolution will depend
         * on the video source quality and client network conditions. Will enable
         * incoming video, if previously disabled.
         *
         * @param resolution preferred resolution, or `undefined` to clear preference
         * @param sessionIds optionally specify session ids of the participants this
         * preference has effect on. Affects all participants by default.
         */
        this.setPreferredIncomingVideoResolution = (resolution, sessionIds) => {
            this.dynascaleManager.setVideoTrackSubscriptionOverrides(resolution
                ? {
                    enabled: true,
                    dimension: resolution,
                }
                : undefined, sessionIds);
            this.dynascaleManager.applyTrackSubscriptions();
        };
        /**
         * Enables or disables incoming video from all remote call participants,
         * and removes any preference for preferred resolution.
         */
        this.setIncomingVideoEnabled = (enabled) => {
            this.dynascaleManager.setVideoTrackSubscriptionOverrides(enabled ? undefined : { enabled: false });
            this.dynascaleManager.applyTrackSubscriptions();
        };
        /**
         * Sets the maximum amount of time a user can remain waiting for a reconnect
         * after a network disruption
         * @param timeoutSeconds Timeout in seconds, or 0 to keep reconnecting indefinetely
         */
        this.setDisconnectionTimeout = (timeoutSeconds) => {
            this.disconnectionTimeoutSeconds = timeoutSeconds;
        };
        this.type = type;
        this.id = id;
        this.cid = `${type}:${id}`;
        this.ringingSubject = new rxjs.BehaviorSubject(ringing);
        this.watching = watching;
        this.streamClient = streamClient;
        this.clientStore = clientStore;
        this.streamClientBasePath = `/call/${this.type}/${this.id}`;
        this.logger = getLogger(['Call']);
        const callTypeConfig = CallTypes.get(type);
        const participantSorter = sortParticipantsBy || callTypeConfig.options.sortParticipantsBy;
        if (participantSorter) {
            this.state.setSortParticipantsBy(participantSorter);
        }
        this.state.setMembers(members || []);
        this.state.setOwnCapabilities(ownCapabilities || []);
        this.state.setCallingState(ringing ? exports.CallingState.RINGING : exports.CallingState.IDLE);
        this.camera = new CameraManager(this);
        this.microphone = new MicrophoneManager(this);
        this.speaker = new SpeakerManager(this);
        this.screenShare = new ScreenShareManager(this);
        this.dynascaleManager = new DynascaleManager(this.state, this.speaker);
    }
    /**
     * A flag indicating whether the call is "ringing" type of call.
     */
    get ringing() {
        return getCurrentValue(this.ringingSubject);
    }
    /**
     * Retrieves the current user ID.
     */
    get currentUserId() {
        return this.clientStore.connectedUser?.id;
    }
    /**
     * A flag indicating whether the call was created by the current user.
     */
    get isCreatedByMe() {
        return this.state.createdBy?.id === this.currentUserId;
    }
}

/**
 * StableWSConnection - A WS connection that reconnects upon failure.
 * - the browser will sometimes report that you're online or offline
 * - the WS connection can break and fail (there is a 30s health check)
 * - sometimes your WS connection will seem to work while the user is in fact offline
 * - to speed up online/offline detection you can use the window.addEventListener('offline');
 *
 * There are 4 ways in which a connection can become unhealthy:
 * - websocket.onerror is called
 * - websocket.onclose is called
 * - the health check fails and no event is received for ~40 seconds
 * - the browser indicates the connection is now offline
 *
 * There are 2 assumptions we make about the server:
 * - state can be recovered by querying the channel again
 * - if the servers fails to publish a message to the client, the WS connection is destroyed
 */
class StableWSConnection {
    constructor(client) {
        this._log = (msg, extra = {}, level = 'info') => {
            this.client.logger(level, `connection:${msg}`, extra);
        };
        this.setClient = (client) => {
            this.client = client;
        };
        /**
         * Builds and returns the url for websocket.
         * @private
         * @returns url string
         */
        this._buildUrl = () => {
            const params = new URLSearchParams();
            params.set('api_key', this.client.key);
            params.set('stream-auth-type', this.client.getAuthType());
            params.set('X-Stream-Client', this.client.getUserAgent());
            return `${this.client.wsBaseURL}/connect?${params.toString()}`;
        };
        /**
         * onlineStatusChanged - this function is called when the browser connects or disconnects from the internet.
         *
         * @param {Event} event Event with type online or offline
         *
         */
        this.onlineStatusChanged = (event) => {
            if (event.type === 'offline') {
                // mark the connection as down
                this._log('onlineStatusChanged() - Status changing to offline');
                // we know that the app is offline so dispatch the unhealthy connection event immediately
                this._setHealth(false, true);
            }
            else if (event.type === 'online') {
                // retry right now...
                // We check this.isHealthy, not sure if it's always
                // smart to create a new WS connection if the old one is still up and running.
                // it's possible we didn't miss any messages, so this process is just expensive and not needed.
                this._log(`onlineStatusChanged() - Status changing to online. isHealthy: ${this.isHealthy}`);
                if (!this.isHealthy) {
                    this._reconnect({ interval: 10 });
                }
            }
        };
        this.onopen = (wsID) => {
            if (this.wsID !== wsID)
                return;
            const user = this.client.user;
            if (!user) {
                this.client.logger('error', `User not set, can't connect to WS`);
                return;
            }
            const token = this.client._getToken();
            if (!token) {
                this.client.logger('error', `Token not set, can't connect authenticate`);
                return;
            }
            const authMessage = JSON.stringify({
                token,
                user_details: {
                    id: user.id,
                    name: user.name,
                    image: user.image,
                    custom: user.custom,
                },
            });
            this._log(`onopen() - Sending auth message ${authMessage}`, {}, 'trace');
            this.ws?.send(authMessage);
            this._log('onopen() - onopen callback', { wsID });
        };
        this.onmessage = (wsID, event) => {
            if (this.wsID !== wsID)
                return;
            this._log('onmessage() - onmessage callback', { event, wsID });
            const data = typeof event.data === 'string'
                ? JSON.parse(event.data)
                : null;
            // we wait till the first message before we consider the connection open.
            // the reason for this is that auth errors and similar errors trigger a ws.onopen and immediately
            // after that a ws.onclose.
            if (!this.isConnectionOpenResolved &&
                data &&
                data.type === 'connection.error') {
                this.isConnectionOpenResolved = true;
                if (data.error) {
                    this.rejectConnectionOpen?.(this._errorFromWSEvent(data, false));
                    return;
                }
            }
            // trigger the event..
            this.lastEvent = new Date();
            if (data &&
                (data.type === 'health.check' || data.type === 'connection.ok')) {
                // the initial health-check should come from the client
                this.scheduleNextPing();
            }
            if (data && data.type === 'connection.ok') {
                this.resolveConnectionOpen?.(data);
                this._setHealth(true);
            }
            if (data && data.type === 'connection.error' && data.error) {
                const { code } = data.error;
                this.isHealthy = false;
                this.isConnecting = false;
                this.consecutiveFailures += 1;
                if (code === KnownCodes.TOKEN_EXPIRED &&
                    !this.client.tokenManager.isStatic()) {
                    clearTimeout(this.connectionCheckTimeoutRef);
                    this._log('connect() - WS failure due to expired token, so going to try to reload token and reconnect');
                    this._reconnect({ refreshToken: true });
                }
            }
            if (data) {
                data.received_at = new Date();
                this.client.dispatchEvent(data);
            }
            this.scheduleConnectionCheck();
        };
        this.onclose = (wsID, event) => {
            if (this.wsID !== wsID)
                return;
            this._log('onclose() - onclose callback - ' + event.code, { event, wsID });
            if (event.code === KnownCodes.WS_CLOSED_SUCCESS) {
                // this is a permanent error raised by stream..
                // usually caused by invalid auth details
                const error = new Error(`WS connection reject with error ${event.reason}`);
                // @ts-expect-error type issue
                error.reason = event.reason;
                // @ts-expect-error type issue
                error.code = event.code;
                // @ts-expect-error type issue
                error.wasClean = event.wasClean;
                // @ts-expect-error type issue
                error.target = event.target;
                this.rejectConnectionOpen?.(error);
                this._log(`onclose() - WS connection reject with error ${event.reason}`, {
                    event,
                });
            }
            else {
                this.consecutiveFailures += 1;
                this.totalFailures += 1;
                this._setHealth(false);
                this.isConnecting = false;
                this.rejectConnectionOpen?.(this._errorFromWSEvent(event));
                this._log(`onclose() - WS connection closed. Calling reconnect ...`, {
                    event,
                });
                // reconnect if its an abnormal failure
                this._reconnect();
            }
        };
        this.onerror = (wsID, event) => {
            if (this.wsID !== wsID)
                return;
            this.consecutiveFailures += 1;
            this.totalFailures += 1;
            this._setHealth(false);
            this.isConnecting = false;
            this.rejectConnectionOpen?.(new Error(`WebSocket error: ${event}`));
            this._log(`onerror() - WS connection resulted into error`, { event });
            this._reconnect();
        };
        /**
         * _setHealth - Sets the connection to healthy or unhealthy.
         * Broadcasts an event in case the connection status changed.
         *
         * @param {boolean} healthy boolean indicating if the connection is healthy or not
         * @param {boolean} dispatchImmediately boolean indicating to dispatch event immediately even if the connection is unhealthy
         */
        this._setHealth = (healthy, dispatchImmediately = false) => {
            if (healthy === this.isHealthy)
                return;
            this.isHealthy = healthy;
            if (this.isHealthy || dispatchImmediately) {
                this.client.dispatchEvent({
                    type: 'connection.changed',
                    online: this.isHealthy,
                });
                return;
            }
            // we're offline, wait few seconds and fire and event if still offline
            setTimeout(() => {
                if (this.isHealthy)
                    return;
                this.client.dispatchEvent({
                    type: 'connection.changed',
                    online: this.isHealthy,
                });
            }, 5000);
        };
        /**
         * _errorFromWSEvent - Creates an error object for the WS event
         */
        this._errorFromWSEvent = (event, isWSFailure = true) => {
            let code;
            let statusCode;
            let message;
            if (isCloseEvent(event)) {
                code = event.code;
                message = event.reason;
                statusCode = 0;
            }
            else {
                const { error } = event;
                code = error.code;
                message = error.message;
                statusCode = error.StatusCode;
            }
            const msg = `WS failed with code: ${code} and reason: ${message}`;
            this._log(msg, { event }, 'warn');
            const error = new Error(msg);
            error.code = code;
            /**
             * StatusCode does not exist on any event types but has been left
             * as is to preserve JS functionality during the TS implementation
             */
            error.StatusCode = statusCode;
            error.isWSFailure = isWSFailure;
            return error;
        };
        /**
         * _setupPromise - sets up the this.connectOpen promise
         */
        this._setupConnectionPromise = () => {
            this.isConnectionOpenResolved = false;
            /** a promise that is resolved once ws.open is called */
            this.connectionOpenSafe = makeSafePromise(new Promise((resolve, reject) => {
                this.resolveConnectionOpen = resolve;
                this.rejectConnectionOpen = reject;
            }));
        };
        /**
         * Schedules a next health check ping for websocket.
         */
        this.scheduleNextPing = () => {
            const timers = getTimers();
            if (this.healthCheckTimeoutRef) {
                timers.clearTimeout(this.healthCheckTimeoutRef);
            }
            // 30 seconds is the recommended interval (messenger uses this)
            this.healthCheckTimeoutRef = timers.setTimeout(() => {
                // send the healthcheck..., server replies with a health check event
                const data = [{ type: 'health.check', client_id: this.client.clientID }];
                // try to send on the connection
                try {
                    this.ws?.send(JSON.stringify(data));
                }
                catch {
                    // error will already be detected elsewhere
                }
            }, this.pingInterval);
        };
        /**
         * scheduleConnectionCheck - schedules a check for time difference between last received event and now.
         * If the difference is more than 35 seconds, it means our health check logic has failed and websocket needs
         * to be reconnected.
         */
        this.scheduleConnectionCheck = () => {
            clearTimeout(this.connectionCheckTimeoutRef);
            this.connectionCheckTimeoutRef = setTimeout(() => {
                const now = new Date();
                if (this.lastEvent &&
                    now.getTime() - this.lastEvent.getTime() > this.connectionCheckTimeout) {
                    this._log('scheduleConnectionCheck - going to reconnect');
                    this._setHealth(false);
                    this._reconnect();
                }
            }, this.connectionCheckTimeout);
        };
        this.client = client;
        /** consecutive failures influence the duration of the timeout */
        this.consecutiveFailures = 0;
        /** keep track of the total number of failures */
        this.totalFailures = 0;
        /** We only make 1 attempt to reconnect at the same time.. */
        this.isConnecting = false;
        /** To avoid reconnect if client is disconnected */
        this.isDisconnected = false;
        /** Boolean that indicates if the connection promise is resolved */
        this.isConnectionOpenResolved = false;
        /** Boolean that indicates if we have a working connection to the server */
        this.isHealthy = false;
        /** Incremented when a new WS connection is made */
        this.wsID = 1;
        /** Store the last event time for health checks */
        this.lastEvent = null;
        /** Send a health check message every 25 seconds */
        this.pingInterval = 25 * 1000;
        this.connectionCheckTimeout = this.pingInterval + 10 * 1000;
        addConnectionEventListeners(this.onlineStatusChanged);
    }
    /**
     * connect - Connect to the WS URL
     * the default 15s timeout allows between 2~3 tries
     * @return {ConnectAPIResponse<ConnectedEvent>} Promise that completes once the first health check message is received
     */
    async connect(timeout = 15000) {
        if (this.isConnecting) {
            throw Error(`You've called connect twice, can only attempt 1 connection at the time`);
        }
        this.isDisconnected = false;
        try {
            const healthCheck = await this._connect();
            this.consecutiveFailures = 0;
            this._log(`connect() - Established ws connection with healthcheck: ${healthCheck}`);
        }
        catch (error) {
            this.isHealthy = false;
            this.consecutiveFailures += 1;
            if (
            // @ts-expect-error type issue
            error.code === KnownCodes.TOKEN_EXPIRED &&
                !this.client.tokenManager.isStatic()) {
                this._log('connect() - WS failure due to expired token, so going to try to reload token and reconnect');
                this._reconnect({ refreshToken: true });
            }
            else {
                // @ts-expect-error type issue
                if (!error.isWSFailure) {
                    // API rejected the connection and we should not retry
                    throw new Error(JSON.stringify({
                        // @ts-expect-error type issue
                        code: error.code,
                        // @ts-expect-error type issue
                        StatusCode: error.StatusCode,
                        // @ts-expect-error type issue
                        message: error.message,
                        // @ts-expect-error type issue
                        isWSFailure: error.isWSFailure,
                    }));
                }
            }
        }
        return await this._waitForHealthy(timeout);
    }
    /**
     * _waitForHealthy polls the promise connection to see if its resolved until it times out
     * the default 15s timeout allows between 2~3 tries
     * @param timeout duration(ms)
     */
    async _waitForHealthy(timeout = 15000) {
        return Promise.race([
            (async () => {
                const interval = 50; // ms
                for (let i = 0; i <= timeout; i += interval) {
                    try {
                        return await this.connectionOpen;
                    }
                    catch (error) {
                        if (i === timeout) {
                            throw new Error(JSON.stringify({
                                code: error.code,
                                StatusCode: error.StatusCode,
                                message: error.message,
                                isWSFailure: error.isWSFailure,
                            }));
                        }
                        await sleep(interval);
                    }
                }
            })(),
            (async () => {
                await sleep(timeout);
                this.isConnecting = false;
                throw new Error(JSON.stringify({
                    code: '',
                    StatusCode: '',
                    message: 'initial WS connection could not be established',
                    isWSFailure: true,
                }));
            })(),
        ]);
    }
    /**
     * disconnect - Disconnect the connection and doesn't recover...
     *
     */
    disconnect(timeout) {
        this._log(`disconnect() - Closing the websocket connection for wsID ${this.wsID}`);
        this.wsID += 1;
        this.isConnecting = false;
        this.isDisconnected = true;
        // start by removing all the listeners
        if (this.healthCheckTimeoutRef) {
            getTimers().clearInterval(this.healthCheckTimeoutRef);
        }
        if (this.connectionCheckTimeoutRef) {
            clearInterval(this.connectionCheckTimeoutRef);
        }
        removeConnectionEventListeners(this.onlineStatusChanged);
        this.isHealthy = false;
        let isClosedPromise;
        // and finally close...
        // Assigning to local here because we will remove it from this before the
        // promise resolves.
        const { ws } = this;
        if (ws && ws.close && ws.readyState === ws.OPEN) {
            isClosedPromise = new Promise((resolve) => {
                const onclose = (event) => {
                    this._log(`disconnect() - resolving isClosedPromise ${event ? 'with' : 'without'} close frame`, { event });
                    resolve();
                };
                ws.onclose = onclose;
                // In case we don't receive close frame websocket server in time,
                // lets not wait for more than 1 second.
                setTimeout(onclose, timeout != null ? timeout : 1000);
            });
            this._log(`disconnect() - Manually closed connection by calling client.disconnect()`);
            ws.close(KnownCodes.WS_CLOSED_SUCCESS, 'Manually closed connection by calling client.disconnect()');
        }
        else {
            this._log(`disconnect() - ws connection doesn't exist or it is already closed.`);
            isClosedPromise = Promise.resolve();
        }
        delete this.ws;
        return isClosedPromise;
    }
    /**
     * _connect - Connect to the WS endpoint
     *
     * @return {ConnectAPIResponse<ConnectedEvent>} Promise that completes once the first health check message is received
     */
    async _connect() {
        if (this.isConnecting)
            return; // ignore _connect if it's currently trying to connect
        this.isConnecting = true;
        let isTokenReady = false;
        try {
            this._log(`_connect() - waiting for token`);
            await this.client.tokenManager.tokenReady();
            isTokenReady = true;
        }
        catch {
            // token provider has failed before, so try again
        }
        try {
            if (!isTokenReady) {
                this._log(`_connect() - tokenProvider failed before, so going to retry`);
                await this.client.tokenManager.loadToken();
            }
            if (!this.client.isConnectionIsPromisePending) {
                this.client._setupConnectionIdPromise();
            }
            this._setupConnectionPromise();
            const wsURL = this._buildUrl();
            this._log(`_connect() - Connecting to ${wsURL}`);
            const WS = this.client.options.WebSocketImpl ?? WebSocket;
            this.ws = new WS(wsURL);
            this.ws.onopen = this.onopen.bind(this, this.wsID);
            this.ws.onclose = this.onclose.bind(this, this.wsID);
            this.ws.onerror = this.onerror.bind(this, this.wsID);
            this.ws.onmessage = this.onmessage.bind(this, this.wsID);
            const response = await this.connectionOpen;
            this.isConnecting = false;
            if (response) {
                this.connectionID = response.connection_id;
                this.client.resolveConnectionId?.(this.connectionID);
                return response;
            }
        }
        catch (err) {
            this.client._setupConnectionIdPromise();
            this.isConnecting = false;
            // @ts-expect-error type issue
            this._log(`_connect() - Error - `, err);
            this.client.rejectConnectionId?.(err);
            throw err;
        }
    }
    /**
     * _reconnect - Retry the connection to WS endpoint
     *
     * @param {{ interval?: number; refreshToken?: boolean }} options Following options are available
     *
     * - `interval`	{int}			number of ms that function should wait before reconnecting
     * - `refreshToken` {boolean}	reload/refresh user token be refreshed before attempting reconnection.
     */
    async _reconnect(options = {}) {
        this._log('_reconnect() - Initiating the reconnect');
        // only allow 1 connection at the time
        if (this.isConnecting || this.isHealthy) {
            this._log('_reconnect() - Abort (1) since already connecting or healthy');
            return;
        }
        // reconnect in case of on error or on close
        // also reconnect if the health check cycle fails
        let interval = options.interval;
        if (!interval) {
            interval = retryInterval(this.consecutiveFailures);
        }
        // reconnect, or try again after a little while...
        await sleep(interval);
        // Check once again if by some other call to _reconnect is active or connection is
        // already restored, then no need to proceed.
        if (this.isConnecting || this.isHealthy) {
            this._log('_reconnect() - Abort (2) since already connecting or healthy');
            return;
        }
        if (this.isDisconnected) {
            this._log('_reconnect() - Abort (3) since disconnect() is called');
            return;
        }
        this._log('_reconnect() - Destroying current WS connection');
        // cleanup the old connection
        this._destroyCurrentWSConnection();
        if (options.refreshToken) {
            await this.client.tokenManager.loadToken();
        }
        try {
            await this._connect();
            this._log('_reconnect() - Waiting for recoverCallBack');
            // await this.client.recoverState();
            this._log('_reconnect() - Finished recoverCallBack');
            this.consecutiveFailures = 0;
        }
        catch (error) {
            this.isHealthy = false;
            this.consecutiveFailures += 1;
            if (error.code === KnownCodes.TOKEN_EXPIRED &&
                !this.client.tokenManager.isStatic()) {
                this._log('_reconnect() - WS failure due to expired token, so going to try to reload token and reconnect');
                return this._reconnect({ refreshToken: true });
            }
            // reconnect on WS failures, don't reconnect if there is a code bug
            if (error.isWSFailure) {
                this._log('_reconnect() - WS failure, so going to try to reconnect');
                this._reconnect();
            }
        }
        this._log('_reconnect() - == END ==');
    }
    /**
     * _destroyCurrentWSConnection - Removes the current WS connection
     *
     */
    _destroyCurrentWSConnection() {
        // increment the ID, meaning we will ignore all messages from the old
        // ws connection from now on.
        this.wsID += 1;
        try {
            this?.ws?.close();
        }
        catch {
            // we don't care
        }
    }
    get connectionOpen() {
        return this.connectionOpenSafe?.();
    }
}

function getUserFromToken(token) {
    const fragments = token.split('.');
    if (fragments.length !== 3) {
        return '';
    }
    const b64Payload = fragments[1];
    const payload = decodeBase64(b64Payload);
    const data = JSON.parse(payload);
    return data.user_id;
}
// base-64 decoder throws exception if encoded string is not padded by '=' to make string length
// in multiples of 4. So gonna use our own method for this purpose to keep backwards compatibility
// https://github.com/beatgammit/base64-js/blob/master/index.js#L26
const decodeBase64 = (s) => {
    const e = {}, w = String.fromCharCode, L = s.length;
    let i, b = 0, c, x, l = 0, a, r = '';
    const A = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/';
    for (i = 0; i < 64; i++) {
        e[A.charAt(i)] = i;
    }
    for (x = 0; x < L; x++) {
        c = e[s.charAt(x)];
        b = (b << 6) + c;
        l += 6;
        while (l >= 8) {
            if ((a = (b >>> (l -= 8)) & 0xff) || x < L - 2)
                r += w(a);
        }
    }
    return r;
};

/**
 * TokenManager
 *
 * Handles all the operations around user token.
 */
class TokenManager {
    constructor(secret) {
        this.loadTokenPromise = null;
        this.type = 'static';
        /**
         * Set the static string token or token provider.
         * Token provider should return a token string or a promise which resolves to string token.
         *
         * @param {TokenOrProvider} tokenOrProvider - the token or token provider.
         * @param {UserResponse} user - the user object.
         * @param {boolean} isAnonymous - whether the user is anonymous or not.
         */
        this.setTokenOrProvider = async (tokenOrProvider, user, isAnonymous) => {
            this.user = user;
            this.isAnonymous = isAnonymous;
            this.validateToken(tokenOrProvider);
            if (isFunction(tokenOrProvider)) {
                this.tokenProvider = tokenOrProvider;
                this.type = 'provider';
            }
            if (typeof tokenOrProvider === 'string') {
                this.token = tokenOrProvider;
                this.type = 'static';
            }
            await this.loadToken();
        };
        /**
         * Resets the token manager.
         * Useful for client disconnection or switching user.
         */
        this.reset = () => {
            this.token = undefined;
            this.tokenProvider = undefined;
            this.type = 'static';
            this.user = undefined;
            this.loadTokenPromise = null;
        };
        // Validates the user token.
        this.validateToken = (tokenOrProvider) => {
            // allow empty token for anon user
            if (this.user && this.isAnonymous && !tokenOrProvider)
                return;
            // Don't allow empty token for non-server side client.
            if (!this.secret && !tokenOrProvider) {
                throw new Error('User token can not be empty');
            }
            if (typeof tokenOrProvider !== 'string' && !isFunction(tokenOrProvider)) {
                throw new Error('User token should either be a string or a function');
            }
            if (typeof tokenOrProvider === 'string') {
                // Allow empty token for anonymous users
                if (this.isAnonymous && tokenOrProvider === '')
                    return;
                const tokenUserId = getUserFromToken(tokenOrProvider);
                if (tokenOrProvider != null &&
                    (tokenUserId == null ||
                        tokenUserId === '' ||
                        (!this.isAnonymous && tokenUserId !== this.user.id))) {
                    throw new Error('userToken does not have a user_id or is not matching with user.id');
                }
            }
        };
        // Resolves when token is ready. This function is simply to check if loadToken is in progress, in which
        // case a function should wait.
        this.tokenReady = () => this.loadTokenPromise;
        // Fetches a token from tokenProvider function and sets in tokenManager.
        // In case of static token, it will simply resolve to static token.
        this.loadToken = () => {
            this.loadTokenPromise = new Promise(async (resolve, reject) => {
                if (this.type === 'static') {
                    return resolve(this.token);
                }
                if (this.tokenProvider && typeof this.tokenProvider !== 'string') {
                    try {
                        const token = await this.tokenProvider();
                        this.validateToken(token);
                        this.token = token;
                    }
                    catch (e) {
                        return reject(new Error(`Call to tokenProvider failed with message: ${e}`));
                    }
                    resolve(this.token);
                }
            });
            return this.loadTokenPromise;
        };
        // Returns a current token
        this.getToken = () => {
            if (this.token) {
                return this.token;
            }
            if (this.user && !this.token) {
                return this.token;
            }
            throw new Error(`User token is not set. Either client.connectUser wasn't called or client.disconnect was called`);
        };
        this.isStatic = () => this.type === 'static';
        this.secret = secret;
    }
}

const getLocationHint = async (hintUrl = `https://hint.stream-io-video.com/`, timeout = 2000, maxAttempts = 3) => {
    const logger = getLogger(['location-hint']);
    let attempt = 0;
    let locationHint = 'ERR';
    do {
        const abortController = new AbortController();
        const timeoutId = setTimeout(() => abortController.abort(), timeout);
        try {
            const response = await fetch(hintUrl, {
                method: 'HEAD',
                signal: abortController.signal,
            });
            const awsPop = response.headers.get('x-amz-cf-pop') || 'ERR';
            logger('debug', `Location header: ${awsPop}`);
            locationHint = awsPop.substring(0, 3); // AMS1-P2 -> AMS
        }
        catch (e) {
            logger('warn', `Failed to get location hint from ${hintUrl}`, e);
            locationHint = 'ERR';
        }
        finally {
            clearTimeout(timeoutId);
        }
    } while (locationHint === 'ERR' && ++attempt < maxAttempts);
    return locationHint;
};

class StreamClient {
    /**
     * Initialize a client.
     *
     * @param {string} key - the api key
     * @param {StreamClientOptions} [options] - additional options, here you can pass custom options to axios instance
     * @param {string} [options.secret] - the api secret
     * @param {boolean} [options.browser] - enforce the client to be in browser mode
     * @param {boolean} [options.warmUp] - default to false, if true, client will open a connection as soon as possible to speed up following requests
     * @param {Logger} [options.Logger] - custom logger
     * @param {number} [options.timeout] - default to 3000
     * @param {httpsAgent} [options.httpsAgent] - custom httpsAgent, in node it's default to https.agent()
     */
    constructor(key, options) {
        this.listeners = {};
        this.getAuthType = () => {
            return this.anonymous ? 'anonymous' : 'jwt';
        };
        this.setBaseURL = (baseURL) => {
            this.baseURL = baseURL;
            this.wsBaseURL = this.baseURL
                .replace('http', 'ws')
                .replace(':3030', ':8800');
        };
        this.getLocationHint = async (hintUrl, timeout) => {
            const hint = await this.locationHint;
            if (!hint || hint === 'ERR') {
                this.locationHint = getLocationHint(hintUrl ?? this.options.locationHintUrl, timeout ?? this.options.locationHintTimeout);
                return this.locationHint;
            }
            return hint;
        };
        this._getConnectionID = () => this.wsConnection?.connectionID;
        this._hasConnectionID = () => Boolean(this._getConnectionID());
        /**
         * connectUser - Set the current user and open a WebSocket connection
         *
         * @param user Data about this user. IE {name: "john"}
         * @param {TokenOrProvider} tokenOrProvider Token or provider
         *
         * @return {ConnectAPIResponse} Returns a promise that resolves when the connection is setup
         */
        this.connectUser = async (user, tokenOrProvider) => {
            if (!user.id) {
                throw new Error('The "id" field on the user is missing');
            }
            /**
             * Calling connectUser multiple times is potentially the result of a  bad integration, however,
             * If the user id remains the same we don't throw error
             */
            if (this.userID === user.id && this.connectUserTask) {
                this.logger('warn', 'Consecutive calls to connectUser is detected, ideally you should only call this function once in your app.');
                return this.connectUserTask;
            }
            if (this.userID) {
                throw new Error('Use client.disconnect() before trying to connect as a different user. connectUser was called twice.');
            }
            if ((this.secret || this.node) && !this.options.allowServerSideConnect) {
                this.logger('warn', 'Please do not use connectUser server side. Use our @stream-io/node-sdk instead: https://getstream.io/video/docs/api/');
            }
            // we generate the client id client side
            this.userID = user.id;
            this.anonymous = false;
            await this.tokenManager.setTokenOrProvider(tokenOrProvider, user, false);
            this._setUser(user);
            this.connectUserTask = this.openConnection();
            try {
                addConnectionEventListeners(this.updateNetworkConnectionStatus);
                return await this.connectUserTask;
            }
            catch (err) {
                if (this.persistUserOnConnectionFailure) {
                    // cleanup client to allow the user to retry connectUser again
                    await this.closeConnection();
                }
                else {
                    await this.disconnectUser();
                }
                throw err;
            }
        };
        this._setUser = (user) => {
            /**
             * This one is used by the frontend. This is a copy of the current user object stored on backend.
             * It contains reserved properties and own user properties which are not present in `this._user`.
             */
            this.user = user;
            this.userID = user.id;
            // this one is actually used for requests. This is a copy of current user provided to `connectUser` function.
            this._user = { ...user };
        };
        /**
         * Disconnects the websocket connection, without removing the user set on client.
         * client.closeConnection will not trigger default auto-retry mechanism for reconnection. You need
         * to call client.openConnection to reconnect to websocket.
         *
         * This is mainly useful on mobile side. You can only receive push notifications
         * if you don't have active websocket connection.
         * So when your app goes to background, you can call `client.closeConnection`.
         * And when app comes back to foreground, call `client.openConnection`.
         *
         * @param timeout Max number of ms, to wait for close event of websocket, before forcefully assuming succesful disconnection.
         *                https://developer.mozilla.org/en-US/docs/Web/API/CloseEvent
         */
        this.closeConnection = async (timeout) => {
            await this.wsConnection?.disconnect(timeout);
        };
        /**
         * Creates a new WebSocket connection with the current user. Returns empty promise, if there is an active connection
         */
        this.openConnection = async () => {
            if (!this.userID) {
                throw Error('UserWithId is not set on client, use client.connectUser or client.connectAnonymousUser instead');
            }
            const wsPromise = this.wsPromiseSafe?.();
            if (this.wsConnection?.isConnecting && wsPromise) {
                this.logger('info', 'client:openConnection() - connection already in progress');
                return await wsPromise;
            }
            if (this.wsConnection?.isHealthy && this._hasConnectionID()) {
                this.logger('info', 'client:openConnection() - openConnection called twice, healthy connection already exists');
                return;
            }
            this._setupConnectionIdPromise();
            this.clientID = `${this.userID}--${generateUUIDv4()}`;
            const newWsPromise = this.connect();
            this.wsPromiseSafe = makeSafePromise(newWsPromise);
            return await newWsPromise;
        };
        /**
         * Disconnects the websocket and removes the user from client.
         *
         * @param timeout Max number of ms, to wait for close event of websocket, before forcefully assuming successful disconnection.
         *                https://developer.mozilla.org/en-US/docs/Web/API/CloseEvent
         */
        this.disconnectUser = async (timeout) => {
            this.logger('info', 'client:disconnect() - Disconnecting the client');
            // remove the user specific fields
            delete this.user;
            delete this._user;
            delete this.userID;
            this.anonymous = false;
            await this.closeConnection(timeout);
            removeConnectionEventListeners(this.updateNetworkConnectionStatus);
            this.tokenManager.reset();
            this.connectionIdPromiseSafe = undefined;
            this.rejectConnectionId = undefined;
            this.resolveConnectionId = undefined;
        };
        this.connectGuestUser = async (user) => {
            this.guestUserCreatePromise = this.doAxiosRequest('post', '/guest', { user }, { publicEndpoint: true });
            const response = await this.guestUserCreatePromise;
            this.guestUserCreatePromise.finally(() => (this.guestUserCreatePromise = undefined));
            return this.connectUser(response.user, response.access_token);
        };
        /**
         * connectAnonymousUser - Set an anonymous user and open a WebSocket connection
         */
        this.connectAnonymousUser = async (user, tokenOrProvider) => {
            addConnectionEventListeners(this.updateNetworkConnectionStatus);
            this._setupConnectionIdPromise();
            this.anonymous = true;
            await this.tokenManager.setTokenOrProvider(tokenOrProvider, user, true);
            this._setUser(user);
            // some endpoints require a connection_id to be resolved.
            // as anonymous users aren't allowed to open WS connections, we just
            // resolve the connection_id here.
            this.resolveConnectionId?.();
        };
        /**
         * on - Listen to events on all channels and users your watching
         *
         * client.on('message.new', event => {console.log("my new message", event, channel.state.messages)})
         *
         * @param eventName The event type to listen for (optional)
         * @param callback The callback to call
         *
         * @return  Returns a function which, when called, unsubscribes the event handler.
         */
        this.on = (eventName, callback) => {
            if (!this.listeners[eventName]) {
                this.listeners[eventName] = [];
            }
            this.logger('debug', `Adding listener for ${eventName} event`);
            this.listeners[eventName]?.push(callback);
            return () => {
                this.off(eventName, callback);
            };
        };
        /**
         * off - Remove the event handler
         */
        this.off = (eventName, callback) => {
            if (!this.listeners[eventName]) {
                this.listeners[eventName] = [];
            }
            this.logger('debug', `Removing listener for ${eventName} event`);
            this.listeners[eventName] = this.listeners[eventName]?.filter((value) => value !== callback);
        };
        /**
         * sets up the this.connectionIdPromise
         */
        this._setupConnectionIdPromise = () => {
            /** a promise that is resolved once connection id is set */
            this.connectionIdPromiseSafe = makeSafePromise(new Promise((resolve, reject) => {
                this.resolveConnectionId = resolve;
                this.rejectConnectionId = reject;
            }));
        };
        this._logApiRequest = (type, url, data, config) => {
            if (getLogLevel() !== 'trace')
                return;
            this.logger('trace', `client: ${type} - Request - ${url}`, {
                payload: data,
                config,
            });
        };
        this._logApiResponse = (type, url, response) => {
            if (getLogLevel() !== 'trace')
                return;
            this.logger('trace', `client:${type} - Response - url: ${url} > status ${response.status}`, {
                response,
            });
        };
        this._logApiError = (type, url, error) => {
            this.logger('error', `client:${type} - Error - url: ${url}`, {
                url,
                error,
            });
        };
        this.doAxiosRequest = async (type, url, data, options = {}) => {
            if (!options.publicEndpoint) {
                await Promise.all([
                    this.tokenManager.tokenReady(),
                    this.guestUserCreatePromise,
                ]);
                // we need to wait for presence of connection id before making requests
                try {
                    await this.connectionIdPromise;
                }
                catch {
                    // in case connection id was rejected
                    // reconnection maybe in progress
                    // we can wait for healthy connection to resolve, which rejects when 15s timeout is reached
                    await this.wsConnection?._waitForHealthy();
                    await this.connectionIdPromise;
                }
            }
            const requestConfig = this._enrichAxiosOptions(options);
            try {
                let response;
                this._logApiRequest(type, url, data, requestConfig);
                switch (type) {
                    case 'get':
                        response = await this.axiosInstance.get(url, requestConfig);
                        break;
                    case 'delete':
                        response = await this.axiosInstance.delete(url, requestConfig);
                        break;
                    case 'post':
                        response = await this.axiosInstance.post(url, data, requestConfig);
                        break;
                    case 'put':
                        response = await this.axiosInstance.put(url, data, requestConfig);
                        break;
                    case 'patch':
                        response = await this.axiosInstance.patch(url, data, requestConfig);
                        break;
                    case 'options':
                        response = await this.axiosInstance.options(url, requestConfig);
                        break;
                    default:
                        throw new Error('Invalid request type');
                }
                this._logApiResponse(type, url, response);
                this.consecutiveFailures = 0;
                return this.handleResponse(response);
            }
            catch (e /**TODO: generalize error types  */) {
                e.client_request_id = requestConfig.headers?.['x-client-request-id'];
                this.consecutiveFailures += 1;
                if (e.response) {
                    this._logApiError(type, url, e.response);
                    /** connection_fallback depends on this token expiration logic */
                    if (e.response.data.code === KnownCodes.TOKEN_EXPIRED &&
                        !this.tokenManager.isStatic()) {
                        if (this.consecutiveFailures > 1) {
                            await sleep(retryInterval(this.consecutiveFailures));
                        }
                        await this.tokenManager.loadToken();
                        return await this.doAxiosRequest(type, url, data, options);
                    }
                    return this.handleResponse(e.response);
                }
                else {
                    this._logApiError(type, url, e);
                    throw e;
                }
            }
        };
        this.get = (url, params) => {
            return this.doAxiosRequest('get', url, null, {
                params,
            });
        };
        this.put = (url, data, params) => {
            return this.doAxiosRequest('put', url, data, { params });
        };
        this.post = (url, data, params) => {
            return this.doAxiosRequest('post', url, data, { params });
        };
        this.patch = (url, data, params) => {
            return this.doAxiosRequest('patch', url, data, { params });
        };
        this.delete = (url, params) => {
            return this.doAxiosRequest('delete', url, null, {
                params,
            });
        };
        this.errorFromResponse = (response) => {
            const { data, status } = response;
            const err = new ErrorFromResponse();
            err.message = `Stream error code ${data.code}: ${data.message}`;
            err.code = data.code;
            err.unrecoverable = data.unrecoverable;
            err.response = response;
            err.status = status;
            return err;
        };
        this.handleResponse = (response) => {
            const data = response.data;
            if (isErrorResponse(response)) {
                throw this.errorFromResponse(response);
            }
            return data;
        };
        this.dispatchEvent = (event) => {
            this.logger('debug', `Dispatching event: ${event.type}`, event);
            if (!this.listeners)
                return;
            // call generic listeners
            for (const listener of this.listeners.all || []) {
                listener(event);
            }
            // call type specific listeners
            for (const listener of this.listeners[event.type] || []) {
                listener(event);
            }
        };
        /**
         * @private
         */
        this.connect = async () => {
            if (!this.userID || !this._user) {
                throw Error('Call connectUser or connectAnonymousUser before starting the connection');
            }
            if (!this.wsBaseURL)
                throw Error('Websocket base url not set');
            if (!this.clientID)
                throw Error('clientID is not set');
            // The StableWSConnection handles all the reconnection logic.
            this.wsConnection = new StableWSConnection(this);
            this.logger('info', 'StreamClient.connect: this.wsConnection.connect()');
            return await this.wsConnection.connect(this.defaultWSTimeout);
        };
        this.getUserAgent = () => {
            if (!this.cachedUserAgent) {
                const { clientAppIdentifier = {} } = this.options;
                const { sdkName = 'js', sdkVersion = "1.20.0", ...extras } = clientAppIdentifier;
                this.cachedUserAgent = [
                    `stream-video-${sdkName}-v${sdkVersion}`,
                    ...Object.entries(extras).map(([key, value]) => `${key}=${value}`),
                    `client_bundle=${"node-cjs"}`,
                ].join('|');
            }
            return this.cachedUserAgent;
        };
        this._enrichAxiosOptions = (options = {
            params: {},
            headers: {},
            config: {},
        }) => {
            const token = options.publicEndpoint && !this.user ? undefined : this._getToken();
            const authorization = token ? { Authorization: token } : undefined;
            if (!options.headers?.['x-client-request-id']) {
                options.headers = {
                    ...options.headers,
                    'x-client-request-id': generateUUIDv4(),
                };
            }
            return {
                params: {
                    user_id: this.userID,
                    connection_id: this._getConnectionID(),
                    api_key: this.key,
                    ...options.params,
                },
                headers: {
                    ...authorization,
                    'stream-auth-type': options.publicEndpoint && !this.user
                        ? 'anonymous'
                        : this.getAuthType(),
                    'X-Stream-Client': this.getUserAgent(),
                    ...options.headers,
                },
                ...options.config,
                ...this.options.axiosRequestConfig,
            };
        };
        this._getToken = () => {
            if (!this.tokenManager)
                return null;
            return this.tokenManager.getToken();
        };
        this.updateNetworkConnectionStatus = (event) => {
            if (event.type === 'offline') {
                this.logger('debug', 'device went offline');
                this.dispatchEvent({ type: 'network.changed', online: false });
            }
            else if (event.type === 'online') {
                this.logger('debug', 'device went online');
                this.dispatchEvent({ type: 'network.changed', online: true });
            }
        };
        // set the key
        this.key = key;
        // set the secret
        this.secret = options?.secret;
        // set the options... and figure out defaults...
        const inputOptions = options
            ? options
            : {
                browser: typeof window !== 'undefined',
            };
        this.browser = inputOptions.browser || typeof window !== 'undefined';
        this.node = !this.browser;
        if (this.browser) {
            this.locationHint = getLocationHint(options?.locationHintUrl, options?.locationHintTimeout, options?.locationHintMaxAttempts);
        }
        this.options = {
            timeout: 5000,
            withCredentials: false, // making sure cookies are not sent
            ...inputOptions,
        };
        if (this.node && !this.options.httpsAgent) {
            this.options.httpsAgent = new https.Agent({
                keepAlive: true,
                keepAliveMsecs: 3000,
            });
        }
        this.setBaseURL(this.options.baseURL || 'https://video.stream-io-api.com/video');
        this.axiosInstance = axios.create({
            ...this.options,
            baseURL: this.baseURL,
        });
        // WS connection is initialized when setUser is called
        this.wsConnection = null;
        this.wsPromiseSafe = null;
        this.connectUserTask = null;
        // mapping between channel groups and configs
        this.anonymous = false;
        this.persistUserOnConnectionFailure =
            this.options?.persistUserOnConnectionFailure;
        // If it is a server-side client, then lets initialize the tokenManager, since token will be
        // generated from secret.
        this.tokenManager = new TokenManager(this.secret);
        this.consecutiveFailures = 0;
        this.defaultWSTimeout = this.options.defaultWsTimeout ?? 15000;
        this.logger = isFunction(inputOptions.logger)
            ? inputOptions.logger
            : () => null;
    }
    get connectionIdPromise() {
        return this.connectionIdPromiseSafe?.();
    }
    get isConnectionIsPromisePending() {
        return this.connectionIdPromiseSafe?.checkPending() ?? false;
    }
    get wsPromise() {
        return this.wsPromiseSafe?.();
    }
}

/**
 * Utility function to get the instance key.
 */
const getInstanceKey = (apiKey, user) => {
    return `${apiKey}/${user.id}`;
};
/**
 * Utility function to get the client app identifier.
 */
const getClientAppIdentifier = (options) => {
    const appId = options?.clientAppIdentifier || {};
    const sdkInfo = getSdkInfo();
    if (sdkInfo) {
        // ensure the sdk name and version are set correctly,
        // overriding any user-provided values
        appId.sdkName = SdkType[sdkInfo.type].toLowerCase();
        appId.sdkVersion = `${sdkInfo.major}.${sdkInfo.minor}.${sdkInfo.patch}`;
    }
    return appId;
};
/**
 * Creates a coordinator client.
 */
const createCoordinatorClient = (apiKey, options) => {
    const clientAppIdentifier = getClientAppIdentifier(options);
    const coordinatorLogger = getLogger(['coordinator']);
    return new StreamClient(apiKey, {
        persistUserOnConnectionFailure: true,
        ...options,
        clientAppIdentifier,
        logger: coordinatorLogger,
    });
};
/**
 * Creates a token provider and allows integrators to provide
 * a static token and a token provider at the same time.
 *
 * When both of them are provided, this function will create an internal
 * token provider that will use the static token on the first invocation
 * and the token provider on the later invocations.
 */
const createTokenOrProvider = (options) => {
    const { token, tokenProvider } = options;
    if (token && tokenProvider) {
        let initialTokenUsed = false;
        return async function wrappedTokenProvider() {
            if (!initialTokenUsed) {
                initialTokenUsed = true;
                return token;
            }
            return tokenProvider();
        };
    }
    return token || tokenProvider;
};

/**
 * A `StreamVideoClient` instance lets you communicate with our API, and authenticate users.
 */
class StreamVideoClient {
    constructor(apiKeyOrArgs, opts) {
        this.effectsRegistered = false;
        this.eventHandlersToUnregister = [];
        this.connectionConcurrencyTag = Symbol('connectionConcurrencyTag');
        this.registerClientInstance = (apiKey, user) => {
            const instanceKey = getInstanceKey(apiKey, user);
            if (StreamVideoClient._instances.has(instanceKey)) {
                this.logger('warn', `A StreamVideoClient already exists for ${user.id}; Prefer using getOrCreateInstance method`);
            }
            StreamVideoClient._instances.set(instanceKey, this);
        };
        this.registerEffects = () => {
            if (this.effectsRegistered)
                return;
            this.eventHandlersToUnregister.push(this.on('connection.changed', (event) => {
                if (!event.online)
                    return;
                const callsToReWatch = this.writeableStateStore.calls
                    .filter((call) => call.watching)
                    .map((call) => call.cid);
                if (callsToReWatch.length <= 0)
                    return;
                this.logger('info', `Rewatching calls ${callsToReWatch.join(', ')}`);
                this.queryCalls({
                    watch: true,
                    filter_conditions: { cid: { $in: callsToReWatch } },
                    sort: [{ field: 'cid', direction: 1 }],
                }).catch((err) => {
                    this.logger('error', 'Failed to re-watch calls', err);
                });
            }));
            this.eventHandlersToUnregister.push(this.on('call.created', (event) => {
                const { call, members } = event;
                if (this.state.connectedUser?.id === call.created_by.id) {
                    this.logger('warn', 'Received `call.created` sent by the current user');
                    return;
                }
                this.logger('info', `New call created and registered: ${call.cid}`);
                const newCall = new Call({
                    streamClient: this.streamClient,
                    type: call.type,
                    id: call.id,
                    members,
                    clientStore: this.writeableStateStore,
                });
                newCall.state.updateFromCallResponse(call);
                this.writeableStateStore.registerCall(newCall);
            }));
            this.eventHandlersToUnregister.push(this.on('call.ring', async (event) => {
                const { call, members } = event;
                if (this.state.connectedUser?.id === call.created_by.id) {
                    this.logger('debug', 'Received `call.ring` sent by the current user so ignoring the event');
                    return;
                }
                // if `call.created` was received before `call.ring`.
                // the client already has the call instance and we just need to update the state
                const theCall = this.writeableStateStore.findCall(call.type, call.id);
                if (theCall) {
                    await theCall.updateFromRingingEvent(event);
                }
                else {
                    // if client doesn't have the call instance, create the instance and fetch the latest state
                    // Note: related - we also have onRingingCall method to handle this case from push notifications
                    const newCallInstance = new Call({
                        streamClient: this.streamClient,
                        type: call.type,
                        id: call.id,
                        members,
                        clientStore: this.writeableStateStore,
                        ringing: true,
                    });
                    await newCallInstance.get();
                }
            }));
            this.effectsRegistered = true;
        };
        /**
         * Connects the given user to the client.
         * Only one user can connect at a time, if you want to change users, call `disconnectUser` before connecting a new user.
         * If the connection is successful, the connected user [state variable](#readonlystatestore) will be updated accordingly.
         *
         * @param user the user to connect.
         * @param tokenOrProvider a token or a function that returns a token.
         */
        this.connectUser = async (user, tokenOrProvider) => {
            if (user.type === 'anonymous') {
                user.id = '!anon';
                return this.connectAnonymousUser(user, tokenOrProvider);
            }
            const connectUserResponse = await withoutConcurrency(this.connectionConcurrencyTag, async () => {
                const client = this.streamClient;
                const { onConnectUserError, persistUserOnConnectionFailure } = client.options;
                let { maxConnectUserRetries = 5 } = client.options;
                maxConnectUserRetries = Math.max(maxConnectUserRetries, 1);
                const errorQueue = [];
                for (let attempt = 0; attempt < maxConnectUserRetries; attempt++) {
                    try {
                        this.logger('trace', `Connecting user (${attempt})`, user);
                        return user.type === 'guest'
                            ? await client.connectGuestUser(user)
                            : await client.connectUser(user, tokenOrProvider);
                    }
                    catch (err) {
                        this.logger('warn', `Failed to connect a user (${attempt})`, err);
                        errorQueue.push(err);
                        if (attempt === maxConnectUserRetries - 1) {
                            onConnectUserError?.(err, errorQueue);
                            throw err;
                        }
                        // we need to force to disconnect the user if the client is
                        // configured to persist the user on connection failure
                        if (persistUserOnConnectionFailure) {
                            await client.disconnectUser();
                        }
                        await sleep(retryInterval(attempt));
                    }
                }
            });
            // connectUserResponse will be void if connectUser called twice for the same user
            if (connectUserResponse?.me) {
                this.writeableStateStore.setConnectedUser(connectUserResponse.me);
            }
            this.registerEffects();
            return connectUserResponse;
        };
        /**
         * Disconnects the currently connected user from the client.
         *
         * If the connection is successfully disconnected, the connected user [state variable](#readonlystatestore) will be updated accordingly
         *
         * @param timeout Max number of ms, to wait for close event of websocket, before forcefully assuming successful disconnection.
         *                https://developer.mozilla.org/en-US/docs/Web/API/CloseEvent
         */
        this.disconnectUser = async (timeout) => {
            await withoutConcurrency(this.connectionConcurrencyTag, async () => {
                const { user, key } = this.streamClient;
                if (!user)
                    return;
                await this.streamClient.disconnectUser(timeout);
                if (user.id) {
                    StreamVideoClient._instances.delete(getInstanceKey(key, user));
                }
                this.eventHandlersToUnregister.forEach((unregister) => unregister());
                this.eventHandlersToUnregister = [];
                this.effectsRegistered = false;
                this.writeableStateStore.setConnectedUser(undefined);
            });
        };
        /**
         * You can subscribe to WebSocket events provided by the API.
         * To remove a subscription, call the `off` method or, execute the returned unsubscribe function.
         * Please note that subscribing to WebSocket events is an advanced use-case, for most use-cases it should be enough to watch for changes in the reactive [state store](#readonlystatestore).
         *
         * @param eventName the event name or 'all'.
         * @param callback the callback which will be called when the event is emitted.
         * @returns an unsubscribe function.
         */
        this.on = (eventName, callback) => {
            return this.streamClient.on(eventName, callback);
        };
        /**
         * Remove subscription for WebSocket events that were created by the `on` method.
         *
         * @param eventName the event name.
         * @param callback the callback which was passed to the `on` method.
         */
        this.off = (eventName, callback) => {
            return this.streamClient.off(eventName, callback);
        };
        /**
         * Creates a new call.
         *
         * @param type the type of the call.
         * @param id the id of the call.
         */
        this.call = (type, id) => {
            return new Call({
                streamClient: this.streamClient,
                id: id,
                type: type,
                clientStore: this.writeableStateStore,
            });
        };
        /**
         * Creates a new guest user with the given data.
         *
         * @param data the data for the guest user.
         */
        this.createGuestUser = async (data) => {
            return this.streamClient.doAxiosRequest('post', '/guest', data, { publicEndpoint: true });
        };
        /**
         * Will query the API for calls matching the given filters.
         *
         * @param data the query data.
         */
        this.queryCalls = async (data = {}) => {
            const response = await this.streamClient.post('/calls', data);
            const calls = [];
            for (const c of response.calls) {
                const call = new Call({
                    streamClient: this.streamClient,
                    id: c.call.id,
                    type: c.call.type,
                    members: c.members,
                    ownCapabilities: c.own_capabilities,
                    watching: data.watch,
                    clientStore: this.writeableStateStore,
                });
                call.state.updateFromCallResponse(c.call);
                await call.applyDeviceConfig(c.call.settings, false);
                if (data.watch) {
                    await call.setup();
                    this.writeableStateStore.registerCall(call);
                }
                calls.push(call);
            }
            return {
                ...response,
                calls: calls,
            };
        };
        /**
         * Retrieve the list of available call statistics reports matching a particular condition.
         *
         * @param data Filter and sort conditions for retrieving available call report summaries.
         * @returns List with summary of available call reports matching the condition.
         */
        this.queryCallStats = async (data = {}) => {
            return this.streamClient.post(`/call/stats`, data);
        };
        /**
         * Retrieve the list of available reports aggregated from the call stats.
         *
         * @param data Specify filter conditions like from and to (within last 30 days) and the report types
         * @returns Requested reports with (mostly) raw daily data for each report type requested
         */
        this.queryAggregateCallStats = async (data = {}) => {
            return this.streamClient.post(`/stats`, data);
        };
        /**
         * Returns a list of available data centers available for hosting calls.
         */
        this.edges = async () => {
            return this.streamClient.get(`/edges`);
        };
        /**
         * addDevice - Adds a push device for a user.
         *
         * @param {string} id the device id
         * @param {string} push_provider the push provider name (eg. apn, firebase)
         * @param {string} push_provider_name user provided push provider name
         * @param {string} [userID] the user id (defaults to current user)
         * @param {boolean} [voip_token] enables use of VoIP token for push notifications on iOS platform
         */
        this.addDevice = async (id, push_provider, push_provider_name, userID, voip_token) => {
            return await this.streamClient.post('/devices', {
                id,
                push_provider,
                voip_token,
                ...(userID != null ? { user_id: userID } : {}),
                ...(push_provider_name != null ? { push_provider_name } : {}),
            });
        };
        /**
         * addDevice - Adds a push device for a user.
         *
         * @param {string} id the device id
         * @param {string} push_provider the push provider name (eg. apn, firebase)
         * @param {string} push_provider_name user provided push provider name
         * @param {string} [userID] the user id (defaults to current user)
         */
        this.addVoipDevice = async (id, push_provider, push_provider_name, userID) => {
            return await this.addDevice(id, push_provider, push_provider_name, userID, true);
        };
        /**
         * getDevices - Returns the devices associated with a current user
         * @param {string} [userID] User ID. Only works on serverside
         */
        this.getDevices = async (userID) => {
            return await this.streamClient.get('/devices', userID ? { user_id: userID } : {});
        };
        /**
         * removeDevice - Removes the device with the given id.
         *
         * @param {string} id The device id
         * @param {string} [userID] The user id. Only specify this for serverside requests
         */
        this.removeDevice = async (id, userID) => {
            return await this.streamClient.delete('/devices', {
                id,
                ...(userID ? { user_id: userID } : {}),
            });
        };
        /**
         * A callback that can be used to create ringing calls from push notifications. If the call already exists, it will do nothing.
         * @param call_cid
         * @returns
         */
        this.onRingingCall = async (call_cid) => {
            // if we find the call and is already ringing, we don't need to create a new call
            // as client would have received the call.ring state because the app had WS alive when receiving push notifications
            let call = this.state.calls.find((c) => c.cid === call_cid && c.ringing);
            if (!call) {
                // if not it means that WS is not alive when receiving the push notifications and we need to fetch the call
                const [callType, callId] = call_cid.split(':');
                call = new Call({
                    streamClient: this.streamClient,
                    type: callType,
                    id: callId,
                    clientStore: this.writeableStateStore,
                    ringing: true,
                });
                await call.get();
            }
            return call;
        };
        /**
         * Connects the given anonymous user to the client.
         *
         * @param user the user to connect.
         * @param tokenOrProvider a token or a function that returns a token.
         */
        this.connectAnonymousUser = async (user, tokenOrProvider) => {
            return withoutConcurrency(this.connectionConcurrencyTag, () => this.streamClient.connectAnonymousUser(user, tokenOrProvider));
        };
        const apiKey = typeof apiKeyOrArgs === 'string' ? apiKeyOrArgs : apiKeyOrArgs.apiKey;
        const clientOptions = typeof apiKeyOrArgs === 'string' ? opts : apiKeyOrArgs.options;
        if (clientOptions?.enableTimerWorker)
            enableTimerWorker();
        const rootLogger = clientOptions?.logger || logToConsole;
        setLogger(rootLogger, clientOptions?.logLevel || 'warn');
        this.logger = getLogger(['client']);
        this.streamClient = createCoordinatorClient(apiKey, clientOptions);
        this.writeableStateStore = new StreamVideoWriteableStateStore();
        this.readOnlyStateStore = new StreamVideoReadOnlyStateStore(this.writeableStateStore);
        if (typeof apiKeyOrArgs !== 'string' && apiKeyOrArgs.user) {
            const user = apiKeyOrArgs.user;
            if (user.type === 'anonymous')
                user.id = '!anon';
            if (user.id)
                this.registerClientInstance(apiKey, user);
            const tokenOrProvider = createTokenOrProvider(apiKeyOrArgs);
            this.connectUser(user, tokenOrProvider).catch((err) => {
                this.logger('error', 'Failed to connect', err);
            });
        }
    }
    /**
     * Gets or creates a StreamVideoClient instance based on the given options.
     */
    static getOrCreateInstance(args) {
        const { apiKey, user, token, tokenProvider } = args;
        if (!user.id && user.type !== 'anonymous') {
            throw new Error('user.id is required for a non-anonymous user');
        }
        if (!token &&
            !tokenProvider &&
            user.type !== 'anonymous' &&
            user.type !== 'guest') {
            throw new Error('tokenProvider or token is required for a authenticated users');
        }
        return (StreamVideoClient._instances.get(getInstanceKey(apiKey, user)) ||
            new StreamVideoClient(args));
    }
    /**
     * Return the reactive state store, use this if you want to be notified about changes to the client state
     */
    get state() {
        return this.readOnlyStateStore;
    }
}
StreamVideoClient._instances = new Map();

Object.defineProperty(exports, "AxiosError", {
    enumerable: true,
    get: function () { return axios.AxiosError; }
});
exports.AudioSettingsRequestDefaultDeviceEnum = AudioSettingsRequestDefaultDeviceEnum;
exports.AudioSettingsResponseDefaultDeviceEnum = AudioSettingsResponseDefaultDeviceEnum;
exports.Browsers = browsers;
exports.Call = Call;
exports.CallState = CallState;
exports.CallType = CallType;
exports.CallTypes = CallTypes;
exports.CameraManager = CameraManager;
exports.CameraManagerState = CameraManagerState;
exports.CreateDeviceRequestPushProviderEnum = CreateDeviceRequestPushProviderEnum;
exports.DynascaleManager = DynascaleManager;
exports.ErrorFromResponse = ErrorFromResponse;
exports.FrameRecordingSettingsRequestModeEnum = FrameRecordingSettingsRequestModeEnum;
exports.FrameRecordingSettingsRequestQualityEnum = FrameRecordingSettingsRequestQualityEnum;
exports.FrameRecordingSettingsResponseModeEnum = FrameRecordingSettingsResponseModeEnum;
exports.InputMediaDeviceManager = InputMediaDeviceManager;
exports.InputMediaDeviceManagerState = InputMediaDeviceManagerState;
exports.LayoutSettingsRequestNameEnum = LayoutSettingsRequestNameEnum;
exports.MicrophoneManager = MicrophoneManager;
exports.MicrophoneManagerState = MicrophoneManagerState;
exports.NoiseCancellationSettingsModeEnum = NoiseCancellationSettingsModeEnum;
exports.OwnCapability = OwnCapability;
exports.RTMPBroadcastRequestQualityEnum = RTMPBroadcastRequestQualityEnum;
exports.RTMPSettingsRequestQualityEnum = RTMPSettingsRequestQualityEnum;
exports.RecordSettingsRequestModeEnum = RecordSettingsRequestModeEnum;
exports.RecordSettingsRequestQualityEnum = RecordSettingsRequestQualityEnum;
exports.RxUtils = rxUtils;
exports.ScreenShareManager = ScreenShareManager;
exports.ScreenShareState = ScreenShareState;
exports.SfuEvents = events;
exports.SfuModels = models;
exports.SpeakerManager = SpeakerManager;
exports.SpeakerState = SpeakerState;
exports.StreamSfuClient = StreamSfuClient;
exports.StreamVideoClient = StreamVideoClient;
exports.StreamVideoReadOnlyStateStore = StreamVideoReadOnlyStateStore;
exports.StreamVideoWriteableStateStore = StreamVideoWriteableStateStore;
exports.TranscriptionSettingsRequestClosedCaptionModeEnum = TranscriptionSettingsRequestClosedCaptionModeEnum;
exports.TranscriptionSettingsRequestLanguageEnum = TranscriptionSettingsRequestLanguageEnum;
exports.TranscriptionSettingsRequestModeEnum = TranscriptionSettingsRequestModeEnum;
exports.TranscriptionSettingsResponseClosedCaptionModeEnum = TranscriptionSettingsResponseClosedCaptionModeEnum;
exports.TranscriptionSettingsResponseLanguageEnum = TranscriptionSettingsResponseLanguageEnum;
exports.TranscriptionSettingsResponseModeEnum = TranscriptionSettingsResponseModeEnum;
exports.VideoSettingsRequestCameraFacingEnum = VideoSettingsRequestCameraFacingEnum;
exports.VideoSettingsResponseCameraFacingEnum = VideoSettingsResponseCameraFacingEnum;
exports.ViewportTracker = ViewportTracker;
exports.checkIfAudioOutputChangeSupported = checkIfAudioOutputChangeSupported;
exports.combineComparators = combineComparators;
exports.conditional = conditional;
exports.createSoundDetector = createSoundDetector;
exports.defaultSortPreset = defaultSortPreset;
exports.descending = descending;
exports.deviceIds$ = deviceIds$;
exports.disposeOfMediaStream = disposeOfMediaStream;
exports.dominantSpeaker = dominantSpeaker;
exports.getAudioBrowserPermission = getAudioBrowserPermission;
exports.getAudioDevices = getAudioDevices;
exports.getAudioOutputDevices = getAudioOutputDevices;
exports.getAudioStream = getAudioStream;
exports.getClientDetails = getClientDetails;
exports.getDeviceState = getDeviceState;
exports.getLogLevel = getLogLevel;
exports.getLogger = getLogger;
exports.getScreenShareStream = getScreenShareStream;
exports.getSdkInfo = getSdkInfo;
exports.getVideoBrowserPermission = getVideoBrowserPermission;
exports.getVideoDevices = getVideoDevices;
exports.getVideoStream = getVideoStream;
exports.getWebRTCInfo = getWebRTCInfo;
exports.hasAudio = hasAudio;
exports.hasScreenShare = hasScreenShare;
exports.hasScreenShareAudio = hasScreenShareAudio;
exports.hasVideo = hasVideo;
exports.isPinned = isPinned;
exports.livestreamOrAudioRoomSortPreset = livestreamOrAudioRoomSortPreset;
exports.logLevels = logLevels;
exports.logToConsole = logToConsole;
exports.name = name;
exports.noopComparator = noopComparator;
exports.paginatedLayoutSortPreset = paginatedLayoutSortPreset;
exports.pinned = pinned;
exports.publishingAudio = publishingAudio;
exports.publishingVideo = publishingVideo;
exports.reactionType = reactionType;
exports.role = role;
exports.screenSharing = screenSharing;
exports.setDeviceInfo = setDeviceInfo;
exports.setLogLevel = setLogLevel;
exports.setLogger = setLogger;
exports.setOSInfo = setOSInfo;
exports.setPowerState = setPowerState;
exports.setSdkInfo = setSdkInfo;
exports.setThermalState = setThermalState;
exports.setWebRTCInfo = setWebRTCInfo;
exports.speakerLayoutSortPreset = speakerLayoutSortPreset;
exports.speaking = speaking;
//# sourceMappingURL=index.cjs.js.map
